<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Ambarella Linux SDK: SDK Code Building</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<link rel="search" href="../../search_opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Ambarella Linux SDK"/>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-ambarella.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../Ambarella.png"/></td>
  <td id="projectalign">
   <div id="projectname">Ambarella Linux SDK<span id="projectnumber">&#160;Cooper_1.6.0 (CV72 &amp; CV3) @ 2024.07.10 14:12:44</span>
   </div>
   <div id="projectbrief">placeholder</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,true,'search.html','Search');
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d9/d98/ov_code_build.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">SDK Code Building </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="code_build_history"></a>
0. Revision History</h1>
<a class="anchor" id="code_build_history"></a>
<table class="doxtable">
<caption>Revision History</caption>
<tr>
<th>SDK Version </th><th>Updated Date </th><th>Modification </th></tr>
<tr>
<td>CV5x_SDK_0.2 </td><td>20211021 </td><td>Initial Version </td></tr>
<tr>
<td>CV5x_SDK_0.5 </td><td>20220114 </td><td>Updated Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_arm">3.3 Install the Arm® Toolchain</a> </td></tr>
<tr>
<td rowspan="2">CV5x_SDK_1.0 </td><td rowspan="2">20220415 </td><td>Updated Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_arm">3.3 Install the Arm® Toolchain</a> </td></tr>
<tr>
<td>Updated Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_full_build">4.3 Build Firmware</a> </td></tr>
<tr>
<td rowspan="2">CV5x_SDK_2.0 </td><td>20220915 </td><td>Migrated this Code Building document from Word form into Doxygen form </td></tr>
<tr>
<td>20221025 </td><td>Update Cortex Toolchain to 12.1 in Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_arm">3.3 Install the Arm® Toolchain</a> </td></tr>
<tr>
<td>CV5x_SDK_2.5 </td><td>20230227 </td><td>Updated Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_pc_evk_nfs">6.5 Network Sharing: NFS</a> </td></tr>
<tr>
<td>Cooper_SDK_0.5 </td><td>20230420 </td><td>Initial Version of Cooper SDK </td></tr>
<tr>
<td rowspan="5">Cooper_SDK_1.0 </td><td rowspan="4">20230720 </td><td>Update Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_ubu">3.1 Install Ubuntu OS</a> </td></tr>
<tr>
<td>Updated Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_tool">3.4 Install the Computer Vision (CV) Toolchain</a> </td></tr>
<tr>
<td>Updated Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_doc">3.5 Install the CV Toolchain on Docker</a> </td></tr>
<tr>
<td>Updated Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_pod">3.6 Install the CV Toolchain on Podman</a> </td></tr>
<tr>
<td>20230811 </td><td>Added Section <a class="el" href="../../d9/d98/ov_code_build.html#code_build_oss">8. Build OSS Libraries</a> </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="code_build_overview"></a>
1. Overview</h1>
<p >This document provides information to help users navigate through the Ambarella Cooper Linux software development kit (SDK), prepare a build machine, build the SDK, and share it during product development.</p>
<p >The Ambarella Cooper Linux SDK development environment requires a host that uses the Linux operating system (OS). This document guides the reader through the installation and configuration of the Linux environment to assist in the compilation of the Cooper Linux SDK. A cross-compile tool suite is used to compile the Linux images.</p>
<dl class="section note"><dt>Note</dt><dd>The configurations described in this document are provided as recommendations only.</dd></dl>
<p>This chapter describes how to perform the following: </p><ul>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_ove_scope">1.1 Scope of Document</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_ove_flex">1.2 Cooper Linux SDK</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_ove_soft">1.3 Software Architecture</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_ove_sou">1.4 Source Code</a> </li>
</ul>
<h2><a class="anchor" id="sub_code_build_ove_scope"></a>
1.1 Scope of Document</h2>
<p >Included in this document are the hardware, software, and network requirements for building the SDK and instructions for setting up the Ubuntu machine and PC.</p>
<p >The following describes the contents of each chapter:<br  />
</p><ul>
<li>Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_overview">1. Overview</a> includes a table of key document updates and an introduction to the SDK package contents, software architecture, and source code.<br  />
</li>
<li>Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_requirement">2. Requirements for the Development Environment</a> lists the development environment requirements.<br  />
</li>
<li>Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_setup_linux">3. Set Up the Linux Build Machine</a> provides instructions on setting up the Ubuntu machine for building codes.<br  />
</li>
<li>Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_full_sdk">4. Build Full SDK Code</a> provides instructions for building new firmware with the full SDK code.<br  />
</li>
<li>Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_eva_sdk">5. Build Evaluation SDK Code</a> provides instructions for building new firmware with the evaluation SDK package.<br  />
</li>
<li>Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_setup_pc">6. Set Up the PC</a> provides instructions for setting up the PC.<br  />
</li>
<li>Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_upgrade">7. Upgrade the Firmware to the Development Platform</a> provides methods for upgrading the firmware on the CV5x / CV7x board.<br  />
</li>
<li>Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_oss">8. Build OSS Libraries</a> provdies instructions for building open source software (OSS) libraries.<br  />
</li>
</ul>
<h2><a class="anchor" id="sub_code_build_ove_flex"></a>
1.2 Cooper Linux SDK</h2>
<p >Ambarella Cooper Linux SDK can be downloaded from the Ambarella Customer Portal site. Contact the Ambarella support team for details on downloading the SDK.</p>
<p >The SDK includes the following:</p><ul>
<li><b>Evaluation:</b> Evaluation package</li>
<li><b>SDKx.x</b> SDK package, which includes code and documentation<ul>
<li>Package: Source code package</li>
<li>Document: Hardware and software documentation</li>
</ul>
</li>
<li><b>Tools:</b> Ambarella tools</li>
</ul>
<h2><a class="anchor" id="sub_code_build_ove_soft"></a>
1.3 Software Architecture</h2>
<p >The following figure shows the system architecture for the CV5x / CV7x chip. The Ambarella CV5x / CV7x platform uses the flexible, open source Linux operating system. Developers can customize the Linux OS for many purposes, including using a novel graphical user interface (GUI) engine such as <b>Qt</b>, enhancing networking, simplifying WiFi use, and reusing available source libraries such as <b>WebServer</b> and <b>HostAP</b>. Additionally, users can easily port a variety of Linux video frameworks such as <b>FFmpeg</b>, <b>GStreamer</b>, and <b>IPV6</b>.</p>
<p ><a class="anchor" id="code_build_soft_arch_fig"></a></p><div class="image">
<img src="../../code_build_soft_arch.png" alt=""/>
<div class="caption">
Figure 1-1. Cooper Software Architecture.</div></div>
<h2><a class="anchor" id="sub_code_build_ove_sou"></a>
1.4 Source Code</h2>
<h3><a class="anchor" id="dsub_code_build_ove_dir"></a>
1.4.1 Code Directory</h3>
<p >The top directory of the Cooper Linux SDK package is <code>ambarella/</code>. Subdirectories are listed below. Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_full_sdk">4. Build Full SDK Code</a> introduces build commands to extract the code from the package.</p>
<a class="anchor" id="code_build_code_diretory"></a>
<table class="doxtable">
<caption>Table 1-1. Code Directory.</caption>
<tr>
<th>Directory </th><th>Content </th></tr>
<tr>
<td><b>amboot/</b> </td><td>Bootloader (BLD), board support toolkit, and file system information about the partitions </td></tr>
<tr>
<td><b>app/</b> </td><td>Demo applications </td></tr>
<tr>
<td><b>boards/</b> </td><td>The compile configuration files, DDR configuration, and bootstrap (BST) </td></tr>
<tr>
<td><b>build/</b> </td><td>Rules for makefile and AmbaConfig </td></tr>
<tr>
<td><b>document/</b> </td><td>Doxygen content and configuration rules </td></tr>
<tr>
<td><b>include/</b> </td><td>Header files </td></tr>
<tr>
<td><b>kernel/</b> </td><td>Linux kernel, digital signal processor (DSP) firmware, image audio video (IAV) / DSP / sensor and peripheral devices drivers </td></tr>
<tr>
<td><b>external</b> </td><td>External WiFi modules codes </td></tr>
<tr>
<td><b>linux-5.15</b> </td><td>Linux kernel and patch codes </td></tr>
<tr>
<td><b>private</b> </td><td>Ambarella propriety drivers / modules codes and binaries </td></tr>
<tr>
<td><b>license/</b> </td><td>License files of each component </td></tr>
<tr>
<td><b>out/</b> </td><td>The build target and intermediate objects </td></tr>
<tr>
<td><b>packages/</b> </td><td>Libraries that assist in video processing, streaming, or transferring </td></tr>
<tr>
<td><b>data_transfer</b> </td><td>Code for data storage over NFS and code for data transferring via USB / TCP </td></tr>
<tr>
<td><b>img_algo</b> </td><td>Image algorithm library; the pre-built binary is in <code>ambarella/prebuild/imgproc</code> (Source codes are not released) </td></tr>
<tr>
<td><b>utils</b> </td><td>Utility library codes </td></tr>
<tr>
<td><b>nnctrl</b> </td><td>Initial Cavalry binary, which is generated by cavalry_gen </td></tr>
<tr>
<td><b>vproc</b> </td><td>Pre-defined directed acyclic graphs (DAGs) used to convert the data format </td></tr>
<tr>
<td><b>prebuild/</b> </td><td>Pre-built binaries, including Ambarella libraries and third-party libraries </td></tr>
<tr>
<td><b>ambarella/library</b> </td><td>Binary format of various Ambarella proprietary libraries </td></tr>
<tr>
<td><b>imgproc</b> </td><td>Binary format of library file and image tuning parameter files </td></tr>
<tr>
<td><b>third-party</b> </td><td>Binary format of third party-library files </td></tr>
<tr>
<td><b>rootfs/</b> </td><td>System (Rootfs) </td></tr>
<tr>
<td><b>unit_test/</b> </td><td>Unit test tools </td></tr>
</table>
<h3><a class="anchor" id="dsub_code_build_ove_sou"></a>
1.4.2 Source Code and Software Layers</h3>
<p >The following shows the relationship between the software architecture (figure <a class="el" href="../../d9/d98/ov_code_build.html#code_build_soft_arch_fig">Figure 1-1. Cooper Software Architecture</a>) and the source code directories. Additional software modules will be added in later SDK versions.</p>
<a class="anchor" id="code_build_soft_arch_dirt"></a>
<table class="doxtable">
<caption>Table 1-2. Code Category.</caption>
<tr>
<th>Category </th><th>Architecture </th><th>Directory </th></tr>
<tr>
<td rowspan="5"><b>System</b> </td><td>Bootstrap and BootLoader </td><td>ambarella/boot/amboot </td></tr>
<tr>
<td>Linux kernel and device driver </td><td>ambarella/kernel/linux </td></tr>
<tr>
<td>DSP / IAV / video input (VIN) / video output (VOUT) </td><td>ambarella/drv_modules </td></tr>
<tr>
<td>File system </td><td>ambarella/rootfs </td></tr>
<tr>
<td>System configuration </td><td>ambarella/boards </td></tr>
<tr>
<td rowspan="2"><b>Middleware</b> </td><td>Neural network control (NNCtrl) </td><td>ambarella/packages/nnctrl </td></tr>
<tr>
<td>VProc </td><td>ambarella/packages/vproc </td></tr>
<tr>
<td rowspan="2"><b>Application</b> </td><td>Unit test tools </td><td>ambarella/unit_test </td></tr>
<tr>
<td>Demo applications </td><td>ambarella/app </td></tr>
</table>
<h3><a class="anchor" id="dsub_code_build_ove_ava"></a>
1.4.3 Source Code Availability</h3>
<p >The source code for the software shown in the application, middleware, and system frames down in <a class="el" href="../../d9/d98/ov_code_build.html#code_build_soft_arch_fig">Figure 1-1. Cooper Software Architecture</a> are included in the SDK package. Third-party libraries (such as the image processing library, the dewarp library, (fisheye and lens distortion correction (LDC)), and the BST) are provided as pre-built binaries. Users can obtain the source code for each library from the internet.</p>
<p >Ambarella warrants the source code for the software shown in the middleware and system frames shown in figure <a class="el" href="../../d9/d98/ov_code_build.html#code_build_soft_arch_fig">Figure 1-1. Cooper Software Architecture</a>. Ambarella does not warrant the source code shown in the application frame. Users can modify the unit test and applications source codes in order to meet product requirements. The software shown in the application frame is provided to enhance the user experience and streamline application development.</p>
<h3><a class="anchor" id="dsub_code_build_ove_cv2x"></a>
1.4.4 Comparison to CV2x SDK</h3>
<p >Due to the similarity between the code directories and software layers of the CV2x SDK and the Cooper SDK, upgrading to the Cooper SDK from the CV2x SDK is straightforward. For more details, refer to page <a class="elRef" target="_blank" href="../../../system/d9/dc6/page_sys_mg_cv2x.html">Migration Guide From CV2x SDK</a>.</p>
<hr  />
<h1><a class="anchor" id="code_build_requirement"></a>
2. Requirements for the Development Environment</h1>
<p >This chapter includes the following sections: </p><ul>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_req_ove">2.1 Overview</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_req_lin">2.2 Linux Build Machine</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_req_win">2.3 Windows PC</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_req_net">2.4 Network Topology</a> </li>
</ul>
<h2><a class="anchor" id="sub_code_build_req_ove"></a>
2.1 Overview</h2>
<p >Using the Ambarella SDK requires three machines:</p><ul>
<li>Portal release order (PRO) release server (<a href="https://customer.ambarella.com/">https://customer.ambarella.com/</a>)</li>
<li>Linux build machine to cross-compile the binary</li>
<li>Windows PC to download the binary</li>
</ul>
<p >The PRO server (1) is organized and supported by Ambarella. Developers are expected to arrange and organize the Linux build machine (2) and the Windows PC (3). </p><div class="image">
<img src="../../code_build_sdk_upgrade_pipeline.png" alt=""/>
<div class="caption">
Figure 2-1. SDK Download / Build / Firmware Upgrade Pipeline.</div></div>
<p >The developer downloads the SDK package from the Ambarella PRO server to the PC and transfers the files to a Linux build machine that runs the <b>Ubuntu</b> server (Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_setup_linux">3. Set Up the Linux Build Machine</a>). The <b>toolchain</b> can be used to build the code (Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_full_sdk">4. Build Full SDK Code</a>) when it is installed in the build machine.</p>
<p >After the SDK is built, the firmware is available to the build machine. The development PC is prepared (Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_eva_sdk">5. Build Evaluation SDK Code</a>), and the firmware binary is transmitted to the PC (described below). The binary is then burned to flash on the development board using the Ambarella <b>AmbaUSB</b> tool (Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_upgrade">7. Upgrade the Firmware to the Development Platform</a>). Contact an Ambarella support team member for development board setup and use.</p>
<p >Ambarella recommends using a <b>Samba</b> server that has been set up on the build machine to transmit the firmware binary to the PC.</p>
<p ><b>Samba</b> setup is outside the scope of this document. For pertinent information, refer to <a href="http://www.samba.org/samba/docs/man/Samba-HOWTO-Collection">http://www.samba.org/samba/docs/man/Samba-HOWTO-Collection</a>.</p>
<h2><a class="anchor" id="sub_code_build_req_lin"></a>
2.2 Linux Build Machine</h2>
<p >The following are the hardware requirements for the Linux build environment; refer to Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_setup_linux">3. Set Up the Linux Build Machine</a> for more information:</p><ul>
<li>64-bit capable</li>
<li>Two Intel(R)® Xeon(R)® X 5670, 2.93-GHz, 12-M cache</li>
<li>32-GB memory (8 x 4 GB), 1333-MHz, dual-rank RDIMMs for two processors</li>
<li>600-GB, 3.5-inch 15 K RPM, 6-Gbps SAS hot plug hard drive</li>
<li>Dual-port gigabit Ethernet</li>
</ul>
<h2><a class="anchor" id="sub_code_build_req_win"></a>
2.3 Windows PC</h2>
<p >A Windows PC connected to the Internet is used to download the SDK and / or upgrade the firmware (Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_eva_sdk">5. Build Evaluation SDK Code</a>). For more details about upgrading the firmware, refer to (Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_upgrade">7. Upgrade the Firmware to the Development Platform</a>).</p>
<p >The PC must support the following: </p><a class="anchor" id="code_build_pc_support"></a>
<table class="doxtable">
<caption>Table 2-1. PC Requirements.</caption>
<tr>
<th>Category </th><th>Requirement </th></tr>
<tr>
<td>CPU </td><td>Intel i5 or higher grade </td></tr>
<tr>
<td>Memory </td><td>8-GB system memory or more </td></tr>
<tr>
<td>Hard disk </td><td>120 GB or more </td></tr>
<tr>
<td>Video card </td><td>3D hardware accelerator card required – 100% DirectX 9.0c compatible. AMD / ATI HD2600 Pro or NVidia 9800 GT or above to assure the full frame rate of high-definition (HD) playback is preferred </td></tr>
<tr>
<td>Monitor </td><td>19-inches LCD or larger with digital video interface (DVI) input. DELL UltraSharp 2709W (VA panel) is preferred </td></tr>
<tr>
<td>LCD TV </td><td>24-inch LCD TV or larger with YPbPr input (1080p resolution) </td></tr>
<tr>
<td>Ethernet card </td><td>1000 Mbps (adaptive) </td></tr>
<tr>
<td>I/O interfaces </td><td>RS232 </td></tr>
<tr>
<td>Operating system </td><td>64-bit Windows 7 / 8 or 64-bit Ubuntu 16.04 LTS </td></tr>
<tr>
<td>Virtual machine </td><td>Oracle Virtualbox 4.4.30 or later </td></tr>
</table>
<h2><a class="anchor" id="sub_code_build_req_net"></a>
2.4 Network Topology</h2>
<p >If multiple developers are working on a network, Ambarella recommends acquiring a powerful build machine and sharing it on each developer's PC. Developers A, B, and C can connect to the building server using SSH protocols in a local area network (LAN) (LAN 1). All developer PCs should have two network cards: the first card connected to a public LAN (LAN 1) and the second to a private LAN (LAN 2, 3, 4) between the local PC and the development board.</p>
<p >Because the SDK includes tools for Windows OS, and the development board is based on Linux OS, Ambarella suggests using a Linux virtual machine (VM) on a Windows PC to install the Ambarella SDK. See the figure below for a diagram of the network topology for the development team with server sharing.</p>
<p >Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_pc_linux">6.3 Linux Virtual Machine</a> provides instructions on installing the Linux virtual machine on Windows PCs, and Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_pc_cifs">6.4 Network Sharing: CIFS</a> provides details on sharing the build machine between the PCs and the development boards. </p><div class="image">
<img src="../../code_build_network_topology.png" alt=""/>
<div class="caption">
Figure 2-2. Network Topology for the Development Team with Server Sharing.</div></div>
<hr  />
<h1><a class="anchor" id="code_build_setup_linux"></a>
3. Set Up the Linux Build Machine</h1>
<p >This chapter includes the following sections: </p><ul>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_ubu">3.1 Install Ubuntu OS</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_dow">3.2 Install Development Packages</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_arm">3.3 Install the Arm® Toolchain</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_tool">3.4 Install the Computer Vision (CV) Toolchain</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_doc">3.5 Install the CV Toolchain on Docker</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_set_pod">3.6 Install the CV Toolchain on Podman</a> </li>
</ul>
<h2><a class="anchor" id="sub_code_build_set_ubu"></a>
3.1 Install Ubuntu OS</h2>
<h3><a class="anchor" id="dsub_code_build_set_pag"></a>
3.1.1 Download Ubuntu</h3>
<ol type="1">
<li>Access the Ubuntu official website: <a href="http://www.ubuntu.com/download/server">http://www.ubuntu.com/download/server</a>.</li>
<li>At <b>Download Options</b>, select <b>Ubuntu Server 20.04.6 LTS</b>. Only <b>64-bit</b> Ubuntu is supported.</li>
<li>To download the ISO file, click the <b>Download</b> button. <div class="image">
<img src="../../code_build_linux_ubn_down.png" alt=""/>
<div class="caption">
Figure 3-1. Linux Ubuntu Download Selection and Download Button.</div></div>
</li>
</ol>
<p >A common method for installing Ubuntu consists of creating a compact disk (CD) to install it after downloading the ISO file. Many applications enable burning data to a disk, including <b>Rufus</b>, <b>Ventoy</b>, <b>UltraISO</b>, <b>Nero Burning</b>, and <b>Infra Recorder</b>. For further application recommendations, refer to the following Ubuntu website: <a href="https://help.ubuntu.com/community/BurningIsoHowto">https://help.ubuntu.com/community/BurningIsoHowto</a>.</p>
<p >To install Ubuntu using another form of media, refer to the following links:</p><ul>
<li><a href="https://help.ubuntu.com/20.04/installation-guide/">https://help.ubuntu.com/20.04/installation-guide/</a></li>
<li><a href="http://www.ubuntu.com/">http://www.ubuntu.com/</a></li>
</ul>
<h3><a class="anchor" id="dsub_code_build_set_ins"></a>
3.1.2 Ubuntu Installation</h3>
<ol type="1">
<li>A <b>64-bit</b> server is recommended for installing Ubuntu. Refer to the hardware recommendations described in Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_req_lin">2.2 Linux Build Machine</a>. Additionally, note the following:<ul>
<li>Prior to installation, the machine should have no OS or data, as the installation process erases all existing data.</li>
<li>Using a virtual machine is not recommended as it lengthens the SDK build time.</li>
<li>To build the Ambarella SDK, the machine requires at least 1.5 GB of RAM and at least 15 GB of disk space if <b>Ubuntu</b> is running on a virtual machine.</li>
</ul>
</li>
<li>Load the CD with the Ubuntu ISO file in the drive and restart the machine. Verify that the basic input / output system (BIOS) configuration and the machine settings are consistent with a boot from CD ROM.</li>
<li>From the Ubuntu installation start screen, choose the preferred <b>Language</b> (see the following figure).</li>
<li>Next, choose <b>Install Ubuntu Server</b> (see the following figure). <div class="image">
<img src="../../code_build_install_start.png" alt=""/>
<div class="caption">
Figure 3-2. Ubuntu Installation Start Screen.</div></div>
</li>
<li>Follow the instructions on the screen. Typically, the <b>Default</b> settings will suffice.</li>
<li>At the <b>Guided storage configuration</b> prompt, select <b>Set up this disk as an LVM group</b> and choose <b>Done</b>. <div class="image">
<img src="../../code_build_install_set_lvm.png" alt=""/>
<div class="caption">
Figure 3-3.Ubuntu Installation LVM Setup.</div></div>
</li>
<li>For the prompt <b>Storage configuration</b>, choose <b>Done</b>. <div class="image">
<img src="../../code_build_install_storage_config.png" alt=""/>
<div class="caption">
Figure 3-4. Ubuntu Installation Storage Configuration.</div></div>
</li>
<li>For the <b>Confirm</b> prompt and choose <b>Yes</b>. <div class="image">
<img src="../../code_build_install_confirm_destruct.png" alt=""/>
<div class="caption">
Figure 3-5. Ubuntu Installation Confirm Destructive Action.</div></div>
</li>
<li>At the <b>Profile setup</b> screen, enter the username and password, and choose <b>Done</b>. <div class="image">
<img src="../../code_build_install_profile_setup.png" alt=""/>
<div class="caption">
Figure 3-6. Ubuntu Installation Profile Setup.</div></div>
</li>
<li>At the <b>SSH Setup</b> prompt, select <b>Install OpenSSH server</b> and choose <b>Done</b>. <div class="image">
<img src="../../code_build_install_ssh.png" alt=""/>
<div class="caption">
Figure 3-7. Ubuntu Installation SSH Setup.</div></div>
</li>
<li>The following interface indicates that the installation is complete. <div class="image">
<img src="../../code_build_install_complete.png" alt=""/>
<div class="caption">
Figure 3-8. Ubuntu Installation Complete.</div></div>
</li>
</ol>
<h3><a class="anchor" id="dsub_code_build_set_net"></a>
3.1.3 Ubuntu Network Configuration</h3>
<p >Configure the network with DHCP or static IP.</p>
<ol type="1">
<li>Log in to the server and configure the network according to the machine environment.<ul>
<li>IP Address: $ sudo vim /etc/network/interfaces (edit files …)</li>
<li>DNS server: $ sudo vim /etc/resolv.conf (edit files …)</li>
<li>Restart networking: $ sudo /etc/init.d/networking restart</li>
</ul>
</li>
<li>Use the following command to verify that the network is connected. (Ensure that the root is correct.) <div class="fragment"><div class="line">build $ ping www.google.com</div>
</div><!-- fragment --></li>
</ol>
<dl class="section note"><dt>Note</dt><dd>Users can access another website, such as www.ubuntu.com, to confirm the network connection.</dd></dl>
<h2><a class="anchor" id="sub_code_build_set_dow"></a>
3.2 Install Development Packages</h2>
<p >Users must install several packages before beginning the development process. In the <b>Ambarella release for the Toolchain</b> package, users can locate the installation script to automatically install the required packages.</p>
<p >Ensure that the building workstation has Internet access, then run the scripts below, which are mentioned in the following sections.</p>
<h2><a class="anchor" id="sub_code_build_set_arm"></a>
3.3 Install the Arm® Toolchain</h2>
<p >The toolchain binary is <b>PRO server</b>, which is named <code>Ambarella_CortexA76_Toolchain_GCC*&gt;*_&lt;Date&gt;.tar.xz</code>.</p>
<p >The toolchain source code can be downloaded from the GCC official website and Git. The version and commit ID used in the latest SDK are as follows: </p><pre class="fragment">  GCC: 12.2.1  git://gcc.gnu.org/git/gcc.git
  Revision:  64efeac03cb9fa2603bb6628712f3a2541aef1cb
  GLIBC: 2.37  git://sourceware.org/git/glibc.git
  Revision:  1d63573f81945a489ea169636fa11850bc74716b
  GDB: 13.1   git://sourceware.org/git/binutils-gdb.git
  Revision: b3eff3e15576229af9bae026c5c23ee694b90389
  Binutils: 2.40  git://sourceware.org/git/binutils-gdb.git
  Revision: ded035f913e4d8c989880cf5928b6b5fca9466ae
</pre> <dl class="section note"><dt>Note</dt><dd>The toolchain is often upgraded during SDK development. Refer to the <em>Ambarella Cooper Linux SDK - Release Notes</em> document for the exact toolchain version.</dd></dl>
<p>The following lists the steps for installing Arm Toolchain:</p>
<ol type="1">
<li>Download the toolchain package <code>Ambarella_CortexA76_Toolchain_GCC*.*_&lt;Date&gt;.tar.xz</code> from the PRO server.</li>
<li>Install the toolchain. For Ubuntu Linux, the commands are as follows: <div class="fragment"><div class="line">build $ tar xvfJp Ambarella_CortexA76_Toolchain_GCC*.*_&lt;Date&gt;.tar.xz</div>
<div class="line">build $ cd Ambarella_CortexA76_Toolchain_GCC*.*_&lt;Date&gt;</div>
<div class="line">build $ sudo chmod +<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> ubuntuToolChain-Linux*.*_&lt;Date&gt;</div>
<div class="line">build $ ./ubuntuToolChain-Linux*.*_&lt;Date&gt;</div>
<div class="ttc" id="agroup__IAV_html_gaf80df1bdae91e5f76236e6ed1110825d"><div class="ttname"><a href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a></div><div class="ttdeci">u32 x</div></div>
</div><!-- fragment --></li>
<li>(Optional) Write a simple program and run it on the development platform.<ul>
<li>Create a file hello.c with the following content: <div class="fragment"><div class="line"><span class="preprocessor">#include &lt;stdio.h&gt;</span></div>
<div class="line"><span class="keywordtype">int</span> <a class="code hl_functionRef" target="_blank" href="../../../video/db/d1a/test__vout__cfg_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a>()</div>
<div class="line">{</div>
<div class="line">    printf(<span class="stringliteral">&quot;Hello World!\n&quot;</span>);</div>
<div class="line">    <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
<div class="ttc" id="atest__vout__cfg_8c_html_a3c04138a5bfe5d72780bb7e82a18e627"><div class="ttname"><a href="../../../video/db/d1a/test__vout__cfg_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a></div><div class="ttdeci">int main(int argc, char **argv)</div></div>
</div><!-- fragment --></li>
<li>Compile the file: <div class="fragment"><div class="line">build $ export PATH=$PATH:/usr/local/cortex-a76-2023.04-gcc12.2-linux5.15/bin/</div>
<div class="line">build $ aarch64-linux-gnu-gcc hello.c -o hello</div>
</div><!-- fragment --></li>
<li>Put the executable program "hello" in the development platform and run the following command: <div class="fragment"><div class="line">board # ./hello</div>
<div class="line">Hello World!</div>
</div><!-- fragment --></li>
</ul>
</li>
</ol>
<h2><a class="anchor" id="sub_code_build_set_tool"></a>
3.4 Install the Computer Vision (CV) Toolchain</h2>
<p >There are two CNNGen packages for CVflow_v2 and CVflow_v3, both of which use Ubuntu 2004 system:</p><ul>
<li><code>Ambarella_Toolchain_CNNGen_2.*.*_2023****.tar.xz</code>: used is for CVflow_v2 (CV2x and CV5x) conversion; AmbaCaffe is included for retaining purpose</li>
<li><code>Ambarella_Toolchain_CNNGen_cv7x.3.*.*_2023****.tar.xz</code>: used for CVflow_v3 (CV7x) conversion; users can use the AmbaCaffe in the CVflow_v2 CNNGen toolchain package</li>
</ul>
<p >Before running the installation script for the toolchain, run the following command: </p><div class="fragment"><div class="line">build $ sudo apt-get update</div>
</div><!-- fragment --><p >Users should regularly upgrade the operating system as shown below, as the toolchain is developed using the latest version OS. </p><div class="fragment"><div class="line">Build $ sudo apt-get upgrade</div>
</div><!-- fragment --><p >Although the command above is included in the installation script, Ambarella recommends noting it and assigning it to an independent machine to avoid a possible build conflict.</p>
<p >Install the toolchain as shown below. For Ubuntu Linux, the commands are as follows: </p><div class="fragment"><div class="line">build $ cd Ubuntu-20.04</div>
<div class="line">build $ sudo chmod +<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> ubuntuToolChain-&lt;version&gt;.ubuntu-20.04</div>
<div class="line">build $ ./ubuntuToolChain-&lt;version&gt;.ubuntu-20.04</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>Users can use the official Caffe from <a href="https://github.com/BVLC/caffe.git">https://github.com/BVLC/caffe.git</a> compile, or they can use AmbaCaffe included in the package. Additionally, users can use <code>AmbaCaffe_&lt;version&gt;/build_script/build-caffe-ubuntu20.04-cpu</code> to build both the public Caffe and AmbaCaffe. Note that in the user's system, the user may be required to modify the script. <div class="fragment"><div class="line">build $ git clone https:<span class="comment">//github.com/BVLC/caffe.git</span></div>
<div class="line">build $ cd AmbaCaffe_&lt;version&gt;/</div>
<div class="line">build $ chmod u+<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> ./build_script/build-caffe-ubuntu20.04</div>
<div class="line">build $ ./build_script/build-caffe-ubuntu20.04-cpu caffe</div>
</div><!-- fragment --><ul>
<li>For more details, refer to <code>readme.txt</code> in the CNNGen toolchain package.</li>
</ul>
</dd></dl>
<h2><a class="anchor" id="sub_code_build_set_doc"></a>
3.5 Install the CV Toolchain on Docker</h2>
<p >Docker is an open source, application-container engine that enables developers to package their applications and dependencies into a portable container, then publish or virtualize them to any Linux machine. Containers are completely sandboxed and do not interface with each other. Docker also provides another method for users to deploy and run CNNGen.</p>
<p >The following sections describe how to install the CV Toolchain on Docker.</p>
<p >For more information about Docker, refer to <a href="https://docs.docker.com/">https://docs.docker.com/</a>.</p>
<h3><a class="anchor" id="dsub_code_build_set_ins_doc"></a>
3.5.1 Docker Installation</h3>
<p >Dockers supports a variety of Ubuntu OS versions. Docker can be installed on both physical and virtual machines.</p>
<p >The following steps for installing Docker are for reference only, as users might have systems that require different Docker installations.</p>
<ol type="1">
<li>Install Docker using the following commands: <div class="fragment"><div class="line">build $ sudo apt-get install Docker</div>
<div class="line">build $ sudo apt-get install Docker.io</div>
</div><!-- fragment --></li>
<li><p class="startli">Add the current user to the Docker group and log in again (or reboot if using a virtual machine); otherwise, Docker requires root privilege. </p><div class="fragment"><div class="line">build $ sudo groupadd docker</div>
<div class="line">build $ sudo usermod –aG docker $USER</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>If users must deploy Docker on a server, Ambarella recommends using secure shell (SSH) service for various users, and not adding all users to the Docker group. Docker includes a "sudo" permission, enabling users in this group to add any folder in this server to the Docker container and use "root" to operate it.</dd></dl>
</li>
<li>Use the following command to verify the installation. If the subsequent messages appear, Docker is functioning correctly. <div class="fragment"><div class="line">build $ docker run hello-world</div>
<div class="line">Unable to find image <span class="stringliteral">&#39;hello-world:latest&#39;</span> locally</div>
<div class="line">latest: Pulling from library/hello-world</div>
<div class="line">1b930d010525: Pull complete</div>
<div class="line">Digest: sha256:9572f7cdcee8591948c2963463447a53466950b3fc15a247fcad1917ca215a2f</div>
<div class="line">Status: Downloaded newer image <span class="keywordflow">for</span> hello-world:latest</div>
<div class="line"> </div>
<div class="line">Hello from Docker!</div>
<div class="line">This message shows that your installation appears to be working correctly.</div>
<div class="line"> </div>
<div class="line">To generate <span class="keyword">this</span> message, Docker took the following steps:</div>
<div class="line">  1. The Docker client contacted the Docker daemon.</div>
<div class="line">  2. The Docker daemon pulled the <span class="stringliteral">&quot;hello-world&quot;</span> image from the Docker Hub.</div>
<div class="line">     (amd64)</div>
<div class="line">  3. The Docker daemon created a <span class="keyword">new</span> container from that image which runs the</div>
<div class="line">     executable that produces the output you are currently reading.</div>
<div class="line">  4. The Docker daemon streamed that output to the Docker client, which sent it</div>
<div class="line">     to your terminal.</div>
<div class="line"> </div>
<div class="line">To <span class="keywordflow">try</span> something more ambitious, users can run an Ubuntu container with:</div>
<div class="line">  $ docker run -it ubuntu bash</div>
<div class="line"> </div>
<div class="line">Share images, automate workflows, and more with a free Docker ID:</div>
<div class="line">  https:<span class="comment">//hub.docker.com/</span></div>
<div class="line"> </div>
<div class="line">For more examples and ideas, visit:</div>
<div class="line">  https:<span class="comment">//docs.docker.com/get-started/</span></div>
</div><!-- fragment --></li>
</ol>
<p >Users can then install Ubuntu and CNNGen toolchain with Dockerfile file, as follows. If users used below Docker file to install the environment, please skip the steps in <a class="el" href="../../d9/d98/ov_code_build.html#dsub_code_build_set_ubu_doc">3.5.2 Install Ubuntu on Docker</a>. </p><div class="fragment"><div class="line">build $ docker build -t cv_tool_cpu . -f ./Docker_Files/Dockerfile_CNNGen_&lt;full_version&gt;_ubu2004_CPU</div>
</div><!-- fragment --><p> For more details, refer to the <code>readme.txt</code> in CNNGen Toolchain pacakge. Users can also refer to the following sections to install the package manually.</p>
<h3><a class="anchor" id="dsub_code_build_set_ubu_doc"></a>
3.5.2 Install Ubuntu on Docker</h3>
<p >Docker supports a variety of operating systems and applications running in independent containers. When a container begins, Docker automatically downloads the Docker image from the Docker image repository (if it does not exist locally). The default repository of Docker image is DockerHub.</p>
<p >To create an <b>Ubuntu 20.04</b> container:</p>
<ol type="1">
<li>Pull the Docker image of Ubuntu 20.04 using the following command: <div class="fragment"><div class="line">build $ docker pull ubuntu:focal</div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><ul>
<li>Docker supports many versions of Ubuntu. Users can find the corresponding commands for pulling images from <a href="https://hub.docker.com/_/ubuntu">https://hub.docker.com/_/ubuntu</a>.</li>
<li>If users want to use <b>Cuda</b> in Docker, NVIDIA-Docker should be installed. NVIDIA-Docker is similar in usage to Docker.</li>
<li>Ambarella recommends using Ubuntu 18.04 to run CNNGen.</li>
</ul>
</dd></dl>
</li>
<li>List local images using the following command: <div class="fragment"><div class="line">build $ docker images</div>
<div class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</div>
<div class="line">ubuntu              focal              ccc6e87d482b        3 weeks ago         64.2<a class="code hl_defineRef" target="_blank" href="../../../driver/d6/d56/iav__utils_8h.html#aa6b38d492364d98453284934ed7caee9">MB</a></div>
<div class="ttc" id="aiav__utils_8h_html_aa6b38d492364d98453284934ed7caee9"><div class="ttname"><a href="../../../driver/d6/d56/iav__utils_8h.html#aa6b38d492364d98453284934ed7caee9">MB</a></div><div class="ttdeci">#define MB</div></div>
</div><!-- fragment --></li>
<li>Create a new folder for sharing files between the build machine and the container. Then, start a container and run a terminal as root. Install sudo and vim using the following commands: <div class="fragment"><div class="line">build $ mkdir share_host</div>
<div class="line">build $ docker run -v &lt;Full Path&gt;/share_host:/share_docker -itd --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> ubuntu ubuntu:focal</div>
<div class="line">build $ docker exec -it ubuntu /bin/bash</div>
<div class="line">root # apt-get update</div>
<div class="line">root # apt-get install sudo vim make</div>
<div class="ttc" id="acJSON_8h_html_a25d22ecc7e656d2c59332072684e8766"><div class="ttname"><a href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a></div><div class="ttdeci">const char *const name</div></div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><ul>
<li>The option "-v &lt;Full Path&gt;/share_host:/share_docker" specifies the shared folders. "/share_host" in the build machine requires a full path. "/share_docker" is in the container.</li>
<li>The option "--name ubuntu" specifies the name of container.</li>
<li>The parameter "ubuntu:focal" specifies the Docker image which is pulled by step 1.</li>
</ul>
</dd></dl>
</li>
<li>Add a user account, and add it to the "sudo" group using the following commands: <div class="fragment"><div class="line">root # useradd -d /home/docker -m docker</div>
<div class="line">root # passwd docker</div>
<div class="line">root # usermod -aG sudo docker</div>
</div><!-- fragment --></li>
<li>Exit the terminal, and begin again with a new user account: <div class="fragment"><div class="line">root # exit</div>
<div class="line">build $ docker exec --user docker -it ubuntu /bin/bash</div>
<div class="line">docker $</div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><ul>
<li>The option "--user docker" specifies the username.</li>
<li>The usage above is an example; any name can be used.</li>
<li>For more details about Docker usage, refer to Section <a class="el" href="../../d9/d98/ov_code_build.html#dsub_code_build_set_com_doc">3.5.5 Common Docker Commands</a>.</li>
</ul>
</dd></dl>
</li>
</ol>
<h3><a class="anchor" id="dsub_code_build_set_cnn_doc"></a>
3.5.3 Install CNNGen on Docker</h3>
<p >This section describes installing and setting up the environment for <b>CNNGen</b> in a <b>Docker</b> container.</p>
<ol type="1">
<li>Copy the toolchain package via the shared folders and locate it in the container. Install the toolchain using the following commands: <div class="fragment"><div class="line">docker $ cd Ubuntu-20.04</div>
<div class="line">docker $ sudo chmod +<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> ubuntuToolChain-&lt;version&gt;.ubuntu-20.04</div>
<div class="line">docker $ ./ubuntuToolChain-&lt;version&gt;.ubuntu-20.04</div>
</div><!-- fragment --></li>
<li>Because the image is pulled from DockerHub, which does not include third-party tools, users should install the tools using the following command: <div class="fragment"><div class="line">docker $ sudo apt-get install libncurses5-dev</div>
</div><!-- fragment --></li>
<li>Set the environment for CNNGen, as follows: <div class="fragment"><div class="line">docker $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> /usr/local/amba-cv-tools-&lt;version&gt;.ubuntu-20.04/env/cv&lt;*chip_name*&gt;.env</div>
<div class="ttc" id="avin__init_8c_html_a07a87b2e6ed927503e2f95f119c9fc23"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a></div><div class="ttdeci">int source</div></div>
</div><!-- fragment --></li>
</ol>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>If any of the following installations are unsuccessful, repeatedly run the installed script to ensure successful installation of all programs.</li>
<li>For step 2 in particular, various systems may require different components; if errors occur during installation, follow the error information and install the required components.</li>
<li>For more information about CNNGen, refer to the <em>CNNGen Doxygen Document</em> in the CVflow® CNNGen Samples package.</li>
</ul>
</dd></dl>
<h3><a class="anchor" id="dsub_code_build_set_con_doc"></a>
3.5.4 Close and Save a Container</h3>
<p >To close and save a container:</p>
<ol type="1">
<li>Exit and check a container ID using the following commands: <div class="fragment"><div class="line">docker $ exit</div>
<div class="line">build $ docker ps</div>
<div class="line">CONTAINER ID        IMAGE                      COMMAND             CREATED</div>
<div class="line">64040448833c        bigbrain/ubuntu20:latest   <span class="stringliteral">&quot;/bin/bash&quot;</span>     4 hours ago</div>
</div><!-- fragment --></li>
<li>Save the container as a Docker image using the following commands: <div class="fragment"><div class="line">build $ docker commit &lt;CONTAINER ID&gt; &lt;IMAGE NAME:TAG&gt;</div>
<div class="line"><span class="keywordflow">for</span> example:</div>
<div class="line">build $ docker commit 64040448833c ubuntu:CNNGen</div>
</div><!-- fragment --></li>
<li>To begin a container with the saved Docker image, use the following commands: <div class="fragment"><div class="line">build $ docker images</div>
<div class="line">REPOSITORY          TAG                 IMAGE ID            CREATED            SIZE</div>
<div class="line">ubuntu            cnngen             d94e16b302d1       18 minutes ago     4.21GB</div>
<div class="line">build $ docker run –v /share_host:/share_docker –itd --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> cnngen ubuntu:CNNGen</div>
</div><!-- fragment --></li>
</ol>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>Because the container does not automatically save changes, changes must be saved manually.</li>
<li>For common commands used with Docker, refer to the following section.</li>
</ul>
</dd></dl>
<h3><a class="anchor" id="dsub_code_build_set_com_doc"></a>
3.5.5 Common Docker Commands</h3>
<p >This section provides examples of commonly used Docker commands. For more details about Docker usage, refer to <a href="https://www.docker.com/play-with-docker">https://www.docker.com/play-with-docker</a>.</p>
<ul>
<li>Docker <b>pull</b>: pulls Docker images from DockerHub<ul>
<li>Command <div class="fragment"><div class="line">Build $ docker pull &lt;IMAGE NAME:TAG&gt;</div>
</div><!-- fragment --></li>
<li>Example <div class="fragment"><div class="line">Build $ docker pull ubuntu:latest</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Docker <b>run</b>: starts a new container with an existing Docker image.<ul>
<li>Command: <div class="fragment"><div class="line">Build $ docker pull &lt;IMAGE NAME:TAG&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ docker pull ubuntu:latest</div>
</div><!-- fragment --></li>
<li>Options description: <div class="fragment"><div class="line">-i option: run container in interactive mode.</div>
<div class="line">-t option: assign a fake terminal <span class="keywordflow">for</span> container.</div>
<div class="line">-d option: run container in the background.</div>
<div class="line">--<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> option: specify the Docker image.</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Docker <b>exec</b>: executes an application in a container<ul>
<li>Command: <div class="fragment"><div class="line">Build $ docker exec -it &lt;CONTAINER NAME&gt; &lt;APPLICATION&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ docker exec -it Ubuntu /bin/bash</div>
</div><!-- fragment --></li>
<li>Options description: <div class="fragment"><div class="line">-i option: run container in interactive mode.</div>
<div class="line">-t option: assign a fake terminal <span class="keywordflow">for</span> container</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Docker <b>commit</b>: saves a container as a Docker image<ul>
<li>Command: <div class="fragment"><div class="line">Build $ docker commit &lt;CONTAINER ID&gt; &lt;IMAGE NAME:TAG&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ docker commit cb634ac9eb81 ubuntu:update</div>
</div><!-- fragment --></li>
<li>Options description: <div class="fragment"><div class="line">-a option: add an author <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> of image.</div>
<div class="line">-m option: add description of image.</div>
<div class="line">-p option: pause the container when it is committing</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Docker <b>images</b>: lists local Docker images <div class="fragment"><div class="line">Build $ docker commit &lt;CONTAINER ID&gt; &lt;IMAGE NAME:TAG&gt;</div>
</div><!-- fragment --></li>
<li>Docker <b>ps</b>: lists local containers <div class="fragment"><div class="line">Build $ docker ps (Active containers)</div>
<div class="line">docker ps -a (All containers)</div>
</div><!-- fragment --></li>
<li>Docker <b>stop</b>: stops a container<ul>
<li>Command: <div class="fragment"><div class="line">Build $ docker stop &lt;CONTAINER ID&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ docker stop cb634ac9eb81Options Description</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Docker <b>rm</b>: removes the Docker container<ul>
<li>Command: <div class="fragment"><div class="line">Build $ docker rm &lt;CONTAINER ID&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ docker rm cb634ac9eb81</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Docker <b>rmi</b>: removes the local Docker container<ul>
<li>Command: <div class="fragment"><div class="line">Build $ docker rmi &lt;IMAGE ID&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ docker rmi ccc6e87d482b</div>
</div><!-- fragment --></li>
</ul>
</li>
</ul>
<h2><a class="anchor" id="sub_code_build_set_pod"></a>
3.6 Install the CV Toolchain on Podman</h2>
<p >Podman is an open source management tool for running Linux containers, which is similar to and compatible with Docker. The advantage of Podman is that Podman can run in rootless mode and daemonless mode. Normal users can use Podman to deploy containers in Linux servers.</p>
<p >The following sections describe how to install the CV toolchain on Podman.</p>
<p >For more details about Podman, refer to <a href="https://podman.io/">https://podman.io/</a>.</p>
<h3><a class="anchor" id="dsub_code_build_set_ins_pod"></a>
3.6.1 Podman Installation</h3>
<p >Podman supports a variety of systems for Ubuntu OS. Podman can be installed on both physical and virtual machines.</p>
<p >Refer to the following steps, which are for Podman installation on Focal 20.04. Note that it is only for reference as users might have different system requirements for different Podman installations.</p>
<ol type="1">
<li>For Podman installation commands, refer to <a href="https://podman.io/getting-started/installation">https://podman.io/getting-started/installation</a>.</li>
<li>Use the following command to verify the installation. If the subsequent messages appear, Podman is functioning correctly. <div class="fragment"><div class="line">build $ podman run hello-world</div>
<div class="line">Resolved <span class="stringliteral">&quot;hello-world&quot;</span> as an alias (/etc/containers/registries.conf.d/000-shortnames.conf)</div>
<div class="line">Trying to pull docker.io/library/hello-world:latest...</div>
<div class="line">Getting image source signatures</div>
<div class="line">Copying blob b8dfde127a29 done</div>
<div class="line">Copying config d1165f2212 done</div>
<div class="line">Writing manifest to image destination</div>
<div class="line">Storing signatures</div>
<div class="line"> </div>
<div class="line">Hello from Docker!</div>
<div class="line">This message shows that your installation appears to be working correctly.</div>
<div class="line"> </div>
<div class="line">To generate this message, Docker took the following steps:</div>
<div class="line">  1. The Docker client contacted the Docker daemon.</div>
<div class="line">  2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub.</div>
<div class="line">     (amd64)</div>
<div class="line">  3. The Docker daemon created a new container from that image which runs the</div>
<div class="line">     executable that produces the output you are currently reading.</div>
<div class="line">  4. The Docker daemon streamed that output to the Docker client, which sent it</div>
<div class="line">     to your terminal.</div>
<div class="line"> </div>
<div class="line">To try something more ambitious, you can run an Ubuntu container with:</div>
<div class="line">  $ docker run -it ubuntu bash</div>
<div class="line"> </div>
<div class="line">Share images, automate workflows, and more with a free Docker ID:</div>
<div class="line">  https:<span class="comment">//hub.docker.com/</span></div>
<div class="line"> </div>
<div class="line">For more examples and ideas, visit:</div>
<div class="line">  https:<span class="comment">//docs.docker.com/get-started/</span></div>
</div><!-- fragment --></li>
</ol>
<p >Next, users can install the Ubuntu and CNNGen toolchains with Dockerfile file, as shown below. If users used below Docker file to install the environment, please skip the steps in <a class="el" href="../../d9/d98/ov_code_build.html#dsub_code_build_set_ubu_pod">3.6.2 Install Ubuntu on Podman</a>. </p><div class="fragment"><div class="line">build $ podman build -t cv_tool_cpu . -f ./Docker_Files/Dockerfile_CNNGen_&lt;full_version&gt;_ubu2004_CPU</div>
</div><!-- fragment --><p> For more details, refer to <code>readme.txt</code> in the CNNGen toolchain pacakge. Users can refer to the following sections to install the program manually.</p>
<h3><a class="anchor" id="dsub_code_build_set_ubu_pod"></a>
3.6.2 Install Ubuntu on Podman</h3>
<p >Podman supports various OSs and applications running in independent containers. When a container begins, Podman automatically downloads the Docker image from DockerHub (if it does not exist locally).</p>
<p >To create an <b>Ubuntu 20.04</b> container:</p>
<ol type="1">
<li>Pull Ubuntu 20.04 Docker image using the following command: <div class="fragment"><div class="line">build $ podman pull ubuntu:focal</div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><ul>
<li>Podman supports many versions of Ubuntu. Users can find the corresponding commands for pulling images from <a href="https://hub.docker.com/_/ubuntu">https://hub.docker.com/_/ubuntu</a>.</li>
<li>To run CNNGen, Ambarella recommends using Ubuntu 20.04.</li>
</ul>
</dd></dl>
</li>
<li>List local images using the following command: <div class="fragment"><div class="line">build $ podman images</div>
<div class="line">REPOSITORY                      TAG          IMAGE ID             CREATED            SIZE</div>
<div class="line">docker.io/library/ubuntu       focal       81bcf752ac3d       6 days ago         65.5<a class="code hl_defineRef" target="_blank" href="../../../driver/d6/d56/iav__utils_8h.html#aa6b38d492364d98453284934ed7caee9">MB</a></div>
</div><!-- fragment --></li>
<li>Create a new folder for sharing files between the build machine and the container. Start a container, then run a terminal as root. Install sudo and vim using the following commands: <div class="fragment"><div class="line">build $ mkdir share_host</div>
<div class="line">build $ podman run -v &lt;Full Path&gt;/share_host:/share_podman -itd --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> ubuntu ubuntu:focal</div>
<div class="line">build $ podman exec -it ubuntu /bin/bash</div>
<div class="line">root # apt-get update</div>
<div class="line">root # apt-get install sudo vim make</div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><ul>
<li>The option "-v &lt;Full Path&gt;/share_host:/share_podman" specifies the shared folders. "/share_host" is in the build machine and requires a full path. "/share_podman" is in the container.</li>
<li>The option "--name ubuntu" specifies the name of container.</li>
<li>The parameter "ubuntu:focal" specifies the Docker image, which is pulled by step 1.</li>
</ul>
</dd></dl>
</li>
<li>Add a user account, and add it to the "sudo" group using the following commands. <div class="fragment"><div class="line">root # useradd -d /home/podman -m podman</div>
<div class="line">root # passwd podman</div>
<div class="line">root # usermod -aG sudo podman</div>
</div><!-- fragment --></li>
<li>Exit the terminal, and restart with a new user account: <div class="fragment"><div class="line">root # exit</div>
<div class="line">build $ podman exec --user podman -it ubuntu /bin/bash</div>
<div class="line">podman $</div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><ul>
<li>The option "--user podman" specifies the user name.</li>
<li>The usage above is an example; customers can use any name.</li>
<li>For more details about Podman usage, refer to Section <a class="el" href="../../d9/d98/ov_code_build.html#dsub_code_build_set_com_pod">3.6.5 Common Podman Commands</a>.</li>
</ul>
</dd></dl>
</li>
</ol>
<h3><a class="anchor" id="dsub_code_build_set_cnn_pod"></a>
3.6.3 Install CNNGen on Podman</h3>
<p >This section describes how to install and set up the environment for <b>CNNGen</b> in a <b>Podman</b> container.</p>
<ol type="1">
<li>Copy the toolchain package via the shared folders and locate it in the container. Install the toolchain using the following commands: <div class="fragment"><div class="line">podman $ cd Ubuntu-20.04</div>
<div class="line">podman $ sudo chmod +<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> ubuntuToolChain-&lt;version&gt;.ubuntu-20.04</div>
<div class="line">podman $ ./ubuntuToolChain-&lt;version&gt;.ubuntu-20.04</div>
</div><!-- fragment --></li>
<li>Because the image is pulled from DockerHub, which does not include third-party tools, users should install the tools using the following command: <div class="fragment"><div class="line">podman $ sudo apt-get install libncurses5-dev</div>
</div><!-- fragment --></li>
<li>Set the environment for CNNGen as follows: <div class="fragment"><div class="line">podman $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> /usr/local/amba-cv-tools-&lt;version&gt;.ubuntu-20.04/env/cv&lt;*chip_name*&gt;.env</div>
</div><!-- fragment --></li>
</ol>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>If any of the following installations are unsuccessful, repeatedly run the installed script to ensure successful installation of all programs.</li>
<li>For steps 2 and 3 in particular, various systems might require different components; if errors occur during installation, follow the error information and install the required components.</li>
<li>For more information about CNNGen, refer to the <em>CNNGen Doxygen Document</em> in the CVflow CNNGen Samples package.</li>
</ul>
</dd></dl>
<h3><a class="anchor" id="dsub_code_build_set_con_pod"></a>
3.6.4 Close and Save a Container</h3>
<p >To close and save a container:</p>
<ol type="1">
<li>Exit and check the container ID using the following commands: <div class="fragment"><div class="line">podman $ exit</div>
<div class="line">build $ podman ps</div>
<div class="line">CONTAINER ID     IMAGE                              COMMAND    CREATED       STATUS</div>
<div class="line">2335bf51b43e  docker.io/library/ubuntu:bionic  /bin/bash  4 hours ago  Up</div>
</div><!-- fragment --></li>
<li>Save the container as a Docker image using the following commands: <div class="fragment"><div class="line">build $ podman commit &lt;CONTAINER ID&gt; &lt;IMAGE NAME:TAG&gt;</div>
<div class="line"><span class="keywordflow">for</span> example:</div>
<div class="line">build $ podman commit 2335bf51b43e ubuntu:CNNGen</div>
</div><!-- fragment --></li>
<li>To initialize a container with the saved Podman image, use the following commands: <div class="fragment"><div class="line">build $ podman images</div>
<div class="line">REPOSITORY                       TAG           IMAGE ID           CREATED             SIZE</div>
<div class="line">Docker.io/library/ubuntu    CNNGen       0db979ef8578       3 hours ago        1.65GB</div>
<div class="line">build $ podman run –v /share_host:/share_podman –itd --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> cnngen ubuntu:CNNGen</div>
</div><!-- fragment --></li>
</ol>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>As Podman does not automatically save system modifications, users must save them manually.</li>
<li>For common commands in Podman, refer to Section <a class="el" href="../../d9/d98/ov_code_build.html#dsub_code_build_set_com_pod">3.6.5 Common Podman Commands</a>.</li>
</ul>
</dd></dl>
<h3><a class="anchor" id="dsub_code_build_set_com_pod"></a>
3.6.5 Common Podman Commands</h3>
<p >This section provides examples of commonly-used Podman commands. For more further details about Podman usage, refer to <a href="http://docs.podman.io/en/latest/Commands.html">http://docs.podman.io/en/latest/Commands.html</a>.</p><ul>
<li>Podman <b>Pull</b>: pulls Docker images from DockerHub<ul>
<li>Command: <div class="fragment"><div class="line">Build $ podman pull &lt;IMAGE NAME:TAG&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ podman pull ubuntu:latest</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Podman <b>Run</b>: starts a new container with an existing Podman image<ul>
<li>Command: <div class="fragment"><div class="line">Build $ podman run -itd --name &lt;CONTAINER NAME&gt; &lt;IMAGE NAME&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ podman run -itd --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> Ubuntu ubuntu:latest</div>
</div><!-- fragment --></li>
<li>Options description: <div class="fragment"><div class="line">-i option: run container in interactive mode.</div>
<div class="line">-t option: assign a fake terminal <span class="keywordflow">for</span> container.</div>
<div class="line">-d option: run container in the background.</div>
<div class="line">--<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> option: specify the Docker image.</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Podman <b>exec</b>: executes an application in a container<ul>
<li>Command: <div class="fragment"><div class="line">Build $ podman exec -it &lt;CONTAINER NAME&gt; &lt;APPLICATION&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ podman exec -it Ubuntu /bin/bash</div>
</div><!-- fragment --></li>
<li>Options description: <div class="fragment"><div class="line">-i option: run container in interactive mode.</div>
<div class="line">-t option: assign a fake terminal <span class="keywordflow">for</span> container</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Podman <b>commit</b>: saves a container as a Docker image<ul>
<li>Command: <div class="fragment"><div class="line">Build $ podman commit &lt;CONTAINER ID&gt; &lt;IMAGE NAME:TAG&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ podman commit cb634ac9eb81 ubuntu:update</div>
</div><!-- fragment --></li>
<li>Options description: <div class="fragment"><div class="line">-a option: add an author <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> of image.</div>
<div class="line">-m option: add description of image.</div>
<div class="line">-p option: pause the container when it is committing</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Podman <b>images</b>: lists local Docker images <div class="fragment"><div class="line">Build $ docker commit &lt;CONTAINER ID&gt; &lt;IMAGE NAME:TAG&gt;</div>
</div><!-- fragment --></li>
<li>Podman <b>ps</b>: lists local containers <div class="fragment"><div class="line">Build $ podman ps (Active containers)</div>
<div class="line">podman ps -a (All containers)</div>
</div><!-- fragment --></li>
<li>Podman <b>stop</b>: stops a container<ul>
<li>Command: <div class="fragment"><div class="line">Build $ podman stop &lt;CONTAINER ID&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ podman stop cb634ac9eb81</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Podman <b>rm</b>: removes local Podman containers<ul>
<li>Command: <div class="fragment"><div class="line">Build $ podman rm &lt;CONTAINER ID&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ podman rm cb634ac9eb81</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Podman <b>rmi</b>: removes local images<ul>
<li>Command: <div class="fragment"><div class="line">Build $ podman rmi &lt;IMAGE ID&gt;</div>
</div><!-- fragment --></li>
<li>Example: <div class="fragment"><div class="line">Build $ podman rmi ccc6e87d482b</div>
</div><!-- fragment --></li>
</ul>
</li>
</ul>
<hr  />
<h1><a class="anchor" id="code_build_full_sdk"></a>
4. Build Full SDK Code</h1>
<p >This chapter includes the following sections: </p><ul>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_full_down">4.1 Download the SDK Package</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_full_import">4.2 Important SDK Folders</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_full_build">4.3 Build Firmware</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_full_cus">4.4 Customize the Build Configuration</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_full_make">4.5 Make Target Options</a> </li>
</ul>
<h2><a class="anchor" id="sub_code_build_full_down"></a>
4.1 Download the SDK Package</h2>
<p >To allow access to the Cooper SDK tarred files, Ambarella provides users with a file transfer protocol (FTP) account and directions for logging in to the Ambarella FTP server using an account password. Users should not modify the SDK within the download directory. If users must modify the SDK, Ambarella recommends making a copy of the SDK and using the copied version instead.</p>
<p >The Ambarella Cooper Linux SDK code package includes:</p><ul>
<li><b>cooper_linux_sdk</b>: This SDK is the formal release and contains the reference application, static / dynamic library files, private drivers, Linux kernel, and file system.</li>
<li><b>Patches</b> (Optional): This part contains the patches to the formal package.</li>
</ul>
<p >Users can access an example (with no patches provided) using the Cooper SDK release file cooper_linux_sdk_******.tar.xz.</p>
<h2><a class="anchor" id="sub_code_build_full_import"></a>
4.2 Important SDK Folders</h2>
<p >The folders listed in this section include the locations of several important components of the SDK. To learn more information about a component, refer to the documents listed below.</p>
<ul>
<li><code>ambarella/drv_modules/private/video/dsp_v6/iav</code>: includes all DSP-related application programming interface (API) codes used for the video process pipeline. Related Ambarella documentation includes the following:<ul>
<li>Page <a class="elRef" target="_blank" href="../../../video/d3/dc4/fd_adv_multi_vin.html">Multi-VIN Design</a></li>
<li><em>AMBA Flexible Linux SDK Document Doxygen</em></li>
</ul>
</li>
<li><code>ambarella/unit_test/private/iav_test</code>: this folder contains the demo applications for testing the DSP. Related Ambarella documentation includes the following:<ul>
<li>Page <a class="el" href="../../d7/d6c/page_getting_start_guide.html">Getting Started Guide</a></li>
<li><em>AMBA Cooper Linux SDK Document Doxygen Feature Sets</em></li>
</ul>
</li>
<li><code>ambarella/drv_modules/private/cavalry</code>: this folder includes the Cavalry-related API codes used for convolutional neural network (CNN) network cases. Related Ambarella documentation is in the <em>SDK Doxygen document of the SDK package</em>.</li>
<li><code>ambarella/packages/vproc</code>: this folder includes the VProc code used to prepare the network input frame. Related Ambarella documentation is in the <em>SDK Doxygen document of the SDK package</em>.</li>
<li><code>ambarella/packages/nnctrl</code>: this folder includes the NNCtrl code used to load the Cavalry binary converted by the CNNGen tool. Related Ambarella documentation is in the <em>SDK Doxygen document of the SDK package</em>.</li>
<li><code>ambarella/packages/cavalry_mem</code>: this folder includes the Cavalry memory code used to allocate memory for Cavalry cases. Related Ambarella documentation is in the <em>SDK Doxygen document of the SDK package</em>. This folder uses APIs found in the continuous memory allocator (CMA) function.</li>
<li><code>ambarella/unit_test/private/cv_test</code>: this folder includes the demo application for testing CVflow® applications. Related Ambarella documentation includes<ul>
<li>Page <a class="el" href="../../d7/d6c/page_getting_start_guide.html">Getting Started Guide</a></li>
<li><em>Doxygen document of CNNGen Samples package</em></li>
</ul>
</li>
<li><code>ambarella/prebuild/library/idsp</code>: this folder contains relevant information about the image process library. For more details, refer to Page <a class="elRef" target="_blank" href="../../../library/d7/de0/page_lib_img_doc.html">Image Library API</a></li>
<li><code>ambarella/packages/security</code>: this folder includes all of the codes related to security functions. Related Ambarella documentation includes <em>Ambarella CV5x DG Flexible Linux SDK Security Features</em>.</li>
<li><code>ambarella/prebuild/ambarella/library/dewarp</code>: this folder includes the prebuild library for dewarp. Related Ambarella documentation includes<ul>
<li>Page <a class="elRef" target="_blank" href="../../../library/da/d8b/page_lib_dewarp_doc.html">Dewarp Library API</a></li>
<li><em>AMBA Cooper Linux SDK Document Doxygen Feature Sets</em></li>
</ul>
</li>
<li><code>ambarella/prebuild/library/eis</code>: this folder holds the electronic image stabilization (EIS) prebuild library. For more details, refer to Page <a class="elRef" target="_blank" href="../../../library/d6/db6/page_lib_eis_doc.html">EIS Library API</a>.</li>
<li><code>ambarella/drv_modules/private/video/dsp_v6/ambcma</code>: this folder contains all of the information about the CMA function. For more details, refer to Page <a class="elRef" target="_blank" href="../../../driver/d8/d84/page_drv_cma_doc.html">CMA Driver API</a>.</li>
</ul>
<h2><a class="anchor" id="sub_code_build_full_build"></a>
4.3 Build Firmware</h2>
<p >Follow the steps below to build the flexible Linux SDK.</p>
<ol type="1">
<li>Extract the SDK package <code>cooper_linux_sdk_xxxxxx.tar.xz</code>. <div class="fragment"><div class="line">build $ tar xvfJp cooper_linux_sdk_********.tar.xz</div>
<div class="line">build $ cd cooper_linux_sdk_*</div>
</div><!-- fragment --></li>
<li>Configure the <b>Arm® Toolchain</b> under <code>ambarella/</code>.</li>
</ol>
<ul>
<li>amba-build <div class="fragment"><div class="line">build $ cd ambarella</div>
<div class="line">build $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> build/env/amba-build.env</div>
</div><!-- fragment --></li>
<li>yocto-build <div class="fragment"><div class="line">build $ cd ambarella</div>
<div class="line">build $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> build/env/yocto-build.env</div>
</div><!-- fragment --></li>
</ul>
<ol type="1">
<li>Configure the image under <code>boards/&lt;board_type&gt;</code>.<ul>
<li>For example, to build the CV5x /CV7x IP camera firmware, use the following commands: <div class="fragment"><div class="line">build $ cd boards/&lt;board_type&gt;</div>
<div class="line">build $ ls -al config/amba/</div>
<div class="line">(Or build $ ls -al config/yocto/)</div>
<div class="line">build $ make ipcam_config</div>
<div class="line">build $ make</div>
</div><!-- fragment --></li>
<li>Refer to Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_full_cus">4.4 Customize the Build Configuration</a> for details on how to customize the compile configuration.</li>
</ul>
</li>
<li>Build the firmware. <div class="fragment"><div class="line">build $ make</div>
</div><!-- fragment --> If the build system has multi-core CPUs, use the "-jN" option to reduce the building time. Users can use the command <b>"nproc"</b> to get the number of CPU cores. For example, if using eight-core CPUs, use the following command: <div class="fragment"><div class="line">build $ make -j8</div>
</div><!-- fragment --></li>
<li>After the building process is complete, the image is located at: <div class="fragment"><div class="line">../../&lt;build_type&gt;_out/&lt;board_type&gt;/firmware/bst_bld_*_kernel_*_release.bin.</div>
</div><!-- fragment --> For example, the built firmware for CV5x IP camera EVK board is located at: <div class="fragment"><div class="line">../../&lt;build_type&gt;_out/cv5x_&lt;board_name&gt;/firmware/bst_bld_kernel_lnx_release.bin (or bst_bld_atf_kernel_lnx_release.bin).</div>
</div><!-- fragment --> And the built firmware for CV7x IP camera EVK board is located at: <div class="fragment"><div class="line">../../&lt;build_type&gt;_out/cv7x_&lt;board_name&gt;/firmware/bst_bld_env_dtb_kernel_rootfs_release.bin.</div>
</div><!-- fragment --></li>
<li>Upgrade the image to the board. Refer to Chapter <a class="el" href="../../d9/d98/ov_code_build.html#code_build_upgrade">7. Upgrade the Firmware to the Development Platform</a>.</li>
</ol>
<h2><a class="anchor" id="sub_code_build_full_cus"></a>
4.4 Customize the Build Configuration</h2>
<h3><a class="anchor" id="dsub_code_build_full_amba"></a>
4.4.1 Modify the Ambarella Add-Ons Configuration</h3>
<p >To remove the Ambarella add-on libraries, drivers, or applications, follow these steps:</p>
<ol type="1">
<li>Go to ambarella/boards/&lt;board_type&gt; folder. <div class="fragment"><div class="line">build $ cd ambarella/boards/cv5x_&lt;board_name&gt;</div>
<div class="line">(Or build $ cd ambarella/boards/cv7x_&lt;board_name&gt;)</div>
</div><!-- fragment --></li>
<li>Clean the previous target template. <div class="fragment"><div class="line">build $ make clean</div>
</div><!-- fragment --></li>
<li>Apply the default Ambarella configuration or chip-related configuration files. The different configuration files for various chips and the build binary show different clock frequencies and performances. <div class="fragment"><div class="line">build $ ls -al config/amba/</div>
<div class="line">build $ make ipcam_config</div>
</div><!-- fragment --></li>
<li>Display and modify the kernel configuration according to the product requirement. <div class="fragment"><div class="line">build $ make menuconfig</div>
</div><!-- fragment --></li>
<li>Rebuild the firmware. See Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_full_make">4.5 Make Target Options</a> for details on compiling specific targets. <div class="fragment"><div class="line">build $ make -j8</div>
</div><!-- fragment --></li>
</ol>
<h3><a class="anchor" id="dsub_code_build_full_linux"></a>
4.4.2 Modify the Linux Kernel Configuration</h3>
<p >To modify the Linux kernel configuration, follow these steps:</p>
<ol type="1">
<li>Go to <code>ambarella/boards/&lt;board_type&gt;</code> folder. <div class="fragment"><div class="line">build $ cd ambarella/boards/cv5x_&lt;board_name&gt;</div>
<div class="line">(Or build $ cd ambarella/boards/cv7x_&lt;board_name&gt;)</div>
</div><!-- fragment --></li>
<li>Clean up the old target template. <div class="fragment"><div class="line">build $ make clean</div>
</div><!-- fragment --></li>
<li>Apply the default kernel configuration. <div class="fragment"><div class="line">build $ make linux_defconfig</div>
</div><!-- fragment --></li>
<li>Display and modify the kernel configuration according to the requirements. <div class="fragment"><div class="line">build $ make linux_menuconfig</div>
</div><!-- fragment --></li>
<li>Create the specific kernel configuration. Below example is with amba-build method. <div class="fragment"><div class="line">build $ mkdir config/kernel</div>
<div class="line">build $ cp -dpRf ../../amba_out/cv5x_&lt;board_name&gt;/kernel/linux-5.15_cv5x/.config config/kernel/ambarella_xxx_config</div>
<div class="line">(Or build $ cp -dpRf ../../amba_out/cv7x_&lt;board_name&gt;/kernel/linux-5.15_cv7x/.config config/kernel/ambarella_xxx_config)</div>
<div class="line">build $ make menuconfig</div>
<div class="line">    kernel  ---&gt;</div>
<div class="line">        [*] linux (kernel)  ---&gt;</div>
<div class="line">            (ambarella_xxx_config) Linux Default Configuration</div>
</div><!-- fragment --></li>
<li>Rebuild the firmware. <div class="fragment"><div class="line">build $ make -j8</div>
</div><!-- fragment --></li>
</ol>
<h2><a class="anchor" id="sub_code_build_full_make"></a>
4.5 Make Target Options</h2>
<p >The make commands are as follows: </p><a class="anchor" id="code_build_make_command"></a>
<table class="doxtable">
<caption>Table 4-1. Building Commands.</caption>
<tr>
<th>Command </th><th>Content </th></tr>
<tr>
<td>make &lt;Tab&gt; &lt;Tab&gt; </td><td>Lists the supported targets </td></tr>
<tr>
<td>make &lt;Target&gt; </td><td>Compiles a specific target </td></tr>
<tr>
<td>make -jN </td><td>Builds with the multi-core CPUs </td></tr>
</table>
<p >The following target options are examples of the most commonly used targets: </p><a class="anchor" id="code_build_make_targets"></a>
<table class="doxtable">
<caption>Table 4-2. Building Targets.</caption>
<tr>
<th>Command </th><th>Target </th></tr>
<tr>
<td>make linux_defconfig </td><td>Apply the default kernel configuration </td></tr>
<tr>
<td>make linux_menuconfig </td><td>Display the kernel menuconfig </td></tr>
<tr>
<td>make menuconfig </td><td>Display the menuconfig </td></tr>
<tr>
<td>make boot </td><td>Build AMBoot </td></tr>
<tr>
<td>make linux </td><td>Build the Linux kernel </td></tr>
<tr>
<td>make kernel-module-ambvideo </td><td>Build the private video drivers </td></tr>
<tr>
<td>make clean kernel-module-ambvideo </td><td>Clean the private video drivers </td></tr>
<tr>
<td>make clean </td><td>Delete the directory </td></tr>
<tr>
<td>make distclean </td><td>Delete all temporary objects in compilation </td></tr>
<tr>
<td>make iav-test </td><td>Compile the IAV unit test tools, such as test_encode </td></tr>
<tr>
<td>make idsp-test </td><td>Compile the IDSP unit test toos, such as test_aaa_service </td></tr>
<tr>
<td>make lwmedia-test </td><td>Compile the media test tools, such as rtsp_server </td></tr>
<tr>
<td>make libimgflow </td><td>Compile the library libimgflow.so </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="code_build_eva_sdk"></a>
5. Build Evaluation SDK Code</h1>
<p >This chapter includes the following sections: </p><ul>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_eva_down">5.1 Download SDK Package</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_eva_build">5.2 Build Application</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_eva_run">5.3 Run Application</a> </li>
</ul>
<h2><a class="anchor" id="sub_code_build_eva_down"></a>
5.1 Download SDK Package</h2>
<p >To enable access to the Cooper SDK tarred files, Ambarella provides users with an FTP account and directions for logging in to the Ambarella FTP server using an account password. Users should not modify the SDK within the download directory. If users must modify the SDK, Ambarella recommends making a copy of the SDK and using the copied version instead.</p>
<p >The Ambarella Cooper Linux SDK evaluation code package includes:</p>
<ul>
<li><b>cooper_linux_evaluation_sdk</b>: This SDK is the formal release and contains all reference applications, the static / dynamic library files, and the header files.</li>
</ul>
<h2><a class="anchor" id="sub_code_build_eva_build"></a>
5.2 Build Application</h2>
<p >To build the application, follow the steps below:</p>
<ol type="1">
<li>Extract the formal SDK package <code>cooper_linux_evaluation_sdk__xxxxxx.tar.xz</code>. <div class="fragment"><div class="line">build $ tar xvfJp cooper_linux_evaluation_sdk_********.tar.xz</div>
<div class="line">build $ cd cooper_linux_evaluation_sdk_*</div>
</div><!-- fragment --></li>
<li>Configure the Arm® Toolchain.</li>
</ol>
<ul>
<li>amba-build <div class="fragment"><div class="line">build $ cd ambarella</div>
<div class="line">build $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> build/env/amba-build.env</div>
</div><!-- fragment --></li>
</ul>
<ol type="1">
<li>Configure the image under <code>boards/&lt;board_type&gt;</code>.</li>
</ol>
<ul>
<li>For Cooper Amba build: <div class="fragment"><div class="line">build $ cd boards/&lt;board_name&gt;</div>
<div class="line">build $ make ipcam_config</div>
<div class="line">build $ make menuconfig</div>
<div class="line">    drv_modules  ---&gt;</div>
<div class="line">         <span class="keyword">private</span>  ---&gt;</div>
<div class="line">          -*- ambvideo-header (drv_modules/<span class="keyword">private</span>/video/dsp_v6)  ---&gt;</div>
<div class="line">              (4)   Max VIN Channel Number</div>
<div class="line">build $ make &lt;app_name&gt;</div>
</div><!-- fragment --></li>
</ul>
<ol type="1">
<li>Upload the application and files to board as this package has no Linux kernel or file system. The application can be found in <code>ambarella/amba_out/cv5x_&lt;board_name&gt;/sysroot/usr/local/bin/&lt;app_name&gt;</code> or <code>ambarella/amba_out/cv7x_&lt;board_name&gt;/sysroot/usr/local/bin/&lt;app_name&gt;</code>.</li>
</ol>
<h2><a class="anchor" id="sub_code_build_eva_run"></a>
5.3 Run Application</h2>
<p >For more information about running the application, refer to the page <a class="el" href="../../d7/d6c/page_getting_start_guide.html">Getting Started Guide</a>.</p>
<hr  />
<h1><a class="anchor" id="code_build_setup_pc"></a>
6. Set Up the PC</h1>
<p >The <b>SSH</b> and <b>Telnet</b> tools are used to access the build machine and the development platform. <b>AmbaUSB</b> is used to upgrade the firmware to the development platform from the PC.</p>
<p >This chapter includes the following sections: </p><ul>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_pc_con">6.1 Connect to a Console Window - PuTTY</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_pc_up">6.2 Upgrade Firmware - AmbaUSB</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_pc_linux">6.3 Linux Virtual Machine</a> </li>
<li>
Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_pc_cifs">6.4 Network Sharing: CIFS</a> </li>
<li>
Section sub_code_build_pc_nfs </li>
</ul>
<h2><a class="anchor" id="sub_code_build_pc_con"></a>
6.1 Connect to a Console Window - PuTTY</h2>
<p >Ambarella recommends using the <b>SSH</b> and Telnet tool <b>PuTTY</b> from <a href="http://www.PuTTY.org">http://www.PuTTY.org</a> to connect to a console window. The <b>PuTTY</b> executable and source code is distributed under the Massachusetts Institute of Technology (MIT) license.</p>
<p >To connect to a console window, use the RS232 serial cable included with the SDK. If the cable is not available, use a female-to-female RS232 receiver / transmitter (RX / TX) crossover cable instead.</p>
<ol type="1">
<li>Run <b>putty.exe</b>. For a serial connection, configure PuTTY as follows and as shown in the following figures:<ul>
<li>Speed (baud rate in bits per second): <b>115200</b></li>
<li>Data Bits: <b>8</b></li>
<li>Parity: <b>None</b></li>
<li>Stop Bits: <b>1</b></li>
<li>Flow Control: <b>None</b></li>
</ul>
</li>
</ol>
<div class="image">
<img src="../../getting_guide_serial_conf_1.png" alt=""/>
<div class="caption">
Figure 6-1. PuTTY Serial Configuration (1).</div></div>
<ol type="1">
<li>From the PuTTY Configuration dialog, choose <b>Category &gt; Connection &gt; Serial</b> and for <b>Serial line to Connect To</b>, enter the correct port (for example, COM1). For <b>Speed, Data Bits, Parity, Stop Bits, and Flow Control</b>, use the settings above.</li>
<li>From <b>Category &gt; Session</b> in the PuTTY Configuration dialog, choose <b>Serial</b> for <b>Connection Type</b>. Set <b>Serial Line</b> to <b>COM1</b> and <b>Speed</b> to <b>115200</b>. Save the current session (for example, Amba Serial in Figure 6-2), so that it can be reused. <div class="image">
<img src="../../getting_guide_serial_conf_2.png" alt=""/>
<div class="caption">
Figure 6-2. PuTTY Serial Configuration (2).</div></div>
</li>
</ol>
<h2><a class="anchor" id="sub_code_build_pc_up"></a>
6.2 Upgrade Firmware - AmbaUSB</h2>
<p ><b>AmbaUSB</b> is the tool which enables users to upgrade the platform on the <b>Ubuntu</b> / Windows PC through the USB. The installation programs can be found in the folder <code>Tools/AmbaUSB</code>, and include 32-bit and 64-bit PC versions.</p>
<p ><b>OS Requirement</b>: 18.04 LTS / 20.04 LTS, Windows 7 32-bit / 64-bit</p>
<p >Select the appropriate OS and double-click the program to begin installation.</p>
<h2><a class="anchor" id="sub_code_build_pc_linux"></a>
6.3 Linux Virtual Machine</h2>
<p >Ambarella recommends installing the Linux virtual machine on the Windows PC to enable direct access to the Linux development platform. For more details on setting up network sharing between the build machine, a Windows PC, and the development platform, see Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_pc_cifs">6.4 Network Sharing: CIFS</a>.</p>
<p >This section provides instructions to install Ubuntu on Windows using virtualization software, such as VirtualBox. <b>VirtualBox</b> is freely available and recommended by Ambarella.</p>
<p >The following instructions use VirtualBox to install Ubuntu on Windows.</p>
<ol type="1">
<li>Obtain the VirtualBox and Ubuntu 20.04 LTS disk images.<ul>
<li>VirtualBox downloading page: <a href="https://www.virtualbox.org/wiki/Downloads">https://www.virtualbox.org/wiki/Downloads</a></li>
<li>Ubuntu 20.04 LTS: <a href="http://www.ubuntu.com/download/ubuntu/download">http://www.ubuntu.com/download/ubuntu/download</a></li>
</ul>
</li>
<li>Create a virtual machine.<ul>
<li>After launching VirtualBox, click <b>New</b> to create a new virtual machine (VM). <div class="image">
<img src="../../code_build_vm_new.png" alt=""/>
<div class="caption">
Figure 6-3. Create a New VM.</div></div>
</li>
<li>VM Name and OS Type<ul>
<li><b>Name</b>: (whatever the developer likes)</li>
<li><b>Operating System</b>: Linux</li>
<li><b>Version</b>: Ubuntu <div class="image">
<img src="../../code_build_vm_name_os.png" alt=""/>
<div class="caption">
Figure 6-4. VM Name and OS Type.</div></div>
</li>
</ul>
</li>
<li>Memory<ul>
<li>If the RAM on the machine used for development is less than 1 GB, Ambarella recommends using VirtualBox. Note that if the RAM exceeds 1 GB, only a quarter of RAM will be accessed. <div class="image">
<img src="../../code_build_vm_ram.png" alt=""/>
<div class="caption">
Figure 6-5. Memory Size.</div></div>
</li>
</ul>
</li>
<li>Virtual hard disk (VHD)<ul>
<li>Select <b>Create a new hard disk</b>, click <b>Create</b>, choose <b>VHD</b>, and then click <b>Next</b>. <div class="image">
<img src="../../code_build_vm_vhd.png" alt=""/>
<div class="caption">
Figure 6-6. Hard Disk File Type.</div></div>
</li>
</ul>
</li>
<li>Hard disk storage type<ul>
<li>Both <b>dynamically expanding storage</b> and <b>fixed-size storage</b> can be used. <div class="image">
<img src="../../code_build_vm_storage.png" alt=""/>
<div class="caption">
Figure 6-7. Storage on Physical Hard Disk.</div></div>
</li>
</ul>
</li>
<li>Virtual disk location and size<ul>
<li>Using the default values is acceptable: more than <b>40 GB</b> is suggested <div class="image">
<img src="../../code_build_vm_loc_size.png" alt=""/>
<div class="caption">
Figure 6-8. File Location and Size.</div></div>
</li>
</ul>
</li>
</ul>
</li>
<li>Configure the virtual machine.<ul>
<li>Click <b>Settings &gt; Storage &gt; Empty</b> under the Controller: IDE. Next to the <b>Optical Drive</b>, click <b>Browse</b> and <b>Choose a disk file ...</b>.Select the Ubuntu.iso downloaded by the user. Click <b>OK</b>. <div class="image">
<img src="../../code_build_vm_ubn_iso.png" alt=""/>
<div class="caption">
Figure 6-9. Choose a Disk File.</div></div>
</li>
<li>If a PC comes equipped with two network interface controllers (NICs), one connected to the Internet and other to the platform, use the <b>Oracle VM VirtualBox Manager</b>, select the virtual machine, and click Settings &gt; Network.</li>
<li>Within <b>Adapter 1</b>, select <b>Enable Network Adapter</b>.<ul>
<li>Attached to: <b>Bridged</b> Adapter</li>
<li>Name: (NIC that is connected to the Internet) <div class="image">
<img src="../../code_build_vm_net_adap_1.png" alt=""/>
<div class="caption">
Figure 6-10. Configuaration of Adapter 1.</div></div>
</li>
</ul>
</li>
<li>Within <b>Adapter 2</b>, select <b>Enable Network Adapter</b>.<ul>
<li>Attached to: <b>Bridged</b> Adapter</li>
<li>Name: (NIC that is connected to the development board) <div class="image">
<img src="../../code_build_vm_net_adap_2.png" alt=""/>
<div class="caption">
Figure 6-11. Configuaration of Adapter 2.</div></div>
</li>
</ul>
</li>
</ul>
</li>
<li>Install Ubuntu on the virtual machine.<ul>
<li>Start the virtual machine. After Ubuntu loads, select <b>Install Ubuntu</b>. <div class="image">
<img src="../../code_build_vm_install_ubun.png" alt=""/>
<div class="caption">
Figure 6-12. Install Ubuntu.</div></div>
</li>
<li>When the installation finishes, shut down the virtual machine. Click <b>Settings &gt; Storage &gt; .iso</b> (Ubuntu disk image). Then, click the <b>Browse</b> button beside <b>Optical Drive</b> and <b>Remove disk from virtual drive</b>. The entry field will clear its contents. <div class="image">
<img src="../../code_build_vm_rm_iso.png" alt=""/>
<div class="caption">
Figure 6-13. Remove Disk from Virtual Drive.</div></div>
</li>
</ul>
</li>
<li>Install guest additions. VirtualBox Guest Additions improves mouse integration, screen resolution options, and other features for the guest operation system.<ul>
<li>Click <b>Settings &gt; Storage &gt; Empty</b> under the <b>Controller: IDE</b>. Click the browse button beside <b>Optical Drive</b> and <b>Choose a virtual CD / DVD file</b>. Browse the file for <b>VBoxGuestAdditions.iso</b> (this can usually be found under C:\Program Files \Oracle\VirtualBox). Click <b>OK</b> to continue. <div class="image">
<img src="../../code_build_vm_vbox_gst.png" alt=""/>
<div class="caption">
Figure 6-14. Install VirtualBox Guest Additions.</div></div>
</li>
<li>Start the virtual machine and change to the directory where the CD-ROM is mounted. For example: /media. <div class="fragment"><div class="line">host $ sudo ./VBoxLinuxAdditions.run</div>
</div><!-- fragment --></li>
</ul>
</li>
</ol>
<dl class="section note"><dt>Note</dt><dd>If it is necessary to attach a USB device, such as AmbaUSB, to the virtual machine, ensure that the USB port is USB 2.0 to avoid the following error message, as shown below. <div class="fragment"><div class="line">Failed to attach the USB device xxxx to the <span class="keyword">virtual</span> machine xxxxx. USB device xxxx with</div>
<div class="line">UUID {xxxxxx} is busy with a previous request. Please <span class="keywordflow">try</span> again later.</div>
</div><!-- fragment --></dd></dl>
<h2><a class="anchor" id="sub_code_build_pc_cifs"></a>
6.4 Network Sharing: CIFS</h2>
<p >See Section <a class="el" href="../../d9/d98/ov_code_build.html#sub_code_build_req_net">2.4 Network Topology</a> for details on setting up the network topology for sharing the building machine.</p>
<h3><a class="anchor" id="dsub_code_build_pc_linux"></a>
6.4.1 Access Linux Folders from the Development Platform</h3>
<p >The following figure illustrates how common internet file systems (CIFS) accesses Linux folders from the development platform. </p><div class="image">
<img src="../../code_build_cifs_linux.png" alt=""/>
<div class="caption">
Figure 6-15. CIFS Between Linux.</div></div>
<p >To enable access of Linux folders from the development platform, perform the following steps:</p>
<p ><b>On the host Linux PC:</b></p>
<ol type="1">
<li>Install <b>Samba</b> and <b>CIFS</b> on the host Linux PC. <div class="fragment"><div class="line">host $ sudo apt-get install samba cifs-utils</div>
</div><!-- fragment --></li>
<li>Create the folder on the host machine that will be shared. <div class="fragment"><div class="line">host $ mkdir /home/linux_share</div>
<div class="line">host $ cd /home/linux_share &amp;&amp; touch abc.txt</div>
</div><!-- fragment --></li>
<li>Modify the <b>Samba</b> configuration file. Add "security=user" to the configuration if the Linux kernel version of the development platform is equal to or later than 3.8. <div class="fragment"><div class="line">host $ sudo vim /etc/samba/smb.conf</div>
<div class="line"> </div>
<div class="line">security = user</div>
<div class="line"> </div>
<div class="line">[linux_share]</div>
<div class="line">      path = /home/linux_share</div>
<div class="line">      writable = yes</div>
<div class="line">      valid users = myusername</div>
</div><!-- fragment --></li>
<li>Restart the <b>Samba</b> service on the host PC. <div class="fragment"><div class="line">host $ sudo service smbd restart</div>
</div><!-- fragment --></li>
</ol>
<p ><b>On the development platform:</b></p>
<ol type="1">
<li>Attach the Linux folder to <code>/mnt</code> on the development platform. <div class="fragment"><div class="line">board # mount –t cifs –o user=myusername,password=mypassword,sec=ntlm  <span class="comment">//10.0.0.3/linux_share /mnt</span></div>
<div class="line">board # ls /mnt</div>
<div class="line">abc.txt</div>
</div><!-- fragment --></li>
<li>To detach the Linux folder, use the following command: <div class="fragment"><div class="line">board # umount /mnt</div>
</div><!-- fragment --></li>
</ol>
<h3><a class="anchor" id="dsub_code_build_pc_win"></a>
6.4.2 Access Windows Folders from the Development Platform</h3>
<p >The following figure illustrates how CIFS accesses Windows folders from the development platform. </p><div class="image">
<img src="../../code_build_cifs_win_linux.png" alt=""/>
<div class="caption">
Figure 6-16. CIFS between Windows and Linux.</div></div>
<p >To enable access of Windows folders from the development platform, perform the following steps:</p>
<p ><b>On the Windows PC:</b></p>
<ol type="1">
<li>Set up the security options for the network connection. (Assume that the connection between the PC and the platform is on a public network.)</li>
<li>Go to <b>Control Panel &gt; Network and Internet &gt; Choose homegroup and sharing options &gt; Change advanced Sharing setting… &gt; Public</b>.<ul>
<li>Network Discovery: Turn on network discovery</li>
<li>File and printer sharing: Turn on</li>
<li>Public folder sharing: Developer's choice, acceptable to have it on or off</li>
</ul>
</li>
<li>Set up the folder you want share on Windows 10. Right click the folder -&gt; <b>chose "Properties" menu -&gt; click "Sharing" tab -&gt; click "Advanced Sharing…" -&gt; check "share this folder" box</b> -&gt; enter a share name. The following figure provides an example of the share folder setting. <div class="image">
<img src="../../code_build_share_win_host.png" alt=""/>
<div class="caption">
Figure 6-17. Share Folder Settings of Windows Host PC.</div></div>
</li>
</ol>
<p ><b>On the development platform:</b></p>
<ol type="1">
<li>Here, the username is the Windows user name, and the password is for the Windows user account. <div class="fragment"><div class="line">board # mount -t cifs  -o  domain=ambarella,sec=ntlmssp,username=xxx,password=xxxxxx,uid=0,gid=0,file_mode=0755,dir_mode=0755  <span class="comment">//10.0.0.1/myshare  /mnt</span></div>
<div class="line">board # ls /mnt</div>
<div class="line">this_is_a_share_file</div>
</div><!-- fragment --></li>
<li>To detach the Linux folder, use the following command: <div class="fragment"><div class="line">baord # umount /mnt</div>
</div><!-- fragment --></li>
</ol>
<h3><a class="anchor" id="dsub_code_build_pc_fold"></a>
6.4.3 Access the Folder on the Building Machine from the Development Platform</h3>
<p >Users can compile the application on the building machine and run it directly on the development platform without burning the binary; this benefits the driver and the debug process for the applications.</p>
<p >The following figure shows an example of the CIFS process. </p><div class="image">
<img src="../../code_build_cifs_example.png" alt=""/>
<div class="caption">
Figure 6-18. CIFS Example.</div></div>
<p >To enable access of the folders on the building machine from the development platform, enter the following commands and perform the following steps:</p>
<p ><b>On the building workstation:</b> </p><div class="fragment"><div class="line">build $ sudo apt-get install samba cifs-utils</div>
<div class="line">build $ mkdir –p /home/build_share</div>
<div class="line">build $ sudo vim /etc/samba/smb.conf</div>
<div class="line">&lt;A simple example&gt;</div>
<div class="line">[build_share]</div>
<div class="line">       path = /home/build_share</div>
<div class="line">      writable = yes</div>
<div class="line">      valid users = mybuildusername</div>
<div class="line">build $ sudo service smbd restart</div>
</div><!-- fragment --><p ><b>On the Linux PC:</b></p>
<div class="fragment"><div class="line">host $ sudo apt-get install samba cifs-utils</div>
<div class="line">host $ mkdir -p /home/linux_share</div>
<div class="line">host $ sudo vim /etc/fstab</div>
</div><!-- fragment --><ol type="1">
<li>Add the following line (all in one line) in <code>/etc/fstab</code>: <code>//10.4.8.155/build_share /home/linux_share cifs username=mydomain\mybuildusername, password=mybuildpasswd</code> <div class="fragment"><div class="line">host $ sudo mount -a</div>
<div class="line">host $ sudo vim /etc/samba/smb.conf</div>
<div class="line">&lt;A simple example&gt;</div>
<div class="line">security = user</div>
<div class="line">[linux_share]</div>
<div class="line">       path = /home/linux_share</div>
<div class="line">       writable = yes</div>
<div class="line">       valid users = myhostname</div>
<div class="line">host $ sudo service smbd restart</div>
</div><!-- fragment --></li>
<li>On the development board, run the following command. <div class="fragment"><div class="line">board # mkdir -p /mnt/build_share</div>
<div class="line">board # mount -t cifs <span class="comment">//10.0.0.3/linux_share /mnt/shares -o user=myhostname, password=myhostpasswd</span></div>
</div><!-- fragment --></li>
<li>If the above configurations are successful, build_share can be accessed from the development platform as shown in the following: <div class="fragment"><div class="line">build $ cd /home/build_share</div>
<div class="line">build $ touch abc.txt</div>
<div class="line">board # ls /mnt/shares</div>
<div class="line">abc.txt</div>
</div><!-- fragment --></li>
<li>To remove the shares, type the following command: <div class="fragment"><div class="line">board # umount /mnt/shares</div>
</div><!-- fragment --></li>
</ol>
<h2><a class="anchor" id="sub_code_build_pc_evk_nfs"></a>
6.5 Network Sharing: NFS</h2>
<p >The network file system (NFS) is a protocol that enables users on a client computer to access files over a network. If the PC that connects to the development platform includes an NFS server, then the platform can access the PC's hard drive through the network.</p>
<p >This section includes procedures for setting up the system with NFS to enable users to access files over a network. The following figure shows an example of the NFS process. </p><div class="image">
<img src="../../code_build_nfs_example.png" alt=""/>
<div class="caption">
Figure 6-19. NFS Example.</div></div>
<p >For more information on setting up the NFS, go to the official web site: <a href="http://tldp.org/HOWTO/NFS-HOWTO/">http://tldp.org/HOWTO/NFS-HOWTO/</a>.</p>
<h3><a class="anchor" id="sub_code_build_pc_nfs_server"></a>
6.5.1 Setting Up an NFS Server on a Linux PC</h3>
<p >To set up an NFS server on a linux PC, perform the following steps:</p>
<ol type="1">
<li>Install the NFS server on the Linux PC. <div class="fragment"><div class="line">host $ sudo apt-get install nfs-kernel-server</div>
</div><!-- fragment --></li>
<li>Set the NFS server's configuration and start the server. <div class="fragment"><div class="line">host $ mkdir -p /home/linux_share</div>
<div class="line">host $ sudo vim /etc/exports</div>
<div class="line">host $ sudo echo <span class="stringliteral">&quot;/home/linux_share 10.0.0.2(rw,root_squash)&quot;</span> &gt; /etc/exports</div>
<div class="line">host $ sudo /etc/init.d/nfs-kernel-server restart</div>
</div><!-- fragment --></li>
</ol>
<h3><a class="anchor" id="sub_code_build_evk_nfs_cs"></a>
6.5.2 Setting Up the NFS Client and Server on a Development Platform</h3>
<p >To set up an NFS server on a development platform, perform the following steps:</p>
<ol type="1">
<li>Select <code>NFS utils</code> and <code>rpcbind</code> in the rootfs and select the kernel NFS support.</li>
</ol>
<ul>
<li>For Cooper Amba build <div class="fragment"><div class="line">build $ make ipcam_config</div>
<div class="line">build $ make menuconfig</div>
<div class="line">      prebuild  ---&gt;</div>
<div class="line">             oss  ---&gt;</div>
<div class="line">                [*] prebuild-nfs-utils (prebuild/oss/armv8-a/nfs-utils)  ---&gt;</div>
<div class="line"> </div>
<div class="line">build $ make menuconfig_public_linux</div>
<div class="line">          File systems &gt;</div>
<div class="line">            [*] Network File Systems &gt;</div>
<div class="line">               &lt;*&gt;   NFS client support</div>
<div class="line">               &lt;*&gt;     NFS client support <span class="keywordflow">for</span> NFS version 3</div>
<div class="line">               &lt;*&gt;   NFS server support</div>
<div class="line">               [*]     NFS server support <span class="keywordflow">for</span> NFS version 3</div>
</div><!-- fragment --></li>
</ul>
<ol type="1">
<li>Set the directory for NFS sharing in <code>/etc/exports</code> When the platform boots up. <div class="fragment"><div class="line">board # mkdir /nfs</div>
<div class="line">board # echo <span class="stringliteral">&quot;/nfs *(rw,sync,fsid=0,no_root_squash,no_subtree_check)&quot;</span> &gt; /etc/exports</div>
<div class="line">board # chmod 777 /nfs</div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><ul>
<li>Because UBIFS cannot support NFS, users cannot export UBIFS file-systems via NFS.</li>
<li>If UBIFS is used, the NFS share folder can be set in tmpfs(/tmp/nfs), VFAT (/sdcard/mmcblk0p1/nfs), or other file-systems.</li>
</ul>
</dd></dl>
</li>
<li>Set the NFS ports and the rpcbind ports in <code>/etc/services</code>. <div class="fragment"><div class="line">nfs     2049/tcp        nfsd</div>
<div class="line">nfs     2049/udp        nfsd</div>
<div class="line">sunrpc  111/tcp         rpcbind portmap</div>
<div class="line">sunrpc  111/udp         rpcbind portmap</div>
</div><!-- fragment --></li>
<li>Check if NFS and NFSD are supported by the kernel. <div class="fragment"><div class="line">board # cat /proc/filesystems | grep nfs</div>
<div class="line">nodev   nfs</div>
<div class="line">nodev   nfsd</div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd><ul>
<li><code>nodev nfs</code> is for the NFS client.</li>
<li><code>nodev nfsd</code> is for the NFS server.</li>
</ul>
</dd></dl>
</li>
<li><p class="startli">Start the NFS server.</p><ul>
<li>If the system is started with <code>systemd</code>, the following commands can be used: <div class="fragment"><div class="line">systemctl start nfs-server.service</div>
</div><!-- fragment --></li>
<li>If the system is started with <code>linuxrc</code>, the following commands can be used: <div class="fragment"><div class="line">board # rpcbind</div>
<div class="line">board # rpc.statd --no-notify</div>
<div class="line">board # rpc.nfsd</div>
<div class="line">board # rpc.mountd</div>
<div class="line">board # exportfs -rv</div>
</div><!-- fragment --></li>
</ul>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>If the NFS server share folder is already created and <code>/etc/exports</code> is set properly before compiling, there is no need to start or restart the NFS server manully when <code>CONFIG_AMBARELLA_NFS_SERVER_AUTO_START</code> is selected in menuconfig.</li>
</ul>
</dd></dl>
</li>
<li>Mount to the NFS server share folder from the NFS client platform.<ul>
<li><b>Temporary Mount</b><ul>
<li>After each reboot of the development platform, type the following commands: <div class="fragment"><div class="line">board # mkdir -p /mnt/shares</div>
<div class="line">board # mount -t nfs -o nolock &lt;NFS_SERVER_IP&gt;:/nfs /mnt/shares</div>
</div><!-- fragment --></li>
<li>&lt;NFS_SERVER_IP&gt; is the IP address of the NFS server.</li>
</ul>
</li>
<li><b>Permanent Mount</b><ul>
<li>When the platform boots up, the NFS mounts automatically. (Note that NFS server on the other platform should be functioning before this platform boots up.) <div class="fragment"><div class="line">build $ make &lt;platform&gt;_ipcam_config</div>
<div class="line">build $ make menuconfig</div>
<div class="line">          Ambarella File System Configuration &gt;</div>
<div class="line">            ()Mount configuration <span class="keywordflow">for</span> /mnt &gt;</div>
<div class="line">              &lt;NFS_SERVER_IP&gt;:/nfs /mnt/shares nfs defaults,nolock 0 0</div>
</div><!-- fragment --></li>
<li>&lt;NFS_SERVER_IP&gt; is the IP address of the Linux PC.</li>
</ul>
</li>
</ul>
</li>
<li>Share files between the NFS server and the NFS client. If the configurations listed in the previous steps are successful, the NFS server share folder <code>/nfs</code> can be accessed from the development platform. The following commands show the sharing processes:<ul>
<li>NFS server: <div class="fragment"><div class="line">board # $ cd /nfs</div>
<div class="line">board $ touch abcd.txt</div>
</div><!-- fragment --></li>
<li>NFS client: <div class="fragment"><div class="line">board # ls /mnt/shares</div>
<div class="line">abcd.txt</div>
<div class="line">board # $ cd /mnt/shares</div>
<div class="line">board $ touch 1234.txt</div>
</div><!-- fragment --></li>
<li>NFS server: <div class="fragment"><div class="line">board # ls /nfs</div>
<div class="line">abcd.txt 1234.txt</div>
</div><!-- fragment --></li>
</ul>
</li>
<li>Remove the client shares using the following command: <div class="fragment"><div class="line">board # umount /mnt/shares</div>
</div><!-- fragment --></li>
<li>Stop the NFS server.<ul>
<li>If the system is started with <code>systemd</code>, the following commands can be used: <div class="fragment"><div class="line">systemctl stop nfs-server.service</div>
</div><!-- fragment --></li>
<li>If the system is started with <code>linuxrc</code>, the following commands can be used: <div class="fragment"><div class="line">board # rpc.nfsd 0</div>
<div class="line">board # killall rpc.mountd</div>
<div class="line">board # exportfs -rv</div>
<div class="line">board # exportfs -f</div>
<div class="line">board # killall rpc.statd</div>
<div class="line">board # killall rpcbind</div>
</div><!-- fragment --></li>
</ul>
</li>
</ol>
<hr  />
<h1><a class="anchor" id="code_build_upgrade"></a>
7. Upgrade the Firmware to the Development Platform</h1>
<p >For more details on installing the firmware through <b>AmbaUSB</b> on <b>Linux</b> or <b>Windows</b>, refer to Chapter <a class="el" href="../../d7/d6c/page_getting_start_guide.html#getting_guide_upgrade_firmware">7. Upgrading the Firmware</a>.</p>
<hr  />
<h1><a class="anchor" id="code_build_oss"></a>
8. Build OSS Libraries</h1>
<p >Cross-compiled open source software (OSS) libraries prepared by Ambarella are included in the SDK.</p>
<p >The pre-built libraries can be used directly by Amba build. Users can request the RPM and SRPM packages from Ambarella, which are separate and not included the standard Linux SDK, if cross-compiling the libraries themselves.</p>
<p >Below are the available source RPM packages. </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Date   </th><th class="markdownTableHeadLeft">Source Package Name    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">20210419   </td><td class="markdownTableBodyLeft">ambarella-oss-src-20210419.tar.bz2    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">20220215   </td><td class="markdownTableBodyLeft">ambarella-oss-src-srpms-20220215.tar    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">20220719   </td><td class="markdownTableBodyLeft">ambarella-oss-src-srpms-20220719.tar.xz    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">20230308   </td><td class="markdownTableBodyLeft">ambarella-oss-src-srpms-20230308.tar.xz   </td></tr>
</table>
<p >Below are the reference steps. </p><div class="fragment"><div class="line">1. Prepare the host PC</div>
<div class="line">1.1 Install CentOS7</div>
<div class="line">1.2 Install EPEL release <span class="keywordflow">for</span> better software support.</div>
<div class="line">    host $ sudo yum install epel-release</div>
<div class="line">1.3 Install <span class="keyword">new</span> <span class="keyword">package </span>software dnf</div>
<div class="line">    host $ sudo yum install dnf</div>
<div class="line">1.4 update the system to the latest</div>
<div class="line">    host $ sudo dnf update</div>
<div class="line"> </div>
<div class="line">2. Build the src rpm package</div>
<div class="line">2.1 Extract the tool chain</div>
<div class="line">2.2 Add the toolchain path into PATH.</div>
<div class="line">2.3 Install the aarch64-filesystem.rpm in the rpms folder</div>
<div class="line">    host $ sudo dnf install ./aarch64-filesystem-18-el7.rpm</div>
<div class="line">2.4 Rebuild the target src.rpm. Take bzip2 as example:</div>
<div class="line">    host $ rpmbuild --rebuild aarch64-bzip2-1.0.8-1.amba.src.rpm</div>
<div class="line">    The target rpm is under the folder: rpmbuild/RPMS/</div>
<div class="line">    If the package has dependencies, the dependency rpm packages need to be built first, then install them by command.</div>
<div class="line">    host $ rpmbuild --rebuild aarch64-xxx-xxx.src.rpm</div>
<div class="line">    host $ sudo dnf install aarch64-xxx-xxx-xxx.rpm</div>
<div class="line"> </div>
<div class="line">    After resolving all the dependency, use below command to build the package.</div>
<div class="line">    host $ rpmbuild --rebuild aarch64-xxx-xxx.src.rpm</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd><ul>
<li>Ambarella collects the source codes from the community. Ambarella does not change any code for the OSS libraries.</li>
<li>The toolchain version used by Ambarella in the step 2.1 above is <b>linaro-aarch64-2019.11-gcc7.5</b> in order to avoid the potential glibc compatibility issue. If users want to re-build the libraries, they can choose a newer toolchain (the toolchain must be released with the SDK). The toolchain version used for buliding the application must be newer than or the same as (but not older than) the toolchain version used for building OSS.</li>
</ul>
</dd></dl>
<hr  />
<h1><a class="anchor" id="code_build_license"></a>
9. License</h1>
<p >Copyright (c) 2024 Ambarella International LP.</p>
<p >This file and its contents ( "Software" ) are protected by intellectual property rights including, without limitation, U.S. and/or foreign copyrights. This Software is also the confidential and proprietary information of Ambarella International LP and its licensors. You may not use, reproduce, disclose, distribute, modify, or otherwise prepare derivative works of this Software or any portion thereof except pursuant to a signed license agreement or nondisclosure agreement with Ambarella International LP or its authorized affiliates. In the absence of such an agreement, you agree to promptly notify and return this Software to Ambarella International LP.</p>
<p >THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL AMBARELLA INTERNATIONAL LP OR ITS AFFILIATES BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; COMPUTER FAILURE OR MALFUNCTION; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</p>
<hr  />
 </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3 </li>
  </ul>
</div>
</body>
</html>
