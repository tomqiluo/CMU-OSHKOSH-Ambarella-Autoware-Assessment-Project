<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Library: Sensor Calibration Library API</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<link rel="search" href="../../search_opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Library"/>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="../../../library/mathjax/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-ambarella.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../Ambarella.png"/></td>
  <td id="projectalign">
   <div id="projectname">Library<span id="projectnumber">&#160;Cooper_1.6.0 (CV72 &amp; CV3) @ 2024.07.10 14:12:44</span>
   </div>
   <div id="projectbrief">placeholder</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,true,'search.html','Search');
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d1/d1e/page_lib_sensor_calib_doc.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">Sensor Calibration Library API </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><a class="anchor" id="Sensor calibration library"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Library Version </th><th align="left">Updated Date </th><th align="left">Modification </th></tr>
<tr>
<td>0.0.1 </td><td>20210604 </td><td>Initial Version </td></tr>
<tr>
<td>0.0.2 </td><td>20210608 </td><td>Added support for saving calibraiton target struct for changing distance calibration </td></tr>
<tr>
<td>0.0.3 </td><td>20210623 </td><td>Refined calibration board detecting and add doing calibration with initial values </td></tr>
<tr>
<td>0.0.4 </td><td>20210628 </td><td>Added support for creating map for H cylindrical and transverse cylindrical projection </td></tr>
<tr>
<td>0.0.5 </td><td>20210706 </td><td>Added support for saving corner id of april tags </td></tr>
<tr>
<td>0.0.6 </td><td>20210713 </td><td>Added support for creating grid level map </td></tr>
<tr>
<td>0.0.7 </td><td>20210722 </td><td>Added support for using disparity to create configrations for specific distance stitching </td></tr>
<tr>
<td>0.0.8 </td><td>20210809 </td><td>Added support for keeping output resolution as the configuration files in base folder </td></tr>
<tr>
<td>0.0.9 </td><td>20210810 </td><td>Added support for keeping specific output resolution for multi-channel stitching </td></tr>
<tr>
<td>0.1.0 </td><td>20210811 </td><td>Added support for keeping specific output resolution for Thermal and RGB calibration </td></tr>
<tr>
<td>0.1.1 </td><td>20210904 </td><td>Added support for accerleration of Mono and RGB automatic calibration </td></tr>
<tr>
<td>0.1.2 </td><td>20210904 </td><td>Added some check for RGB and Thermal calibration </td></tr>
<tr>
<td>0.1.2 </td><td>20210904 </td><td>Moved Lens / ToF calibration to Sensor Calibration User Guide </td></tr>
<tr>
<td>0.1.2 </td><td>20210921 </td><td>Refined the stitching pose calibration </td></tr>
<tr>
<td>0.1.3 </td><td>20210921 </td><td>Added support for creating stereo map </td></tr>
<tr>
<td>0.1.4 </td><td>20211012 </td><td>Added support for keeping output </td></tr>
<tr>
<td>0.1.5 </td><td>20211021 </td><td>Removed crop delta function </td></tr>
<tr>
<td>0.1.6 </td><td>20211022 </td><td>1. Added different zoom factor 2. Added padding width </td></tr>
<tr>
<td>0.1.7 </td><td>20211110 </td><td>Fixed issues of RGB and Mono calibration </td></tr>
<tr>
<td>0.1.8 </td><td>20211114 </td><td>Fixed issues of specifying the output resolution </td></tr>
<tr>
<td>0.1.9 </td><td>20211117 </td><td>Fixed issues of creating full calibration warp table </td></tr>
<tr>
<td>0.1.10 </td><td>20211206 </td><td>Fixed issues of VFoV loss </td></tr>
<tr>
<td>0.1.11 </td><td>20211209 </td><td>Fixed issues of saving debug image </td></tr>
<tr>
<td>0.1.11 </td><td>20211220 </td><td>Added options descriptions </td></tr>
<tr>
<td>0.1.12 </td><td>20211220 </td><td>Removed unnecessary cutting of the last channel </td></tr>
<tr>
<td>0.1.13 </td><td>20220118 </td><td>Added detection threshold to get more keypoints </td></tr>
<tr>
<td>0.1.13 </td><td>20220119 </td><td>Updated Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>0.1.14 </td><td>20220126 </td><td>Updated Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_mono_rgb">Mono and RGB Sensors Calibration</a> </td></tr>
<tr>
<td>0.1.15 </td><td>20220126 </td><td>Updated Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>0.1.16 </td><td>20220224 </td><td>Updated Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_mono_rgb">Mono and RGB Sensors Calibration</a> </td></tr>
<tr>
<td>0.1.17 </td><td>20220303 </td><td>Updated Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_mono_rgb">Mono and RGB Sensors Calibration</a> </td></tr>
<tr>
<td>0.1.18 </td><td>20220311 </td><td>Moved use_apriltag to reserved0 </td></tr>
<tr>
<td>0.1.19 </td><td>20220314 </td><td>Added log level </td></tr>
<tr>
<td>0.1.20 </td><td>20220418 </td><td>Added multiple threads for creating 2d map </td></tr>
<tr>
<td>0.1.21 </td><td>20220525 </td><td>Fixed issues of core dump in adjust camera </td></tr>
<tr>
<td>0.1.22 </td><td>20220616 </td><td>Added support for channel rotate <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>0.1.23 </td><td>20220630 </td><td>Changed offset to 64 align <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>0.1.24 </td><td>20220729 </td><td>Added outlier remove for clusters <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>0.1.25 </td><td>20220803 </td><td>Added check for the stitching view bigger than 360 degree <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>0.2.0 </td><td>20220809 </td><td>Added support for grid keypoints <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>0.2.1 </td><td>20220810 </td><td>Fixed issues when detecting the neighbouring points <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>0.2.2 </td><td>20220906 </td><td>Fixed issues in debug image </td></tr>
<tr>
<td>0.2.3 </td><td>20220915 </td><td>Removed H matrix refinement stage </td></tr>
<tr>
<td>0.2.4 </td><td>20221024 </td><td>Added support for April tag ID 3 </td></tr>
<tr>
<td>0.2.5 </td><td>20221025 </td><td>Added support for cw_rotate / hflip / vflip </td></tr>
<tr>
<td>1.0.0 </td><td>20221130 </td><td>Added support for dual fisheye stitching </td></tr>
<tr>
<td>1.0.1 </td><td>20230317 </td><td>Added WINDOWS_COMPILE macro to prevent imwrite compatibility problem </td></tr>
<tr>
<td>1.0.2 </td><td>20230327 </td><td>Fix warnings caused by snprintf </td></tr>
<tr>
<td>1.0.3 </td><td>20230428 </td><td>Added support for tilt angle stitching </td></tr>
<tr>
<td>1.0.4 </td><td>20230530 </td><td>Added support for adjusting dewarp table on the fly by using optical flow </td></tr>
<tr>
<td>1.0.5 </td><td>20230531 </td><td>Remove thread to fix core dump problem </td></tr>
<tr>
<td>1.0.6 </td><td>20230728 </td><td>Added calib_scale to increase speed </td></tr>
<tr>
<td>1.1.0 </td><td>20230728 </td><td>Added support for dense dynamic stitching V3 </td></tr>
<tr>
<td>1.1.1 </td><td>20230927 </td><td>Added support for keypoints to get global shifts </td></tr>
<tr>
<td>1.1.2 </td><td>20230927 </td><td>Fixed artifact in the padding area </td></tr>
<tr>
<td>1.2.0 </td><td>20231020 </td><td>Added support for vhhv mode stitching case </td></tr>
<tr>
<td>1.3.0 </td><td>20231020 </td><td>Added support for using middle line's dis to do compensation </td></tr>
<tr>
<td>1.3.1 </td><td>20231114 </td><td>Added template match to resolve chessboard matching </td></tr>
<tr>
<td>1.4.0 </td><td>20231114 </td><td>Added FoV configrations for calibration with rotation stitching </td></tr>
<tr>
<td>1.4.1 </td><td>20231226 </td><td>Added scale ratio for rotation stitching </td></tr>
<tr>
<td>1.5.0 </td><td>20240116 </td><td>Added max_overlap / ignore_pause options </td></tr>
</table>
<h1><a class="anchor" id="sensor_calib_introduction"></a>
Introduction</h1>
<p >This chapter introduces basic information on different sensor calibrations.</p><ul>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_cfg">1. Calibration Configration File Descriptions</a></li>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">2. Stitching Pose Calibration</a></li>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_thermal_rgb">3. Thermal and RGB Sensors Calibration</a></li>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_mono_rgb">4. Mono and RGB Sensor Calibration</a></li>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_tool_usage">5. Tool Usage</a></li>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_api">6. Sensor Calibration API</a></li>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_lic">7. License</a></li>
</ul>
<hr  />
<h1><a class="anchor" id="sensor_calib_cfg"></a>
1. Calibration Configration File Descriptions</h1>
<p >The <code>.ini</code> example files are in the path <code>ambarella\packages\sensor_calib_ini_parser\arch_v5\configure</code>. Some descriptions of the options in sensor calibration (.ini file) are as follows: <br  />
 </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Title   </th><th class="markdownTableHeadCenter">Field   </th><th class="markdownTableHeadCenter">Value   </th><th class="markdownTableHeadCenter">Details    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">General   </td><td class="markdownTableBodyCenter">sensor_mode   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Calibration mode. 0: Projection. 1: Calibration. 2: Create undistorted map    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">channel_num   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Channel numbers    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">overlap_num   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Overlap numbers    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">is_vertical   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Vertical stitching flag    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">no_yuv   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">No YUV for calibration    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">prefix   </td><td class="markdownTableBodyCenter">../example/2_hor/   </td><td class="markdownTableBodyCenter">Path prefix    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">output_width   </td><td class="markdownTableBodyCenter">2592   </td><td class="markdownTableBodyCenter">Output width    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">output_height   </td><td class="markdownTableBodyCenter">1944   </td><td class="markdownTableBodyCenter">Output height    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">disable_hv_align   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Disable horizontal and vertical alignment    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">cw-rotate   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Channel rotate in the clockwise direction    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">hflip   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Channel h-flip in the horizontal direction    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">vflip   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Channel v-flip in the vertical direction    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">width_ratio   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Width ratio for ecurectangle projection    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">create_base   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Create base configuation    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">sensor_debug_mode   </td><td class="markdownTableBodyCenter">-1   </td><td class="markdownTableBodyCenter">Specify debug mode. 2: Print difference information. 9: Print detailed information. 10: Save simulation canvas image    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">ignore_pause   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Stop the terminal task    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">max_overlap   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Max overlap width / height    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Overlap   </td><td class="markdownTableBodyCenter">tag_info   </td><td class="markdownTableBodyCenter">11 0.023978 0.024031   </td><td class="markdownTableBodyCenter">April tag information    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Channel   </td><td class="markdownTableBodyCenter">width   </td><td class="markdownTableBodyCenter">2592   </td><td class="markdownTableBodyCenter">Input width    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">height   </td><td class="markdownTableBodyCenter">1944   </td><td class="markdownTableBodyCenter">Input height    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">use_h_flag   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Use H matrix    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">no_dist_flag   </td><td class="markdownTableBodyCenter">1944   </td><td class="markdownTableBodyCenter">No distortion    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">scale_ratio   </td><td class="markdownTableBodyCenter">1.0,1.0   </td><td class="markdownTableBodyCenter">Scale ratio    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">filename_yuv   </td><td class="markdownTableBodyCenter">0_canvas0_2592x1944_NV12.yuv   </td><td class="markdownTableBodyCenter">YUV name    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">focal   </td><td class="markdownTableBodyCenter">1080   </td><td class="markdownTableBodyCenter">Focal length of fisheye    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">cx   </td><td class="markdownTableBodyCenter">width / 2   </td><td class="markdownTableBodyCenter">X center of fisheye    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">cy   </td><td class="markdownTableBodyCenter">height / 2   </td><td class="markdownTableBodyCenter">Y center of fisheye    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">tilt_angle   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify tilt angle    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">coor_point   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify coordinates    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">H_mat   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify H matrix    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">top_left_point   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify top left points    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">bot_right_point   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify right bottom points    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">adjust   </td><td class="markdownTableBodyCenter">0,0   </td><td class="markdownTableBodyCenter">Adjust offset for stitching result    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">chan_cw_rotate   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Clockwise rotate    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Pattern   </td><td class="markdownTableBodyCenter">sensor_pattern_type   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">0: Circle. 1: Chessboard    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">share_id   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Share ID    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">multi_board   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Multiple board calibration flags    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">sensor_pattern_distance   </td><td class="markdownTableBodyCenter">1.5   </td><td class="markdownTableBodyCenter">Pattern distance to the optical center    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">square_size   </td><td class="markdownTableBodyCenter">1.5   </td><td class="markdownTableBodyCenter">Chessboard pattern square size    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">board_size   </td><td class="markdownTableBodyCenter">8,12   </td><td class="markdownTableBodyCenter">Chessboard pattern size    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Calib   </td><td class="markdownTableBodyCenter">different_zoom   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Different zoom factors    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">expand_flag   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Expand field of view (FoV) flag    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">sensor_dist_mode   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Sensor distance mode. 0: Disparity. 1: Rotation    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">keep_cfg_from_base   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Keep configration as the base    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">sensor_distance   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Stitching distance    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">baseline   </td><td class="markdownTableBodyCenter">0.05   </td><td class="markdownTableBodyCenter">Baseline between two lens    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">sensor_fuse_method   </td><td class="markdownTableBodyCenter">2   </td><td class="markdownTableBodyCenter">0: Homography. 1: Rotation. 2: Homography and rotation    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">expand_same_focal   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Keep the focal length the same in the horizontal / vertical direction    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">cali_type   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Sensor distance mode. 0: Fuse. 1: Thermal. 2: STITCH. 3: Matrix. 4: Extrinsic.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">cali_keypoints_method   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Sensor distance mode. 0: Akaze. 1: Orb. 2:Sift. 3:Static. 4:Harris.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">calib_scale   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Scale ratio to increase calibration speed    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">fisheye_radius   </td><td class="markdownTableBodyCenter">544   </td><td class="markdownTableBodyCenter">Radius of fisheye    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">fisheye_overlap_delta   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Overlap width of fisheye    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">fisheye_stitch_start   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Fisheye stitching start offset    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">fisheye_stitch_end   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Fisheye stitching end offset    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">fx_ratio   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">X focal length ratio    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">fy_ratio   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Y focal length ratio    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">use_grid_keypoints   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Use keypoints in the grid level to improve matching robustness    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">auto_match_method   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify match method. 0: Apriltag. 1: Optical flow. 2: Flann    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">use_four_points   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Use four points to calculate the homography matrix    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">backend_name   </td><td class="markdownTableBodyCenter">"backend"   </td><td class="markdownTableBodyCenter">Specify folder name for backend files    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Thresh   </td><td class="markdownTableBodyCenter">detect_thresh   </td><td class="markdownTableBodyCenter">0.001   </td><td class="markdownTableBodyCenter">Key point detection threshold for (AKAZE / SIFT). Decreasing (such as by 0.0005) the value will get more points    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">extract_match_ratio   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Image scale ratio for key point extraction and matching; the defalut is 1    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">knn_thresh   </td><td class="markdownTableBodyCenter">0.6   </td><td class="markdownTableBodyCenter">Key point matching threshold for the KNN method, the defalut is 0.6. Increasing (such as by 0.75) the value will get more pairs    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">ransac_thresh   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Threshold for calculating homography matrix. Decreasing (such as by 0.5 pixel) the value will improve the calibration accuracy    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">x_offset_ratio   </td><td class="markdownTableBodyCenter">0.1   </td><td class="markdownTableBodyCenter">Threshold of key points horizontal coordinates ratio difference in point-matching stage    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">y_offset_ratio   </td><td class="markdownTableBodyCenter">0.1   </td><td class="markdownTableBodyCenter">Threshold of key points vertical coordinates ratio difference in point-matching stage    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">octaves   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Group numbers of the image pyramid    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">sublevels   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Level numbers in one group of the image pyramid    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">use_apriltag   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Use the April tag to calculate the homography matrix    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">min_area   </td><td class="markdownTableBodyCenter">50   </td><td class="markdownTableBodyCenter">Threshold for detecting small radius circle on the calibration pattern    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter"></td><td class="markdownTableBodyCenter">line_ratio   </td><td class="markdownTableBodyCenter">0.3   </td><td class="markdownTableBodyCenter">Threshold of removing the wrong connection in the incline direction   </td></tr>
</table>
<dl class="section note"><dt>Note</dt><dd><br  />
<ul>
<li>In the <code>xx_save_target_xx.ini</code> file, sensor_distance should be fixed to 100.</li>
<li>In the <code>xx_pose_calibration_distance_xx.ini</code> file, sensor_distance should be no smaller than the pattern distance.</li>
</ul>
</dd></dl>
<hr  />
<h1><a class="anchor" id="sensor_calib_stitch"></a>
2. Stitching Pose Calibration</h1>
<p >Users should perform stitching pose calibration to obtain the configuration (offset / width / height) for each channel. Ambarella platforms support pose calibration on both the host side and the chip side. <br  />
 Host side: more friendly for users to achieve mass production. <br  />
 Chip side: suitable for environment-independent applications. Users can refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_flow">6.3 Stitching Pose Calibration Flow</a> to learn how to perform pose calibration at both the PC Windows side and the chip side.</p>
<h2><a class="anchor" id="sensor_calib_chip"></a>
2.1 Stitching Pose Calibration Flow</h2>
<p >The process of pose calibration relies on the intrinsic parameters generated in the process of lens calibration, which is assumed to be performed on the host side. For more details, refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">2. Lens Calibration</a>. <br  />
 Because the intrinsic parameters of same lens are similar, users can perform stitching pose calibration on the chip side with the same intrinsic parameters to save the time it costs during the process of lens calibration. <br  />
</p>
<p >Stitching pose calibration could be performed on the chip side with a few images. <br  />
 If users choose to perform pose calibration on the chip side, refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calib_prepare_board">2.1.2 Board Calibration Tool</a> to configure board configurations and build the firmware. <br  />
 To increase convenience for users to configure the values of each parameter, Ambarella introduces the <code>.ini</code> file. Compared with the form of the command line, the <code>.ini</code> file is much more friendly. <br  />
 With the exception of the four lens pose calibrations based on circle board cases shown in <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_flow">6.3 Stitching Pose Calibration Flow</a>, Ambarella lists two lenses for circle boards and three lenses for chess board pose calibration.</p>
<p >Case 1: Perform pose calibration for circle boards for two-lens lens distortion correction (LDC) alignment </p><div class="fragment"><div class="line">host (Windows) $ copy <span class="stringliteral">&quot;intrinsic_x&quot;</span> generated in the stage of <span class="stringliteral">&quot;lens calibration&quot;</span> to the path <span class="stringliteral">&quot;front_end/&quot;</span> directly. (intrinsic_x: x = 0, 1, 2, 3)</div>
<div class="line">host (Windows) $ test_sensor_calib --msc-ini-file sensor_calib_ini_pose_calibration_save_target_2x_hor.ini</div>
<div class="line">host (Windows) $ Edit <span class="stringliteral">&quot;sensor_calib_ini_pose_calibration_distance_2x_hor.ini&quot;</span> and modify <span class="stringliteral">&quot;sensor_distance=x&quot;</span> accordingly. (x means the distance user specified, and the unit is meter.)</div>
<div class="line">host (Windows) $ test_sensor_calib --msc-ini-file sensor_calib_ini_pose_calibration_distance_2x_hor.ini</div>
<div class="line">host (Windows) $ There will be <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> configurations showed in the command window, and then users can config <span class="stringliteral">&quot;cvxx_dual_chan_xm_stitch_xM_linear.lua&quot;</span> file accordingly.</div>
<div class="ttc" id="acJSON_8h_html_aff2566f4c366b48d73479bef43ee4d2e"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a></div><div class="ttdeci">char * buffer</div><div class="ttdef"><b>Definition:</b> cJSON.h:163</div></div>
<div class="ttc" id="avin__init_8c_html_a07a87b2e6ed927503e2f95f119c9fc23"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a></div><div class="ttdeci">int source</div></div>
</div><!-- fragment --><p >Case 2: Perform pose calibration for chess boards for three-lens LDC alignment </p><div class="fragment"><div class="line">host (Windows) $ copy <span class="stringliteral">&quot;intrinsic_x&quot;</span> generated in the stage of <span class="stringliteral">&quot;lens calibration&quot;</span> to the path <span class="stringliteral">&quot;front_end/&quot;</span> directly. (intrinsic_x: x = 0, 1, 2, 3)</div>
<div class="line">host (Windows) $ test_sensor_calib --msc-ini-file sensor_calib_ini_pose_calibration_save_target_3x_hor_chess.ini</div>
<div class="line">host (Windows) $ cp back_end/ base/ -rf</div>
<div class="line">host (Windows) $ Edit <span class="stringliteral">&quot;sensor_calib_ini_pose_calibration_distance_3x_hor_chess.ini&quot;</span> and modify <span class="stringliteral">&quot;sensor_distance=x&quot;</span> accordingly. (x means the distance user specified, and the unit is meter.)</div>
<div class="line">host (Windows) $ test_sensor_calib --msc-ini-file sensor_calib_ini_pose_calibration_distance_3x_hor_chess.ini</div>
<div class="line">host (Windows) $ There will be <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> configurations shown in the command window, and then users can configure <span class="stringliteral">&quot;cvxx_tripple_chan_xm_stitch_xM_linear.lua&quot;</span> file accordingly.</div>
</div><!-- fragment --><p >Users can refer to sections below for more details about the complete flow of the stitching calibration (inlcuding lens and pose calibration). <br  />
</p><ul>
<li><a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> <br  />
</li>
<li><a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_stitch">Multi-Sensor Stitching Pose Calibration</a> <br  />
</li>
</ul>
<h2><a class="anchor" id="sensor_calib_chip"></a>
2.1 Stitching Pose Calibration Flow</h2>
<p >Multi-VIN stitching is based on the warp engine, which is hardware that uses the warp vector to perform real-time dewarping. <br  />
 The warp pipeline requires a 1D horizontal vector and a 1D vertical vector. <br  />
 There are some limitations for the warp vector. In the horizontal or vertical warp stage, the digital signal processor (DSP) divides the input of the vector map into grids and relocates the vertices of each grid based on the vector. <br  />
 The DSP performs an interpolation for the pixels that are not vertices of the grids. <br  />
 <b> Maximum Dimensions </b> <br  />
 The grid size can be different in the horizontal and vertical map. <br  />
 The grid width and height for the horizontal vector map must be 8 / 16 / 32 / 64 / 128 / 256 / 512. <br  />
 The grid width for the vertical vector map must be 8 / 16 / 32 / 64 / 128 / 256 / 512. <br  />
 The grid height for the vertical vector map must be 8 / 16 / 32 / 64 / 128 / 256 / 512. <br  />
 The vector map height can be greater than the main buffer height. <br  />
 <b> Vector </b> <br  />
 The vector is in the format of signed 11.4. <br  />
 For the horizontal map, negative vectors point to the right and positive vectors point to the left. <br  />
 </p><div class="image">
<img src="../../horizontal_vector.jpg" alt=""/>
<div class="caption">
Figure 2-1. Horizontal Vector.</div></div>
 <div class="image">
<img src="../../vertical_vector.jpg" alt=""/>
<div class="caption">
Figure 2-2. Vertical Vector.</div></div>
<p> Users can create 2D warp tables by using pose calibration parameters, and then convert them to 1D + 1D warp tables using the test_stitch application. <br  />
 Different grid spacings will bring quality loss, especially in the horizontal direction. Users can choose the proper grid spacing for good image quality and calculation times. <br  />
 There are a few types of 2D warp tables: <br  />
</p><ul>
<li>Full pixel-level 2D warp tables. After convertion, the caculated 1D horizontal vector is the most accurate. <br  />
</li>
<li>For grid-level warp tables, calculate the grid spacing automatically. The calculation time is the shortest. <br  />
</li>
<li>For grid-level warp tables, customize the grid spacing. The default grid spacing is four; users can specify the grid spacing for proper image quality and calculation time. <br  />
</li>
</ul>
<p >Case 1: Create a full pixel-level 2D warp table, and apply LDC </p><div class="fragment"><div class="line">test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 4 -f ./ --grid-map 0</div>
<div class="line">test_stitch  --mode 2 -f . --no-overlap --fuse 15 --vertical</div>
<div class="ttc" id="avin__init_8c_html_adf7dff2c57c0da9a4a2b70e3e815be31"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a></div><div class="ttdeci">int channel</div></div>
</div><!-- fragment --><p >Case 2: Create a grid-level 2D warp table (calculate the grid spacing automatically), and apply LDC </p><div class="fragment"><div class="line">test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 4 -f ./ --grid-map 1</div>
<div class="line">test_stitch  --mode 2 -f . --no-overlap --fuse 15 --vertical --use-map 2</div>
</div><!-- fragment --><p >Case 3: Create a grid-level 2D warp table (customize the grid spacing), and apply LDC </p><div class="fragment"><div class="line">test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 4 -f ./ --grid-map 2 --grid-wh 4 --grid-h 4</div>
<div class="line">test_stitch  --mode 2 -f . --no-overlap --fuse 15 --vertical --use-map 3 --grid-w 4 --grid-h 4</div>
</div><!-- fragment --><hr  />
<h1><a class="anchor" id="sensor_calib_thermal_rgb"></a>
3. Thermal and RGB Sensors Calibration</h1>
<div class="image">
<img src="../../thermal_points_calib.jpg" alt=""/>
<div class="caption">
Figure 3-1. Thermal Points Choosing Procedure.</div></div>
<p> Because the thermal image's resolution is low, in order to obtain an accurate key point, <br  />
 Ambarella suggests resizing the thermal image to the RGB image size. <br  />
 After the thermal key points are selected, the key points should be resized to a coordinate in the original image. <br  />
 Ambarella recommends selecting more than four pairs of points from both sensor FoVs to perform calibration. <br  />
 First, upscale the thermal image and choose good-quality points, then downscale to the video input (VIN) domain. <br  />
 In one example of the calibration flow, assuming that the thermal sensor resolution is 256x192, and RGB sensor is 2336x1752. Specify scale_ratio (2.5, 2.5) <br  />
 in the <code>.ini [Channel]</code> part for channel 1, if the output fusion resolution is 640x480. <br  />
 All points should come from the VIN domain, and the dewarp parameters should only be applied for RGB channels. <br  />
 Specify output_width / output_height in the <code>.ini [General]</code> part to fix RGB channel's resolution. <br  />
</p>
<ol type="1">
<li>Perform thermal and RGB sensor (remove distortion) alignment calibration. <br  />
 It is assumed that users have performed lens calibration; refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">3. Lens Calibration</a> for more details. <br  />
 <div class="fragment"><div class="line">board # cp front_end /root -rf</div>
<div class="line">Set no_dist_flag=0 <span class="keywordflow">for</span> RGB <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> in the sensor_calib_ini_rgb_thermal.ini</div>
<div class="line">board # test_sensor_calib --msc-ini-file sensor_calib_ini_rgb_thermal.ini</div>
</div><!-- fragment --></li>
<li>Perform thermal and RGB sensor (no distortion) alignment calibration. <div class="fragment"><div class="line">board # test_sensor_calib --msc-ini-file sensor_calib_ini_rgb_thermal.ini</div>
</div><!-- fragment --></li>
</ol>
<p >After calibration, the application reports the messages as shown below. Users can use it to crop the RGB channel's fusion source buffer. </p><div class="fragment"><div class="line">Channel [0] Configuration:</div>
<div class="line">Canvas: output: size [2304x1712]</div>
<div class="line">RGB and thermal calibration result: input offset 216, 282, w / h 1680, 1260</div>
</div><!-- fragment --><p> [2304x1712] is the RGB channel's main buffer size. <br  />
</p>
<p >Users can change the Lua option "srcbuf_to_fusion" to specify which source buffer from the RGB channel to fuse with the thermal channel main buffer. <br  />
 Note that the thermal channel main buffer only performs upscaling / downscaling during thermal RGB fusion. <br  />
 After entering the preview with the applied calibration result through the Lua configuration, apply LDC parameters for the RGB channel concurrently. <br  />
 If users want to obtain a fused image with a resolution of 640x480, "scale-reso" option should be modified accordingly. Apply the calibration result above to the RGB channel. <br  />
 In the following Lua configuration, RGB channel-1 in the fifth buffer is chosen for the RGB fusion source buffer through specifying "srcbuf_to_fusion = 4".</p>
<div class="fragment"><div class="line">chan_1 = {</div>
<div class="line">    <span class="keywordtype">id</span> = 1,</div>
<div class="line">....</div>
<div class="line">    srcbuf_to_fusion = 4,</div>
<div class="line">    fifth = {</div>
<div class="line">        max_output = {2304, 1712},</div>
<div class="line">        input      = {0, 0, 0, 0},</div>
<div class="line">        output     = {0, 0, 2304, 1712},</div>
<div class="line">    },</div>
<div class="line">....</div>
<div class="line">    fifth = {</div>
<div class="line">        max_output = {1088, 976},</div>
<div class="line">        input      = {216, 282, 1680, 1260},</div>
<div class="line">        output     = {0, 0, 640, 480},</div>
<div class="line">    },</div>
<div class="line">....</div>
<div class="line">}</div>
</div><!-- fragment --><p >input_offset: 216 x 282 from RGB VIN domain. input_width * input_hegith: 1680 * 1260: After configuration, users can run the command to apply the calibration results. </p><div class="fragment"><div class="line">board # mv back_end/cali_warp_0 back_end/cali_warp_1 (change dewarp parameters <span class="keywordflow">for</span> RGB)</div>
<div class="line">board # test_stitch --mode 2 -f ./ --no-overlap --fuse-<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> 2 -c 0</div>
</div><!-- fragment --><hr  />
<h1><a class="anchor" id="sensor_calib_mono_rgb"></a>
4. Mono and RGB Sensor Calibration</h1>
<div class="image">
<img src="../../mono_rgb.jpg" alt=""/>
<div class="caption">
Figure 4-1. Mono and RGB Sensor Calibration.</div></div>
<p> For mono and RGB sensor fusion applications, users must align the field of view (FoV) of the mono image with the FoV of the RGB image before combining them. The tool can support automatic alignment calibration for the application. Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calib_prepare_board">2.1.2 Board Calibration Tool</a> for setting in menuconfig. <br  />
 The flow of the mono and RGB sensor calibration is as follows: <br  />
</p><ol type="1">
<li>Capture RGB and mono channels' dataset. <br  />
</li>
<li>Perform lens calibration if the lens' distortion is large. <br  />
 Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">3. Lens Calibration</a> for more details. <br  />
</li>
<li>There are a few methods for the users to perform the calibration. <br  />
 a) Perform the calibration by detecting keypoints automatically. <br  />
 As the keypoint extraction algorithm runs very slowly on Arm®, <br  />
 the user can adjust the "extract_match_ratio" and "thread-num" options to perform the acceleration. <br  />
 As keypoint detection and matching quality is related to image quality, <br  />
 users can change some options to obtain enough matching pairs in different testing environments. <br  />
 Adjust the "cali_keypoints_method" option to choose the point detection algorithm; the tool supports the Akaze / Orb / Sift detection methods. <br  />
 Adjust the "detect_thresh" option to get more keypoints in each image. <br  />
 Adjust "octaves" / "sublevels" to control the image pyramid levels for the AKAZE algorithm. <br  />
 Adjust the "knn_thresh" option for more matching keypoints numbers. <br  />
 Adjust the "ransac_thresh" option to remove outliers and improve the calibration accuracy. <br  />
 Adjust "x_offset_ratio" and "y_offset_ratio" options to remove outliers in the horizontal / vertical directions. <br  />
 The default value is 0.1. If the coordinate difference is larger than width * x_offset_ratio / height * y_offset_ratio, the outliers will be removed. <br  />
</li>
</ol>
<div class="image">
<img src="../../mono_rgb_four_points.jpg" alt=""/>
<div class="caption">
Figure 4-2. Use Four Points to Calculate the Homography Matrix.</div></div>
<p> The image demonstrates using four pairs of points from keypoint extraction to calculate the homography matrix. <br  />
 Set "use_four_points" to 1 in order to choose the feature. <br  />
 When taking snapshots of the calibration pattern, ensure that at least one pair of matching points are placed in each area, as shown below: <br  />
 (&lt; center_x, &lt; center_y), (&gt; center_x, &lt; center_y), (&lt; center_x, &gt; center_y), (&gt; center_x, &gt; center_y). <br  />
 Otherwise, the tool will receive a failure. Refer to <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_cfg"><ol type="1">
<li>Calibration Configration File Descriptions</li>
</ol>
</a> for more details. <br  />
</p>
<p >b) Perform the calibration using April tags. If users want to find four pairs of points to calculate the homography matrix without automatic keypoint detection, they can use four April tags to reach such a target. <br  />
 </p><div class="image">
<img src="../../april_tag_in_four_corner.jpg" alt=""/>
<div class="caption">
Figure 4-3. April Tag Distribution.</div></div>
<p> The image shows four April tags that are placed in the corners of the pattern. <br  />
 The April tags can be found from <a href="https://github.com/AprilRobotics/apriltag-imgs">https://github.com/AprilRobotics/apriltag-imgs</a>, and tag16h5 is shown in the image. Users can add the four April tags to their own calibration pattern board. <br  />
 When taking snapshots of the pattern, ensure that at least one pair of matching points are placed in each area as follows: <br  />
 (&lt; center_x, &lt; center_y), (&gt; center_x, &lt; center_y), (&lt; center_x, &gt; center_y), (&gt; center_x, &gt; center_y). <br  />
 Otherwise, the tool will receive a failure. The option "use_april_tag" is to be used for this method.</p>
<p >Perform mono and RGB sensor calibration with the following commands. <br  />
 </p><div class="fragment"><div class="line">1. Calibration:</div>
<div class="line">Set no_dist_flag = 0 <span class="keywordflow">if</span> the distortion has been calibrated.</div>
<div class="line">Case 1: use April tag to perform the calibration.</div>
<div class="line">board # test_sensor_calib --msc-ini-file sensor_calib_ini_rgb_mono_apri.ini</div>
<div class="line"> </div>
<div class="line">Case 2: use the Orb feature extraction method to perform the calibration.</div>
<div class="line">board # test_sensor_calib --msc-ini-file sensor_calib_ini_rgb_mono.ini</div>
<div class="line"> </div>
<div class="line">2. Apply calibration results.</div>
<div class="line">a) If <span class="stringliteral">&quot;no_dist_flag=1&quot;</span> is used:</div>
<div class="line">board # mv back_end/cali_warp_0 back_end/cali_warp_1</div>
<div class="line">board # test_stitch --mode 2 -f . --no-overlap --fuse 2 -c 0</div>
<div class="line"> </div>
<div class="line"><a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a>) If <span class="stringliteral">&quot;no_dist_flag=0&quot;</span> is used:</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 2 -f ./</div>
<div class="line">board # test_stitch  --mode 2 -f . --no-overlap --fuse 3</div>
<div class="ttc" id="acJSON_8h_html_a1a175e87536301df98c805ac0636ad7c"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a></div><div class="ttdeci">const cJSON *const b</div><div class="ttdef"><b>Definition:</b> cJSON.h:255</div></div>
</div><!-- fragment --><ol type="1">
<li>If users have performed the calibration by themselves and want to apply the homography matrix to the specific channel, use the following command: <div class="fragment"><div class="line">board # test_sensor_calib --mode 1 -i 0 --no-distort --H_matrix 0.9977401365552157,-0.000099578</div>
<div class="line">23263696219,2.775830523841213,-0.0001202783377077572,0.9971905736384313,1.376427136930342,-</div>
<div class="line">0.0000001840078883173892,-0.000000157500677787866,1 --cali-type 0 -w 2688 -h 1520 -f .</div>
<div class="line">configure the lua as the tool reports, and run :</div>
<div class="line">board # mv back_end/cali_warp_0 back_end/cali_warp_1</div>
<div class="line">board # test_stitch --mode 2 -f . --no-overlap --fuse 2  -c 0</div>
</div><!-- fragment --></li>
</ol>
<hr  />
<h1><a class="anchor" id="sensor_calib_tool_usage"></a>
5. Tool Usage</h1>
<ul>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_tool_usage_function">5.1 Feature Usage</a></li>
<li>Section <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#calib_2dwarp_gen_tool_usage">5.2 Generate 2D Warp Table via Calib-Param</a></li>
</ul>
<h2><a class="anchor" id="sensor_calib_tool_usage_function"></a>
5.1 Feature Usage</h2>
<p >The tool supports other basic features for customers to use.</p>
<p ><b>Example</b> 1: Apply an H matrix on a specific channel </p><div class="fragment"><div class="line">board # test_sensor_calib --mode 1 -i 0 --no-distort</div>
<div class="line">      --H_matrix 0.998323,-0.000051,4.251321,-0.000663,0.997634,-1.634829,-0.000000,-0.000001,1.000001</div>
<div class="line">      --cali-type 0 -w 2560 -h 1440 -f .</div>
<div class="line">board # test_stitch --mode 2 -f /root --no-overlap --verbose --fuse-<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> 1  -c 0</div>
</div><!-- fragment --><p ><b>Example</b> 2: RGBD alignment matrix / reprojection matrix calibration </p><div class="fragment"><div class="line">board # test_sensor_calib --mode 1 --yuv-file 0.yuv_canvas0_640x480_IYUV.yuv,2.yuv_canvas2_1920x1080_IYUV.yuv</div>
<div class="line">-f /root --pattern 1 --chessboard-size 5,3 -i 0 -w 640 -h 480 -i 1 -w 1920 -h 1080 --cali-type 3</div>
<div class="line">board # test_sensor_calib --mode 0  -i 1 --map-point 282,129 -f . (map point from one image to the other)</div>
</div><!-- fragment --><p ><b>Example</b> 3: Mono sensor extrinsic calibration </p><div class="fragment"><div class="line">board # test_sensor_calib --mode 1  --yuv-file 0.yuv_canvas0_3840x2160_IYUV.yuv -i 0 -w 3840 -h 2160 --cali-type 4</div>
<div class="line">--pattern 1 --chessboard-size 5,3 --mode 1 -f /root -s 0.058</div>
</div><!-- fragment --><h2><a class="anchor" id="calib_2dwarp_gen_tool_usage"></a>
5.2 Generate 2D Warp Table via Calib-Param</h2>
<p >When performing lens distortion correction (LDC) or other image remapping operations, the Ambarella digital signal processor (DSP) requires a unique format warp table. Users must implement a user application to convert sensor calibration parameters to an Ambarella warp table. Ambarella provides a sample application, calib_2d_warp_gen.cpp, which reads a calibration parameter file and generates the corresponding 2D-warp table bin file. Users can refer to it to implement their own application. Developers must focus on two funtions: gen_remap_stereo_param and transfer_to_s12_4_vector. Using the example tool, the command is as follows.</p>
<dl class="section note"><dt>Note</dt><dd>Do not perform any round_up / round_down / truncating to the parameters of the calibration results when generating 2D warp table from calibration results on the PC side. Otherwise, it will cause negative side effects to the final dewarped image.</dd></dl>
<p><b>Example</b> 1: Build calib_2d_warp_gen</p>
<ul>
<li>For software development kit (SDK) 3.0 Amba build: <div class="fragment"><div class="line">build $ make menuconfig</div>
<div class="line">build $ [*] Ambarella Prebuild  ---&gt;</div>
<div class="line">build $     [*]   Configure Ambarella sensor calibration library  ---&gt;</div>
<div class="line">build $         [*]   Configure Generate 2D-Calib Warp Table</div>
<div class="line">build $ make</div>
</div><!-- fragment --></li>
<li>For Cooper Amba build <div class="fragment"><div class="line">build # make menuconfig</div>
<div class="line">  prebuild ---&gt;</div>
<div class="line">      library  ---&gt;</div>
<div class="line">          [*] prebuild-sensorcalib (prebuild/library/multi_sensor_calib/dsp_v6)</div>
</div><!-- fragment --></li>
<li>For Cooper Yocto build: <div class="fragment"><div class="line">build # make menuconfig</div>
<div class="line">     meta-ambalib  ---&gt;</div>
<div class="line">         recipes-prebuild  ---&gt;</div>
<div class="line">             [*] prebuild-sensorcalib (meta-ambalib/recipes-prebuild/prebuild-sensorcalib)</div>
</div><!-- fragment --> <b>Example</b> 2: Run calib_2d_warp_gen <div class="fragment"><div class="line">board # calib_2d_warp_gen -f sensor_calib_ini_stereo.ini -o ./ --res_l 1920x1080 --res_r 1920x1080</div>
<div class="line">board #     <span class="comment">//res_l or res_r represents the sensor resolution.</span></div>
</div><!-- fragment --></li>
</ul>
<hr  />
<h1><a class="anchor" id="sensor_calib_api"></a>
6. Sensor Calibration API</h1>
<p >Visit the following link for details of the application programming interface (API) functions.</p><ul>
<li><a class="el" href="../../d2/d55/group__lib-sensor-helper.html">Sensor Calibration Library API Helper</a> shows related macros and enumerations.</li>
<li><a class="el" href="../../da/d11/group__lib-sensor-api.html">Sensor Calibration Library API Detail</a> shows related APIs.</li>
</ul>
<hr  />
<h1><a class="anchor" id="sensor_calib_lic"></a>
7. License</h1>
<p >Copyright (c) 2024 Ambarella International LP.</p>
<p >This file and its contents ( "Software" ) are protected by intellectual property rights including, without limitation, U.S. and/or foreign copyrights. This Software is also the confidential and proprietary information of Ambarella International LP and its licensors. You may not use, reproduce, disclose, distribute, modify, or otherwise prepare derivative works of this Software or any portion thereof except pursuant to a signed license agreement or nondisclosure agreement with Ambarella International LP or its authorized affiliates. In the absence of such an agreement, you agree to promptly notify and return this Software to Ambarella International LP.</p>
<p >THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL AMBARELLA INTERNATIONAL LP OR ITS AFFILIATES BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; COMPUTER FAILURE OR MALFUNCTION; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3 </li>
  </ul>
</div>
</body>
</html>
