<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Library: VPROC Library API</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<link rel="search" href="../../search_opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Library"/>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="../../../library/mathjax/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-ambarella.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../Ambarella.png"/></td>
  <td id="projectalign">
   <div id="projectname">Library<span id="projectnumber">&#160;Cooper_1.6.0 (CV72 &amp; CV3) @ 2024.07.10 14:12:44</span>
   </div>
   <div id="projectbrief">placeholder</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,true,'search.html','Search');
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d1/d66/page_lib_vproc_doc.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">VPROC Library API </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="vproc_history"></a>
0. Revision History</h1>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Library Version   </th><th class="markdownTableHeadLeft">Updated Date   </th><th class="markdownTableHeadLeft">Modification    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">0.0.1   </td><td class="markdownTableBodyLeft">20200630   </td><td class="markdownTableBodyLeft">Initial Version    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">0.1.4   </td><td class="markdownTableBodyLeft">20210125   </td><td class="markdownTableBodyLeft">Support 1)alpha blending; 2)rgb2yuv; 3)transpose; 4)abs calculation; 5)cclb; 6)bayer2bgr    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">0.1.5   </td><td class="markdownTableBodyLeft">20210422   </td><td class="markdownTableBodyLeft">Support flatten    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">0.1.6   </td><td class="markdownTableBodyLeft">20210616   </td><td class="markdownTableBodyLeft">Support bitwise logical operation    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">0.1.8   </td><td class="markdownTableBodyLeft">20210718   </td><td class="markdownTableBodyLeft">Support dsi fusion scale0 with shifted    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">0.1.9   </td><td class="markdownTableBodyLeft">20210928   </td><td class="markdownTableBodyLeft">Upgrade vproc.bin with cavalry_gen version 2.2.8.3    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">0.1.9   </td><td class="markdownTableBodyLeft">20220221   </td><td class="markdownTableBodyLeft">1. Add VProc performance information of CV22<br  />
2. Split APIs into two groups that use physical address and use memory file descriptor    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">0.1.9   </td><td class="markdownTableBodyLeft">20220823   </td><td class="markdownTableBodyLeft">1. Support vproc FBM, <a class="el" href="../../d1/d66/page_lib_vproc_doc.html#vproc_library_test_vproc_fbm">2.1.35 test_vproc_fbm</a>. <br  />
 2. Support Point Cloud Rendering,<a class="el" href="../../d1/d66/page_lib_vproc_doc.html#vproc_library_test_vproc_render3d">2.1.33 test_vproc_render3d_live</a>.    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">0.1.9   </td><td class="markdownTableBodyLeft">20221101   </td><td class="markdownTableBodyLeft">Update the descriptions about FBM and dfilter    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">0.2.0   </td><td class="markdownTableBodyLeft">20221216   </td><td class="markdownTableBodyLeft">Add log level support    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">0.2.0   </td><td class="markdownTableBodyLeft">20230214   </td><td class="markdownTableBodyLeft">Add rotate with mvproc.bin for CV28 and CV25    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">0.2.0   </td><td class="markdownTableBodyLeft">20230224   </td><td class="markdownTableBodyLeft">Support dsfilter, update the descriptions about FBM    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">0.2.0   </td><td class="markdownTableBodyLeft">20230308   </td><td class="markdownTableBodyLeft">Support pre-process of FBM, add the descriptions about FBM process pipeline    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">0.2.0   </td><td class="markdownTableBodyLeft">20230315   </td><td class="markdownTableBodyLeft">Refine VProc page    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">3.0.0   </td><td class="markdownTableBodyLeft">20230615   </td><td class="markdownTableBodyLeft">Enable Harris for CV72    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">3.0.0   </td><td class="markdownTableBodyLeft">20230625   </td><td class="markdownTableBodyLeft">Enable Render3d for CV72    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">3.0.0   </td><td class="markdownTableBodyLeft">20230710   </td><td class="markdownTableBodyLeft">Support CV72, using cavalry_gen version 3.0.2    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">3.0.0   </td><td class="markdownTableBodyLeft">20230724   </td><td class="markdownTableBodyLeft">Expand the maximal input resolution of cvfilter from 1080p to 4096x4096 for CV2x / CV72    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">3.0.0   </td><td class="markdownTableBodyLeft">20230725   </td><td class="markdownTableBodyLeft">Add performance improvement guidance for CV72 resize    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">3.0.0   </td><td class="markdownTableBodyLeft">20230831   </td><td class="markdownTableBodyLeft">Enable FBM and related pre-process and post-process filters for CV72    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">3.0.0   </td><td class="markdownTableBodyLeft">20230926   </td><td class="markdownTableBodyLeft">Update FBM performance for CV72   </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="vproc_introduction"></a>
1. Introduction</h1>
<p >VProc stands for CVflowâ„¢ vector processor (VP), which manages operations and mathmatical calculations whose performance can be boosted utilizing Ambarella CVflow chips. Here, the majority of the heavy calculations are carried out on the CVflow vector processor.</p>
<p >The VProc library is based on the Cavalry driver. Users should first enable the Cavalry driver, and then enable the VProc library. Follow the commands below to build the library:</p>
<ul>
<li>For CV2x SDK 3.0 Amba build: <div class="fragment"><div class="line">build # make menuconfig</div>
<div class="line">         [*] Ambarella Package Configuration  ---&gt;</div>
<div class="line">             [*]   Build Ambarella vp process library</div>
</div><!-- fragment --></li>
<li>For Cooper Amba build: <div class="fragment"><div class="line">build # make menuconfig</div>
<div class="line">         packages  ---&gt;</div>
<div class="line">             [*] libvproc (packages/vproc)</div>
</div><!-- fragment --></li>
<li>For Cooper Yocto build: <div class="fragment"><div class="line">build # make menuconfig</div>
<div class="line">         meta-ambalib  ---&gt;</div>
<div class="line">             recipes-cavalry  ---&gt;</div>
<div class="line">                [*] libvproc (meta-ambalib/recipes-cavalry/libvproc)</div>
</div><!-- fragment --></li>
</ul>
<p >To verify pre-defined algorithms in the VProc library, such as the algorithm cvfilter, follow the commands below to build the unit tests:</p>
<ul>
<li>For CV2x SDK 3.0 Amba build: <div class="fragment"><div class="line">build # make menuconfig</div>
<div class="line">         [*] Ambarella Unit Test Configuration  ---&gt;</div>
<div class="line">             [*]   Ambarella Private Linux Unit test configs  ---&gt;</div>
<div class="line">                [*]   Build CV unit tests  ---&gt;</div>
<div class="line">                   [*]   Build vproc algorithm unit test</div>
</div><!-- fragment --></li>
<li>For Cooper Amba build: <div class="fragment"><div class="line">build # make menuconfig</div>
<div class="line">         unit_test  ---&gt;</div>
<div class="line">             <span class="keyword">private</span>  ---&gt;</div>
<div class="line">                 [*] cv-test (unit_test/<span class="keyword">private</span>/cv_test/cavalry_v2)  ---&gt;</div>
<div class="line">                     [*]   Build VP Profile unit tests</div>
</div><!-- fragment --></li>
<li>For Cooper Yocto build: <div class="fragment"><div class="line">build # make menuconfig</div>
<div class="line">         meta-ambaapp  ---&gt;</div>
<div class="line">             recipes-test  ---&gt;</div>
<div class="line">                 [*] cv-test (meta-ambaapp/recipes-test/cv-test)  ---&gt;</div>
<div class="line">                     [*]   Build vproc algorithm unit tests</div>
</div><!-- fragment --> <hr  />
</li>
</ul>
<h1><a class="anchor" id="vproc_library_example_usage"></a>
2. Example Usage</h1>
<h2><a class="anchor" id="vproc_library_test_vproc"></a>
2.1 VProc Unit Test Application</h2>
<p >Dozens of unit test applications are provided for VProc library verificaiton. DMABuf is supported for each feature, with a postfix "mfd" in its corresponding unit test. Users can reference them as the sample code when writing applications. Enable the Cavalry driver before running a VProc unit test with the command below.</p>
<dl class="section note"><dt>Note</dt><dd>The following live demos may not function on CV5x. Refer to the CV5x Feature Sets document for more details if using a CV5x platform. <div class="fragment"><div class="line">board # cavalry_load -f /lib/firmware/cavalry.bin -r</div>
</div><!-- fragment --></dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_yuv2rgb"></a>
2.1.1 test_vproc_yuv2rgb</h3>
<p >The test_vproc_yuv2rgb uses the VProc library to convert YUV images to RGB images. By default, the test converts YUV (NV12) images to RGB images. The available options of test_vproc_yuv2rgb are as follows: </p><pre class="fragment">  -b --bin          Path to bin binary
  -i --input        Path to YUV input binary
  -o --output       Path to output binary
  -s --resolution   Image resolution [WxH]
  -p --pitch        Image pitch
  -R --ROI          ROI of input image, [x_offset],[y_offset],[width],[height]
  -y --yuv_format   YUV format, 10: NV12. Default is NV12 format
  -r --rgb_format   RGB format, 0: RGB; 1: BGR. Default is RGB
  -m --feed_mem     Feed VProc binary by memory instead of filename; default is disabled
  -t --time         Measure runtime
</pre><p >One example is provided using the command below: </p><div class="fragment"><div class="line">board # test_vproc_yuv2rgb -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/yuv1080p.bin -o /tmp/rgb1080p.bin -s 1920x1080</div>
<div class="ttc" id="acJSON_8h_html_a1a175e87536301df98c805ac0636ad7c"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a></div><div class="ttdeci">const cJSON *const b</div><div class="ttdef"><b>Definition:</b> cJSON.h:255</div></div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_resize"></a>
2.1.2 test_vproc_resize</h3>
<p >The test_vproc_resize application can resize gray, UV-interleaved, RGB, and YUV images to specified-resolution images with the same color space. Users are free to choose the resize strategy, which could be either multiple steps or a single step in order to approach the targeted ratio. The available test_vproc_resize options are listed below: </p><pre class="fragment">  -b --bin              Path to bin binary
  -i --input            Path to input binary
  -o --output           Path to output binary
  -s --in_resolution    Input image resolution [WxHxD]
  -p --in_pitch         Input image pitch
  -R --ROI              Input image ROI, [x_offset],[y_offset],[width],[height]
  -S --out_resolution   Output image resolution [WxHxD]
  -P --out_pitch        Output image pitch
  -c --cspace           Image color space. 0: VECT; 1: RGB; 2: BGR; 10: NV12; 11: Y; 12: ITL; default is 0 (VECT)
  -m --method           Resize method. 0: mul-step; 1: sin-step; default is 0
  -t --time             Measure runtime
</pre><p >Below is an example of resizing an RGB image with an region of interest (ROI), where only the ROI would be taken into account. </p><div class="fragment"><div class="line">board # test_vproc_resize -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/rgb1080p.bin -o /tmp/rgb720p.bin -s 1920x1080x3 -S 1280x720x3 -c 1 -R 100,100,640,480</div>
</div><!-- fragment --><p >Resizing on CV72 and CV3 provides a certain degree of parallelism on the channel dimension. Performance improvement can be achieved if data with the same input / output resolution and ROI settings can be combined in the channel dimension and executed together. For instance, it takes almost the same time to resize RGB image as grayscale image (when channel-promotion is not applicable).</p>
<p >On CV72 and CV3, channel-promotion optimization is also introduced to accelerate resizing performance. It is however only applicable to planar input data, and in cases where:</p><ul>
<li>The height dimension is being down-sampled ( output height &lt;= input height )</li>
<li>The scale factor in the height dimension can be represented by 13 fractional bits ( (input height &lt;&lt; 13) % output height) == 0 )</li>
<li>The input height and output height have a common divisor within [2, 43]</li>
</ul>
<p >Ambarella recommends that users design use cases in such a manner that they can profit from channel-promotion optimization, as the improvement in performance is substantial. For example, resizing RGB 1920x1080 to 1280x720 requires 700 us when channel-promotion is enabled by default. When this optimization is disabled, it requires 3600 us.</p>
<p >The channel-promotion feature is enabled by default. The VProc library provides an option to disable this optimization if there is a decrease in performance. </p><dl class="section note"><dt>Note</dt><dd>Multi-step resize is not yet supported on CV72. </dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_submean"></a>
2.1.3 test_vproc_submean</h3>
<p >The test_vproc_submean application subtracts a mean value from the input data by channel or by pixel. Input data, mean data, and output data should be represented as either fixed 8-bit values or fixed 16-bit values. The available options of test_vproc_submean are as follows: </p><pre class="fragment">  -b --bin               Path to bin binary
  -i --input             Path to data input binary
  -m --mean              Path to mean input binary
  -o --output            Path to output binary
  -s --in_resolution     Input data resolution [WxHxD]
  -p --in_pitch          Input data pitch
  -S --mean_resolution   Mean data resolution WxHxD
  -P --mean_pitch        Mean data pitch
  -I --in_df             Input data format [sign] [datasize] [exp_offset] [exp_bits]. 0,0,0,0 stands for uint8. Default is 0,0,0,0. FP16 is 1,1,0,4
  -M --mean_df           Mean data format [sign] [datasize] [exp_offset] [exp_bits]. 0,0,0,0 stands for uint8. Default is 0,0,0,0. FP16 is 1,1,0,4
  -O --out_df            Output data format [sign] [datasize] [exp_offset] [exp_bits]. 0,0,0,0 stands for uint8. Default is 1,0,0,0. FP16 is 1,1,0,4
  -t --time              Measure runtime
</pre><p >Follow the example to perform channel-wise mean subtraction. </p><div class="fragment"><div class="line">board # test_vproc_submean -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/rgb720p.bin -o /tmp/norm.bin -m /tmp/mean.bin -s 1280x720x3 -S 1x1x3 -I 0,0,0,0 -M 0,0,0,0 -O 1,0,0,0</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_scale"></a>
2.1.4 test_vproc_scale</h3>
<p >The test_vproc_submean scales the input data by multiplying it with a scale factor, which can be used to normalize the image data to a defined range. Input data and output data should be represented as fixed 8-bit or 16-bit values. The available test_vproc_scale options are as follows: </p><pre class="fragment">  -b --bin             Path to bin binary
  -i --input           Path to data input binary
  -o --output          Path to output binary
  -s --in_resolution   Input data resolution [WxHxD]
  -p --in_pitch        Input data pitch
  -I --in_df           Input data format [sign] [datasize] [exp_offset]. 0,0,0,0 stands for uint8. Default is 0,0,0,0
  -r --scale           Scale factor
  -O --out_df          Output data format [sign] [datasize] [exp_offset]. 0,0,0,0 stands for uint8. Default is 0,0,0,0
  -t --time            Measure runtime
</pre><p >Use the command below to scale fixed 8-bit input data with a provided scale factor. Both input and output data must be set by the user. </p><div class="fragment"><div class="line">board # test_vproc_scale -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/rgb720p.bin -o /tmp/out.bin -s 1280x720x3 -I 0,0,0,0 -r 0.00390625 -O 0,0,8,0</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_dtcvt"></a>
2.1.5 test_vproc_dtcvt</h3>
<p >The test_vproc_submean applicaiton converts data among the FX8 / FX16 / FP16 / FP32 formats. Note that output data can overflow if the Q in the data format is not correctly set. The available test_vproc_dtcvt options are as follows: </p><pre class="fragment">  -b --bin             Path to bin binary
  -i --input           Path to data input binary
  -o --output          Path to output binary
  -s --in_resolution   Input data resolution [WxHxD]
  -p --in_pitch        Input data pitch
  -P --out_pitch       Output data pitch
  -I --in_df           Input data format [sign] [datasize] [exp_offset] [exp_bits]. 0,0,0,0 stands for uint8. Default is 0,0,0,0. FP16 is 1,1,0,4
  -O --out_df          Output data format [sign] [datasize] [exp_offset] [exp_bits]. 0,0,0,0 stands for uint8. Default is 0,0,0,0. FP16 is 1,1,0,4
  -t --time            Measure runtime
</pre><p >The test_vproc_dtcvt application is able to convert fixed 8-bit data to fixed 16-bit data by setting the corresponding data format with the command below. </p><div class="fragment"><div class="line">board # test_vproc_dtcvt -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /tmp/vproc.bin -i /tmp/rgb720p.bin -o /tmp/out.bin -s 1280x720x3 -I 0,0,0,0 -O 0,1,0,0</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_rotate"></a>
2.1.6 test_vproc_rotate</h3>
<p >The test_vproc_rotate applicaiton rotates / flips a fixed 8-bit image by providing a rotate-flip bit map. The available test_vproc_rotate options are as follows: </p><pre class="fragment">  -b --bin              Path to bin binary
  -i --input            Path to input binary
  -o --output           Path to output binary
  -s --in_resolution    Input image resolution WxHXD
  -p --in_pitch         Input image pitch
  -S --out_resolution   Output image resolution WxHXD
  -P --out_pitch        Output image pitch
  -c --color_space      Image color space. 0: VECT; 1: RGB; 2: BGR; 10: NV12; 11: Y; 12: ITL; Default is 0 (VECT)
  -f --rotate_flip      Set input port rotate-flip bit map. Specify bitmap order (High -&gt; Low):
                         3: dflip; 2: vflip; 1: hflip; 0: rotate. For example: vflip+rotate: 0x05 (00101)
  -t --time             Measure run time
</pre><p >Follow the example below to rotate an image 90 degrees: </p><div class="fragment"><div class="line">board # test_vproc_rotate -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/head1080p.bin -o /tmp/head_rot.bin -s 1920x1080x3 -S 1080x1920x3 -f 0x1</div>
</div><!-- fragment --><p >Rotate an image 180 degrees by simultaneously flipping an image horizontally and vertically: </p><div class="fragment"><div class="line">board # test_vproc_rotate -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/head1080p.bin -o /tmp/head_rot.bin -s 1920x1080x3 -S 1920x1080x3 -f 0x6</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_preproc"></a>
2.1.7 test_vproc_preproc</h3>
<p >The test_vproc_rotate application performs pre-processing operations in a chain, either starting image deformation (such as YUV2RGB and resize) or data processing (such as mean substraction and scaling). The available test_vproc_preproc options are as follows: </p><pre class="fragment">  -b --bin      Path to bin binary
  -m --mode     Modes to run image_deformation or data_polish. Default is 0
                  0: Image deformation; manages YUV2RGB, resize, cropping, and more
                  1: Data polish; manages submean, scaling, data type conversion, and more
     --in       Path to data input binary
     --out      Path to output binary
     --avg      Path to mean input binary
     --ires     Input data resolution [WxHxD]. Default is 1280x720x3
     --ipch     Input data pitch
     --ares     Mean data resolution [WxHxD]
     --apch     Mean data pitch
     --ores     Output data resolution [WxHxD]. Default is 1280x720x3
     --opch     Output data pitch
     --ics      Input color space. Default is 0
                  0: General vector; 1: RGB; 2: BGR; 3: NV12; 4: Y
     --ocs      Output color space. Default is 0
                  0: General vector; 1: RGB; 2: BGR; 3: NV12; 4: Y
  -R --roi      ROI of input image, [x_offset],[y_offset],[width],[height]
  -r --scale    Scale factor
  -I --in_df    Input data format [sign],[datasize],[exp_offset],[exp_bits]. 0,0,0,0 stands for uint8. FP16 is 1,1,0,4. Default is 0,0,0,0
  -O --out_df   Mean data format [sign],[datasize],[exp_offset],[exp_bits]. 0,0,0,0 stands for uint8. FP16 is 1,1,0,4. Default is 0,0,0,0
  -A --avg_df   Output data format [sign],[datasize],[exp_offset],[exp_bits]. 0,0,0,0 stands for uint8. FP16 is 1,1,0,4. Default is 0,0,0,0
  -t --time     Print runtime
  -h --help     Print help information
</pre><p >Follow the test_vproc_preproc example below to use the YUV image as an input and perform YUV2RGB, cropping, and resize operations in order to generate an RGB image as a defined ROI. </p><div class="fragment"><div class="line">board # test_vproc_preproc -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin --in /tmp/yuv1080.bin --ires 1920x1080x3 --ics 3 --out /tmp/out.bin --ores 1280x720x3 --ocs 1 -R 0,200,1280,720 -m 0</div>
</div><!-- fragment --><p >Use test_vproc_preproc to manage mean substration, scaling, and data type conversion in one call, as shown in the example below. </p><div class="fragment"><div class="line">board # test_vproc_preproc -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin --in /tmp/cvt720_fx8.bin --ires 1280x720x3 -ics 0 -I 0,0,0,0 --avg /tmp/cvt720_fx16.bin --ares 1280x720x3 -A 0,1,1,0 --out /tmp/out.bin --ores 1280x720x3 -O 0,0,2,0 --ocs 0 -r 0.5 -m 1</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_harris"></a>
2.1.8 test_vproc_harris</h3>
<p >The test_vproc_harris application performs two-image matching using detected Harris points with BRIEF descriptors. The available test_vproc_harris options are as follows: </p><pre class="fragment">  -b   File path to vproc.bin
  -l   File path to left image file
  -r   File path to right image file
  -o   Output folder path
  -s   Resize the input image, image in [WxH] format; supports 1920x1080,1280x720 and 720x640
  -t   Harris response threshold
  -n   Maximum number of the Harris points
</pre><p >Follow the example below to use test_vproc_harris to perform two-image resizing to 1080p. Then, perform Harris point detection and Harris point matching. </p><div class="fragment"><div class="line">board # test_vproc_harris -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -l left.jpg -r right.jpg -o /tmp -s 1920x1080 -t 0.01 -n 1000</div>
</div><!-- fragment --> <div class="image">
<img src="../../harris_match.jpg" alt=""/>
<div class="caption">
Figure 2-1. Harris Point Matching.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_harris_live"></a>
2.1.9 test_vproc_harris_live</h3>
<p >This is a live demo that performs Harris point detection and screen illustration. It only supports two input resolutions: 1920x1080 and 720x640. The available test_vproc_harris_live options are as follows: </p><pre class="fragment">  -t   Harris point response threshold
  -n   Maximum number of Harris points
  -w   Set non-maximum suppression (NMS) window size
</pre><p >Follow the example below to perform Harris point detection and to draw boxes for each Harris point on the screen. </p><div class="fragment"><div class="line">board # test_vproc_harris_live -t 0.01 -n 2000 -w 28</div>
</div><!-- fragment --> <div class="image">
<img src="../../harris_live_result.gif" alt=""/>
<div class="caption">
Figure 2-2. Live Harris Detection.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_perspective"></a>
2.1.10 test_vproc_perspective</h3>
<p >The test_vproc_perspective application performs perspective warp using a given perspective projection matrix. The input resolution should be one of the following: 1/3x1280x800,1/3x1280x720, and 1/3x720x640. The available test_vproc_perspective options are as follows: </p><pre class="fragment">  -b     File path to vproc.bin
  -i     File path to the input image file
  -m     The perspective projection matrix whose size must be 3x3
  -o     Output folder path
  -s     Resize the input images. The format is in [CxWxH], which supports [1/3]x1280x800,[1/3]x1280x720 and [1/3]x720x640
</pre><p >The example below utilizes test_vproc_perspective to warp an image to a bird's-eye view. </p><div class="fragment"><div class="line">board # test_vproc_perspective -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i test.jpg -m [-0.46688,-1.89871,922.0,-0.06845,-3.18593,1304.6,-0.000059,-0.00311,1] -o /tmp -s 1x1280x800</div>
</div><!-- fragment --> <div class="image">
<img src="../../perspective_result.jpg" alt=""/>
<div class="caption">
Figure 2-3. Perspective Result.</div></div>
<dl class="section note"><dt>Note</dt><dd>CV72 is not supported yet. </dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_perspective_live"></a>
2.1.11 test_vproc_perspective_live</h3>
<p >The test_vproc_perspective_live application performs a perspective live demo. The available test_vproc_perspective_live options are as follows: </p><pre class="fragment">  -m   Perspective projection matrix whose size must be 3x3
  -s   Resizes input images in [1xWxH] format
</pre><p >Use the command below to run the live perspective demo. </p><div class="fragment"><div class="line">board # init.sh --na; modprobe imx274_mipi  (Need add extra module params <span class="keywordflow">for</span> cv5: vinc_id=8 bus_id=3 )</div>
<div class="line">board <span class="preprocessor"># test_aaa_service -a&amp;</span></div>
<div class="line">(cv2x command as below)</div>
<div class="line">board # test_encode -i0 --hdmi 1080p --ors 1920x1080 --enc-dummy-latency 2</div>
<div class="line">(or cv5 command as below, check inside vout_hdmi.lua,  selected vout osd_rescaler_output_window = {0, 0, 1920, 1080})</div>
<div class="line">board # test_encode -i0 cv5_vin0_1080p_linear.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua --enc-dummy-latency 2</div>
<div class="line">board # rmmod ambarella_fb</div>
<div class="line">board # modprobe ambarella_fb resolution=1920x1080 mode=clut8bpp buffernum=5</div>
<div class="line">board # test_vproc_perspective_live -m [-0.46688,-1.89871,922.0,-0.06845,-3.18593,1304.6,-0.000059,-0.00311,1] -s 1x1280x800</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>CV72 is not supported yet. </dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_cdist"></a>
2.1.12 test_vproc_cdist</h3>
<p >The test_vproc_cdist application performs cosine distance calculations. The available test_vproc_cdist options are as follows: </p><pre class="fragment">  -b   File path to vproc.bin
  -l   Input binary file path of data vector A
  -r   Input binary file path of data vector B
  -L   Data format of input file A
  -R   Data format of input file B
  -s   Vector input dimension [CxWxH]
</pre><p >The example below uses test_vproc_cdist to calculate the cosine distance between vector A and vector B. </p><div class="fragment"><div class="line">board # test_vproc_cdist -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -l vect_A.bin -r vect_B.bin -L ufix8_8 -R ufix8_8 -s 3x256x128</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_imhist"></a>
2.1.13 test_vproc_imhist</h3>
<p >The test_vproc_imhist application performs histogram analysis for a grayscale input image. The available test_vproc_imhist options are as follows: </p><pre class="fragment">  -b   File path to vproc.bin
  -i   The grayscale input image
  -n   Category: number of histograms
  -o   Output folder path
  -s   Resize input images in [WxH] format
</pre><p >The example below uses test_vproc_imhist to perform histogram calculations for a grayscale image. </p><div class="fragment"><div class="line">board # test_vproc_imhist -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i gray.jpg -n 256 -o /tmp -s 1920x1080</div>
</div><!-- fragment --> <div class="image">
<img src="../../imhist_result.jpg" alt=""/>
<div class="caption">
Figure 2-4. Image Histogram Result.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_imcvt"></a>
2.1.14 test_vproc_imcvt</h3>
<p >The test_vproc_imcvt application converts images to different formats, which are plane-interleaved and element-interleaved in the OpenCV format. The available test_vproc_imhist options are as follows: </p><pre class="fragment">  -b --bin             Path to bin binary
  -i --input           Path to input binary
  -o --output          Path to output binary
  -s --in_resolution   Input image resolution [WxH]
  -p --in_pitch        Input image pitch
  -P --out_pitch       Output image pitch
  -c --cvt_code        Image conversion code. 0: amb2ocv; 1: ocv2amb; default is 0 (amb2ocv)
  -t --time            Measure runtime
</pre><p >Follow the example below to convert an RGB image in Ambarella format to the OpenCV format using test_vproc_imcvt. </p><div class="fragment"><div class="line">board # test_vproc_imcvt -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/head1080p_amb.bin -o /tmp/head1080p_ocv.bin -s 1920x1080x3 -c 0</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_cvfilter"></a>
2.1.15 test_vproc_cvfilter</h3>
<p >The test_vproc_cvfilter application filters an input grayscale or color image with the provided filter kernel. The available test_vproc_cvfilter options are as follows: </p><pre class="fragment">  -b    File path to vproc.bin
  -i    Input grayscale / color image
  -o    Output folder path
  -s    Resize input images in [CxWxH] format
  -f    Filtering kernel size
  -k    Filtering kernel data. (Note: The same kernel applies to multiple input channels)
</pre><p >The example below applies an average filter on the input image. The average window size is 11x11 and the elements value is 1/(11*11) = 0.00826. </p><div class="fragment"><div class="line">board # test_vproc_cvfilter -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i img.JPEG -o /tmp -s 3x1920x1080 -f 11x11 -k [0.00826]</div>
</div><!-- fragment --> <div class="image">
<img src="../../cvfilter_result.jpg" alt=""/>
<div class="caption">
Figure 2-5. Average CVfilter Result.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_morph"></a>
2.1.16 test_vproc_morph</h3>
<p >The test_vproc_morph application applies dilation or erosion to a binarized / Luma image. The application supports dilate / erode / open / close, and can be used to delete the noisy points or fill the in-block hole. The available test_vproc_morph options are as follows: </p><pre class="fragment">  -b    File path to vproc.bin
  -i    Input binarized image
  -m    0: binary dilate; 1: binary erode; 2: Luma dilate; 3: Luma erode
  -o    Output folder path
  -s    Resize input images in [WxH] format
  -t    Binarization threshold (set -1 in Luma morph)
  -f    Morph kernel size
  -k    Morph kernel data
  -r    Anner of border replication. 0: same data replicated; 1: zero data replicated
</pre><p >The example provided below applies a morphological transformation. </p><div class="fragment"><div class="line">board # test_vproc_morph -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i pic1.jpg -m 0 -o /tmp -s 1920x1080 -t 127 -f 11x11 -r 0</div>
<div class="line">board # test_vproc_morph -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i pic1.jpg -m 1 -o /tmp -s 1920x1080 -t 127 -f 11x11 -r 1</div>
<div class="line">board # test_vproc_morph -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i pic1.jpg -m 2 -o /tmp -s 1280x720 -t -1 -f 5x5 -k [0,0,1,0,0,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,0,0,1,0,0]  -r 0</div>
<div class="line">board # test_vproc_morph -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i pic1.jpg -m 3 -o /tmp -s 1280x720 -t -1 -f 5x5 -k [0,0,1,0,0,0,1,1,1,0,1,1,1,1,1,0,1,1,1,0,0,0,1,0,0]  -r 1</div>
</div><!-- fragment --> <div class="image">
<img src="../../bin_morph_result.jpg" alt=""/>
<div class="caption">
Figure 2-6. Binary Morph (Orginal / Dilate / Erode) Result.</div></div>
 <div class="image">
<img src="../../luma_morph_result.jpg" alt=""/>
<div class="caption">
Figure 2-7. Luma Morph (Orginal / Dilate / Erode) Result.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_optlk"></a>
2.1.17 test_vproc_optlk</h3>
<p >The test_vproc_optlk application performs LK calculations on two continuous images. The available test_vproc_optlk options are as follows: </p><pre class="fragment">  -b   File path to vproc.bin
  -l   First input image
  -r   Second input image
  -o   Output folder path
  -s   Resize input images in [WxH] format
  -t   Threshold to the LK response (for details, see the application programming interface (API) vproc_optlk() )
  -z   With / without K coefficient. LK response value = det(M)-k*(trace(M))^2
  -w   LK window size
  -k   Windows kernel data; default is 1
  -d   Stride to draw the optical flow for pixels
</pre><p >Run the command below to perform LK calculations using test_vproc_optlk. </p><div class="fragment"><div class="line">board # test_vproc_optlk -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -l img0.jpg -r img1.jpg -o /tmp -s 160x90 -t 0.01 -w 11x11</div>
</div><!-- fragment --> <div class="image">
<img src="../../optflow_flow.jpg" alt=""/>
<div class="caption">
Figure 2-8. LK Optical Flow Result.</div></div>
<dl class="section note"><dt>Note</dt><dd>CV72 is not supported yet. </dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_optlk_flow_live"></a>
2.1.18 test_vproc_optlk_flow_live</h3>
<p >The test_vproc_optlk_flow_live application shows a live demo of the optical flow on Harris points. The available test_vproc_optlk_flow_live options are as follows: </p><pre class="fragment">  -b   File path to vproc.bin
  -s   Resizes input in [WxH] format
  -d   Harris points reponse threshold
  -n   Harris points NMS window size
  -k   Scale-down factor of the input size; runs the optical flow on the scaled input
  -f   Run loop per frame
  -t   Threshold to the LK response (for details, see the API vproc_optlk() ).
  -w   LK window size
  -m   0: shows the optical flow on Harris points, 1: shows only the Harris points, 2: shows the full optical flow
  -o   Threshold to show the minimal optical flow displacement dx / dy
  -z   Scales the optical flow displacement dx / dy for display
</pre><p >Execute the command below to run the optical flow live demo. </p><div class="fragment"><div class="line">board # rmmod ambarella_fb</div>
<div class="line">board # modprobe ambarella_fb resolution=1920x1080 mode=clut8bpp buffernum=4</div>
<div class="line">board # init.sh --na</div>
<div class="line">board # modprobe lt6911  (Need add extra module params <span class="keywordflow">for</span> cv5: vinc_id=8 bus_id=3 )</div>
<div class="line">board <span class="preprocessor"># sleep 5</span></div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">(cv2x command as below)</div>
<div class="line">board # test_encode --resource-cfg cv22_vin0_1080p_linear.lua --hdmi 1080p --ors 1920x1080</div>
<div class="line">(or cv5 command as below, check inside vout_hdmi.lua,  selected vout osd_rescaler_output_window = {0, 0, 1920, 1080})</div>
<div class="line">board # test_encode --resource-cfg cv5_vin0_1080p_linear.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line">board # test_vproc_optlk_flow_live -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -s 1920x1080 -d 0.01 -n 20 -k 10.0 -f 1 -t 0.001 -w 11x11 -m 0 -o 2 -z 4</div>
</div><!-- fragment --> <div class="image">
<img src="../../optlk_flow_live.gif" alt=""/>
<div class="caption">
Figure 2-9. Live LK Optical Flow on Harris Points.</div></div>
<dl class="section note"><dt>Note</dt><dd>CV72 is not supported yet. </dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_optlk_tracking_live"></a>
2.1.19 test_vproc_optlk_tracking_live</h3>
<p >The test_vproc_optlk_tracking_live application is a live demo of LK tracking based on Harris points. The available test_vproc_optlk_tracking_live options are as follows: </p><pre class="fragment">  -b   File path to vproc.bin
  -s   Resize input in [WxH] format
  -t   Threshold to the LK response (for details, see the API vproc_optlk() )
  -w   LK window size
  -k   LK window weights
  -p   Pyramid level for LK tracking
  -f   Run loop per frame
  -l   Tracking records per frame
  -d   Harris points reponse threshold
  -n   Harris points NMS window size
  -o   Minimum tracking points (otherwise, add new Harris points for tracking)
</pre><p >Run the command below to enable the optical tracking live demo. </p><div class="fragment"><div class="line">board # rmmod ambarella_fb</div>
<div class="line">board # modprobe ambarella_fb resolution=1920x1080 mode=clut8bpp buffernum=4</div>
<div class="line">board # init.sh --na</div>
<div class="line">board # modprobe lt6911  (Need add extra module params <span class="keywordflow">for</span> cv5: vinc_id=8 bus_id=3 )</div>
<div class="line">board <span class="preprocessor"># sleep 5</span></div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">(cv2x command as below)</div>
<div class="line">board # test_encode --resource-cfg cv22_vin0_1080p_linear.lua --hdmi 1080p --ors 1920x1080</div>
<div class="line">(or cv5 command as below, check inside vout_hdmi.lua,  selected vout osd_rescaler_output_window = {0, 0, 1920, 1080})</div>
<div class="line">board # test_encode --resource-cfg cv5_vin0_1080p_linear.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line">board # test_vproc_optlk_tracking_live -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -s 1280x720 -t 0.01 -w 11x11 -k [1.0] -p 4 -f 2 -l 2 -d 0.04 -n 64 -o 20</div>
</div><!-- fragment --> <div class="image">
<img src="../../optlk_tracking_live.gif" alt=""/>
<div class="caption">
Figure 2-10. Pyramid LK on Harris Points Tracking.</div></div>
<dl class="section note"><dt>Note</dt><dd>CV72 is not supported yet. </dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_edge_det"></a>
2.1.20 test_vproc_edge_det</h3>
<p >The test_vproc_edge_det application performs edge detection. The available test_vproc_edge_det options are as follows: </p><pre class="fragment">  -b   File path to vproc.bin
  -i   Input image file path
  -s   Resize input in [WxH] format
  -f   Kernel size of the edge filter
  -k   Kernel data of the edge filter
  -t   Edge line binarization threshold
  -p   Smooth filter kernel size; run the smooth filter before edge detection
  -o   Output path
</pre><p >Use the example below to detect edge using test_vproc_edge_det. </p><div class="fragment"><div class="line">board # test_vproc_edge_det -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i img.JPEG -s 1280x720 -f 3x3 -k [1,2,1,0,0,0,-1,-2,-1] -t 20 -p 5x5 -o /tmp</div>
</div><!-- fragment --> <div class="image">
<img src="../../edgedet_result.jpg" alt=""/>
<div class="caption">
Figure 2-11. Sobel Edge Detection Result.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_memcpy"></a>
2.1.21 test_vproc_memcpy</h3>
<p >The test_vproc_memcpy application performs a memory copy for a continuous region. The available test_vproc_memcpy options are as follows: </p><pre class="fragment">  -i --input    Path to input binary
  -o --output   Path to output binary
  -l --loop     Loop count, always -1
  -t --time     Measure run time
  -c --cache    Enable cache
</pre><p >The example below illustrates using test_vproc_memcpy to copy data. </p><div class="fragment"><div class="line">board # test_vproc_memcpy -i /tmp/1920x1080.y -o /tmp/out.bin -c -t</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_memset"></a>
2.1.22 test_vproc_memset</h3>
<p >The test_vproc_memset application sets a continuous region of memory with a provided value (0~255). The available test_vproc_memset options are as follows: </p><pre class="fragment">  -b --bin      Path to bin binary
  -o --output   Path to output binary
  -s --size     Buffer size
  -a --val      Initial value (0~255)
  -t --time     Measure runtime
</pre><p >The example below illustrates using test_vproc_memset to set memory. </p><div class="fragment"><div class="line">board # test_vproc_memset -o /tmp/out.bin -s 2073600 -a 0 -t</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_statistics"></a>
2.1.23 test_vproc_statistics</h3>
<p >The test_vproc_statistics application gets input vector statistics such as mean, standard deviation, minimum, and maximum. The available test_vproc_memset options are as follows: </p><pre class="fragment">  -b --bin            Path to bin binary
  -i --input          Path to input binary
  -o --output         Path to output binary
  -s --in_resolution  Input image resolution [WxHxD]
  -p --in_pitch       Input data pitch
  -I --in_df          Input data format [sign] [datasize] [exp_offset] [exp_bits]. Default is uint8 (0,0,0,0)
  -O --out_df         Output data format [sign] [datasize] [exp_offset] [exp_bits]. Default is FP32 (1,2,0,7)
     --min            Enable minimum calculation if set to 1
     --max            Enable maximum calculation if set to 1
     --avg            Enable mean calculation if set to 1
     --std            Enable standard deviation calculation if set to 1
  -t --time           Measure runtime
</pre><p >Use the example below to calculate the input vector statistics. </p><div class="fragment"><div class="line">board # test_vproc_statistics -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/1920x1080.y -o /tmp/out.bin -s 1920x1080x1 -I 0,0,0,0 -O 1,2,0,7 --min 1 --max 1 --avg 1 --std 1 -t</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>CV72 is not supported yet. </dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_warp"></a>
2.1.24 test_vproc_warp</h3>
<p >The test_vproc_warp application performs a variety of image transformations based on warp operations. The available test_vproc_warp options are as follows: </p><pre class="fragment">  -b --bin     Path to bin binary
  -i --in      Path to input binary
  -o --out     Path to output binary
  -w --warp    Path to warp table binary
  -m --mode    Warp mode. 0: generic warp; 1: warp affine; 2: warp perspective. Default is 0
     --ires    Input data resolution [WxHxD]
     --ipch    Input data pitch
     --ores    Output data resolution [WxHxD]
     --opch    Output data pitch
     --wres    Warp table resolution [WxH]
     --wpch    Warp table pitch
     --amat    2x3 warp affine transformation matrix
     --pmat    3x3 warp perspective transformation matrix
     --inv     Matrix is the inverse transformation matrix. 0: non-inverse; 1: inverse. Default is 0
  -s --dsize   Input / output (I/O) data size. 0 for 8-bit; 1 for 16-bit. Default is 0
  -t --time    Measure run time
</pre><p >The test_vproc_warp can perform any transformation as long as the warp field is correctly provided. </p><div class="fragment"><div class="line">board # test_vproc_warp -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/y720.bin -o /tmp/out.bin -w /tmp/wt.bin --ires 1280x720x1 --ores 1280x720x1 --wres 641x361 -m 0 -s 0 -t</div>
</div><!-- fragment --><p >Warp affine transformation is also supported by the test_vproc_warp application. The user must provide the affine transformation matrix. </p><div class="fragment"><div class="line">board # test_vproc_warp -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/y720.bin -o /tmp/out.bin --ires 1280x720x1 --ores 640x360x1 --amat 0.5,0,0,0,0.5,0 --inv 1 -m 1 -s 0 -t</div>
</div><!-- fragment --><p >Warp perspective transformation is achievable using the test_vproc_warp application if the perspective transformation matrix is provided. </p><div class="fragment"><div class="line">board # test_vproc_warp -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/y720.bin -o /tmp/out.bin --ires 1280x720x1 --ores 1280x720x1 --pmat -0.46688,-1.89871,922.0,-0.06845,-3.18593,1304.6,-0.000059,-0.00311,1 --inv 1 -m 2 -s 0 -t</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_epnr"></a>
2.1.25 test_vproc_epnr</h3>
<p >The test_vproc_epnr application performs edge-preserved noise reduction (EPNR). The available test_vproc_epnr options are as follows: </p><pre class="fragment">  -b    File path to vproc.bin
  -i    Input path of Y / YUV data
  -s    Input size in format [WxH]
  -d    Alpha value; range in [0, 14]. Set to 0 to keep as original input
  -o    Output path
</pre><p >Follow the example below to perform EPNR using test_vproc_epnr. </p><div class="fragment"><div class="line">board # test_vproc_epnr -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -s 384x288 -i in.NV12 -d 10 -o /tmp</div>
</div><!-- fragment --> <div class="image">
<img src="../../epnr_thermal.png" alt=""/>
<div class="caption">
Figure 2-12. Edge-Preserved Noise Reduction Result from Thermal Map Test.</div></div>
 <div class="image">
<img src="../../epnr_yuv.png" alt=""/>
<div class="caption">
Figure 2-13. Edge-Preserved Noise Reduction Result from YUV Image Test.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_epnr_live"></a>
2.1.26 test_vproc_epnr_live</h3>
<p >The test_vproc_epnr_live application performs the EPNR live demo. The available test_vproc_epnr_live options are as follows: </p><pre class="fragment">  -b    File path to vproc.bin
  -k    Low pass filter kernel size
  -B    Canvas buffer ID
  -d    Alpha value; range is [0, 14]. Set to 0 to keep as original input
  -m    Run mode
</pre><p >Run the command below to enable the EPNR demo. </p><div class="fragment"><div class="line">board # init.sh --na; modprobe imx274_mipi  (Need add extra module params <span class="keywordflow">for</span> cv5: vinc_id=8 bus_id=3 )</div>
<div class="line">board <span class="preprocessor"># test_aaa_service -a&amp;</span></div>
<div class="line">board # rmmod ambarella_fb</div>
<div class="line">board # modprobe ambarella_fb resolution=1920x1080 mode=clut8bpp buffernum=5</div>
<div class="line">(cv2x command as below)</div>
<div class="line">board # test_encode --resource-cfg cv22_vin0_1080p_linear.lua  --hdmi 1080p --ors 1920x1080 --vout-from-image 1</div>
<div class="line">(or cv5 command as below, check inside vout_hdmi.lua,  selected vout osd_rescaler_output_window = {0, 0, 1920, 1080}, <a class="code hl_variableRef" target="_blank" href="../../../video/d4/de8/vout__init_8c.html#abf5456cca33a36fb256bce85a8447f82">vout_from_image</a> = <span class="stringliteral">&quot;enable&quot;</span>)</div>
<div class="line">board # test_encode --resource-cfg cv5_vin0_1080p_linear.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line">board # cavalry_load -f /lib/firmware/cavalry.bin</div>
<div class="line">board # test_vproc_epnr_live -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -d 10 -k 3 -B 2 -m 3</div>
<div class="ttc" id="avout__init_8c_html_abf5456cca33a36fb256bce85a8447f82"><div class="ttname"><a href="../../../video/d4/de8/vout__init_8c.html#abf5456cca33a36fb256bce85a8447f82">vout_from_image</a></div><div class="ttdeci">u8 vout_from_image[VOUT_NUM]</div></div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_bayer2bgr"></a>
2.1.27 test_vproc_bayer2bgr</h3>
<p >The test_vproc_bayer2bgr application performs data format conversion from Bayer pattern to BGR / RGB. The available test_vproc_bayer2bgr options are as follows: </p><pre class="fragment">  -b    File path to vproc.bin
  -i    Bayer pattern input file path
  -s    Input size in [WxH] format
  -c    0: RGB sequence; 1: BGR sequence
  -o    Output path
</pre><p >Follow the example below to convert Bayer data to RGB data using test_vproc_bayer2bgr. </p><div class="fragment"><div class="line">board # test_vproc_bayer2bgr -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i bayer_in_1080p.bin  -s 1920x1080 -c 0 -o /tmp</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_cclb"></a>
2.1.28 test_vproc_cclb</h3>
<p >Run the test_vproc_cclb application to label the connected component. The available test_vproc_cclb options are as follows: </p><pre class="fragment">  -b    File path to vproc.bin
  -i    Path to input image
  -s    Input resize resolution in [WxH] format
  -t    Black / white threshold; for example, -t 128
  -w    Method of connection. 0: 4-way,1: 8-way
  -c    Minimum component size
  -h    Minmum hole size
  -o    Path to output folder; for example, -o / tmp
  -l    Scale factor for label
</pre><p >Follow the example below to label the connected component using test_vproc_cclb. </p><div class="fragment"><div class="line">board # test_vproc_cclb -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i Ambarella.png  -s 128x128 -t 128 -w 1 -c 10 -h 4 -o /tmp/ -l 40</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>CV72 is not supported yet. </dd></dl>
<h3><a class="anchor" id="vproc_library_test_vproc_alpha_blend"></a>
2.1.29 test_vproc_alpha_blend</h3>
<p >Run the test_vproc_alpha_blend application to blend two images using an alpha matrix. The available test_vproc_alpha_blend options are as follows: </p><pre class="fragment">  -b --bin                 Path to bin binary
     --inA                 Path to input image A binary
     --inB                 Path to input image B binary
     --alpha               Path to input alpha matrix binary
     --out                 Path to output binary
     --in_resolution       Input images resolution [WxHxD]
     --in_pitch            Input images pitch
     --alpha_resolution    Input alpha matrix resolution [WxH]
     --alpha_pitch         Alpha matrix pitch
     --out_pitch           Output image pitch
     --cs                  Color space of input / output images. Default is 0
                             0: General vector; 1: RGB; 2: BGR; 3: NV12; 4: Y
  -t --time                Measure runtime
</pre><p >The example below uses test_vproc_alpha_blend to merge two images. </p><div class="fragment"><div class="line">board # test_vproc_alpha_blend -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin --inA head_1080p.bin --inB rgb_1080p.bin --alpha mask0_5.bin --out out.bin --in_resolution 1920x1080x3 --alpha_resolution 1920x1080 --cs 0 -t</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_abs"></a>
2.1.30 test_vproc_abs</h3>
<p >Run the test_vproc_abs application to calculate the absolute values of a matrix. The available test_vproc_abs options are as follows: </p><pre class="fragment">  -b --bin       Path to bin binary
  -i --input     Path to input binary
  -o --output    Path to output binary
  -s --ires      Input image resolution [WxHxD]
  -p --ipch      Input data pitch
  -I --idf       Input data format [sign] [datasize] [exp_offset] [exp_bits]. Default is int8 (1,0,7,0)
  -O --odf       Output data format [sign] [datasize] [exp_offset] [exp_bits]. Default is int8 (1,0,7,0)
  -t --time      Measure runtime
</pre><p >Follow the example below to obtain the absolute value matrix from a matrix using test_vproc_abs. </p><div class="fragment"><div class="line">board # test_vproc_abs -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i data.bin -o out.bin -s 1280x720x1 -I 1,1,0,4 -O 1,1,0,4 -t</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_rgb2yuv"></a>
2.1.31 test_vproc_rgb2yuv</h3>
<p >Run the test_vproc_rgb2yuv application to convert an image from RGB format to YUV format. The available test_vproc_rgb2yuv options are as follows: </p><pre class="fragment">  -b --bin            Path to bin binary
  -i --input          Path to RGB input binary
  -o --output         Path to YUV output binary
  -s --resolution     Image resolution [WxH]
  -p --pitch          Image pitch
  -R --ROI            ROI of input image, [x_offset],[y_offset],[width],[height]
  -r --rgb_format     RGB format, 0: RGB; 1: BGR. Default is RGB
  -y --yuv_format     YUV format, 10: NV12. Default is NV12 format
  -t --time           Measure runtime
</pre><p >Follow the example below to use test_vproc_rgb2yuv to convert an image from RGB to NV12. </p><div class="fragment"><div class="line">board # test_vproc_rgb2yuv -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i rgb_1080p.bin -o out.bin -s 1920x1080 -t</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_transpose"></a>
2.1.32 test_vproc_transpose</h3>
<p >Run the test_vproc_transpose application to transpose a vector. The available test_vproc_transpose options are as follows: </p><pre class="fragment">  -b --bin        Path to bin binary
  -i --input      Path to input binary
  -o --output     Path to output binary
  -s --idim       Input vector dimension [DxHxW]
  -p --ipch       Input vector pitch
  -P --opch       Output vector pitch
  -T --tspose     Transpose operation. 0: CHW2HWC; 1: HWC2CHW. Default is 0
  -d --dsize      Data size of the I/O vector. 0 is 8-bit, 1 is 16-bit
  -t --time       Measure runtime
</pre><p >The example below uses test_vproc_transpose to tranpose a vector from CxHxW to HxWxC. </p><div class="fragment"><div class="line">board # test_vproc_transpose -i bgr_320x180.bin -o /tmp/out.bin -s 3x180x320 -T 0 -d 0 -t 0</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_render3d"></a>
2.1.33 test_vproc_render3d_live</h3>
<p >Run the test_vproc_render3d_live application to directly render a point cloud via video output (VOUT) high-definition multimedia interface (HDMIÂ®) without PC tool support. </p><pre class="fragment">  The point cloud rendering function consists of two sub-functions:
      - Transfer and rotate the point cloud in the world Axis
      - Render the point cloud to the canvas
  Both results from the sub-functions can be dumped by the library function, and only the rendering result is used in this unit test.
  The whole processing sequence in the unit test is as follows:
   1. Input the depth map
   2. Convert to point cloud in world Axis; the data format of the point in the world Axis should be int16
   3. Center shift the point cloud
   4. Rotate the point cloud
   5. Transfer shift the point cloud
   6. Project for 3D rendering
   7. Draw on VOUT
  The library performs the functions from step 3 to step 6.
  The formula from step 3 to step 5 is as follows: P_out=R_rot * (P_in + T_center) + T_trans, P_in/out=(Px,Py,Pz)
  R_rot = Rot_yaw * Rot_roll * Rot_pitch
</pre> <div class="image">
<img src="../../render3d_world_axis.png" alt=""/>
<div class="caption">
Figure 2-14. Render 3D World Axis.</div></div>
<p> The available test_vproc_render3d_live options are as follows: </p><pre class="fragment">  -b   Path to vproc.bin
  -i   Input depth map; for example, -i depth.bin
  -s   Input size of depth map
  -S   Projection resolution
  -f   Focal length of input depth
  -F   Focal length of projection
  -r   Rotation degree (Pitch#Roll#Yaw); for example, 90#30#180
  -c   Center shift [X#Y#Z]; for example, 0#0#-50 indicates rotation around the origin point at (0,0,50)
  -t   Transfer shift [X#Y#Z]; for example, -t 0#0#500 indicates the object shift at (0,0,500) for rendering
  -d   Rendering stride. High stride means low rendering density
  -q   Rendering depth range; for example, -q 100#500 indicates that a depth from 100 to 500 has rendering
  -m   Run live frequence; for example, -m 0 [0:static mode, 1: live mode]
  -Q   Scale of depth data; for example, -Q 0.0625. Some depth data has a high accuracy level; for example, with 1/16 pixel accuracy
</pre><p >The two examples below run point cloud rendering using test_vproc_render3d_live. </p><div class="fragment"><div class="line">board # test_vproc_render3d_live -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i dm_face_int16.bin -s 400x640 -S 1920x1080 -f 822.4  -F 622.4 -r 0#0#0 -c 0#0#-800 -t 0#0#800 -d 3 -q 500#1000 -m 1 -Q 1.0</div>
</div><!-- fragment --> <div class="image">
<img src="../../render3d_live.gif" alt=""/>
<div class="caption">
Figure 2-15. Live Rendering of a Point Cloud.</div></div>
 <div class="image">
<img src="../../render3d_static.png" alt=""/>
<div class="caption">
Figure 2-16. Static Rendering of a Point Cloud.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_bitwise"></a>
2.1.34 test_vproc_bitwise</h3>
<p >Run the test_vproc_bitwise application to perform bitwise logical operations. The available test_vproc_bitwise options are as follows: </p><pre class="fragment">  -b --bin              Path to bin binary
     --in0              Path to input0 binary
     --in1              Path to input1 binary
     --out              Path to output binary
  -s --in_resolution    Input image resolution [WxHxC]
  -p --in_pitch         Input image pitch
  -P --out_pitch        Output image pitch
  -o --opt_code         Bitwise operation code
                0: v0&amp;v1; 1: v0&amp;~v1; 2: ~v0&amp;v1; 3: ~(v0|v1); 4: v0|v1; 5: v0|~v1;6: ~v0|v1; 7: ~(v0&amp;v1); 8: v0^v1; 9: ^(v0^v1). Default is 0 (v0&amp;v1)
  -t --time             Measure runtime
</pre><p >Follow the example below using test_vproc_bitwise to perform "or" bitwise logical operations. </p><div class="fragment"><div class="line">board # test_vproc_bitwise --in0 1.bin --in1 2.bin --out 1or2.bin -s 32x32x3 -p 32 -P 32 -o 4</div>
</div><!-- fragment --><h3><a class="anchor" id="vproc_library_test_vproc_fbm"></a>
2.1.35 test_vproc_fbm</h3>
<p >Run the test_vproc_fbm application to generate the disparity using fast BM (FBM). The available test_vproc_fbm options are as follows. </p><pre class="fragment">  -b --bin                Path to vproc.bin; for example, -b /usr/share/ambarella/vproc/vproc.bin
  -l --src input          Path to source input image; for example, -l left.jpg
  -r --ref input          Path to reference input image; for example, -r right.jpg
  -o --output             Path to output folder; for example, -o /tmp
  -s --resolution         Resize input to WxH; for example, -s 720x640, maximum resolution is 1280x720
  -A --roi                ROI configuration [x#y#w#h]; for example, -A 320#180#640#480, not supported in CV7x version
  -w --SAD-winsize        SAD window size; for example, -w 15, range in [11,27]
  -g --SAD-thresh         SAD threshold, suggestion from 4000 to 50000; for example, -g 10000
  -n --disparity-num      Disparity number,CV2x: range in [27, 135], must be times of 9. CV7x: range in [33, 143], must be times of 11. For example, -n 66,
  -t --min-disparity      Minimum disparity value; for example, -t -32
  -q --fb-value           Focal length multiply baseline; for example, -q 1000
  -u --unique-ratio       Unique ratio, range [0,100]; for example, -u 3
  -f --pre-post-filter    With post / pre-filter; for example, -f 1, [0x01:pre-filter:xsobel, 0x02:pre-filter:xnorm, 0x04:post-process: dfilter &amp; dsfilter ]
  -d --max-speckle-diff   Maximum disparity / depth speckle difference; for example, -d 15
  -a --max-speckle-size   Maximum disparity / depth speckle size; for example, -a 7, range in [2,11]
  -k --texture-threshold  Texture threshold range in [0,100]; for example, -k 5
  -e --dsfilter-alpha     dsfilter alpha; for example, -e 0.1  [diparity / depth smooth filter with edge preserved], suggest range in [0.1, 10]
</pre><p> The FBM dumped disparity value is a fixed-point value in 16 signed bits, with 4 lower bits for fraction accuracy. </p><div class="fragment"><div class="line">real_disparity = dump_disparity / 16.0, real_disparity is <span class="keywordtype">float</span> value.</div>
</div><!-- fragment --><p> Below is an example to run test_vproc_fbm. </p><div class="fragment"><div class="line">board # test_vproc_fbm -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -l l2.png -r r2.png -o /tmp -w 17 -g 40000 -n 63 -t 0  -q 3200 -u 3  -s 1280x720 -d 15  -a 7 -f 4 -k 5 -e 2</div>
</div><!-- fragment --> <div class="image">
<img src="../../fbm_src.png" alt=""/>
<div class="caption">
Figure 2-17. FBM Inputs.</div></div>
 <div class="image">
<img src="../../fbm_disp.png" alt=""/>
<div class="caption">
Figure 2-18. FBM Output Disparity.</div></div>
<p> &diams; <b>FBM schematic:</b><br  />
 The following image shows the FBM schematic, which enables users to set the minimum-disparity for all the values even for a negative value, <br  />
 which is convenient for mono-stereo solutions. The maximum disparity number is 135. <br  />
 The following chart on the right demonstrates the way to define the min-disparity and disparity number. </p><div class="image">
<img src="../../fbm_schematic.png" alt=""/>
<div class="caption">
Figure 2-19. FBM Schematic.</div></div>
<p> &diams; <b>FBM pipeline with pre-process and post-process: </b><br  />
 FBM must function with pre-process and post-process functions in order to obtain improved disparity / depth results. <br  />
 Different solutions, hardware conditions, and use scenarios may require different pre-process / post-process conditions. <br  />
 Currently, the xsobel and xnorm filters are designed for pre-processing. Dfilter and dsfilter are designed for post-processing. <br  />
 Not all cases require pre-process and post-process; requirements depend on if the quality of disparity maps / depth maps meet expectations. <br  />
 </p><div class="image">
<img src="../../fbm_pipeline.png" alt=""/>
<div class="caption">
Figure 2-20. FBM Process Pipeline.</div></div>
<p> &diams; <b>pre-process: (xsobel filter and xnorm filter)</b><br  />
 Both the xsobel filter and xnorm filter are used to extract details from a RAW input image. Xsobel focuses on gradient details while xnorm focuses on grayscale details.<br  />
 Both can be used in stereo, active stereo, and mono structured-light stereo conditions. The filters can also run simultaneously with high efficiency and excellent results. <br  />
 The following case shows the disparity result from a mono structured-light stereo. Using the xnorm filter provides better results than when the filter is not in use. </p><div class="image">
<img src="../../fbm_prefilter_result.png" alt=""/>
<div class="caption">
Figure 2-21. Using Xnorm Filter in Mono Structured-Light Stereo.</div></div>
<p> &diams; <b>dfilter: (Noise filter of disparity / depth map)</b><br  />
 The following image demonstrates the <b>disparity / depth noise filter (dfilter)</b>process, which suppresses disparity / depth noise speckles. When the disparity / depth noise speckles are detected, the speckles are stuffed by a filtered value. <br  />
 <br  />
 </p><div class="image">
<img src="../../dfilter.png" alt=""/>
<div class="caption">
Figure 2-22. Dfilter Process.</div></div>
<p >The dfilter configurations are as follows: </p><pre class="fragment">  max_speckle_size:  Maximum noise speckle size to be suppressed; range is [2,11]
  filtered_val:      When noise speckles are detected, fill the filtered value into these speckles
  max_diff:          The gradient threshold of disparity / depth map. A gradient under max_diff indicates a continual area; a gradient over max_diff indicates an area edge
</pre> <div class="image">
<img src="../../dfilter_result.png" alt=""/>
<div class="caption">
Figure 2-23. Dfilter Result.</div></div>
<p> &diams; <b>dsfilter: (Edge-preserved smooth filter of disparity / depth map)</b><br  />
 The dsfilter configurations are as follows : </p><pre class="fragment">  alpha:        Smooth filter intensity; suggested range is from 0.1 to 10
  filtered_val: Filtered value in disparity / depth map will be skipped by dsfilter
  keep_edge:    Disparity / depth map gradient threshold. A gradient under keep_edge indicates a continual area; a gradient over keep_edge indicates an area edge
  rad:          Filter radius, valid in rad = 2
</pre> <div class="image">
<img src="../../dsfilter_result.png" alt=""/>
<div class="caption">
Figure 2-24. Dsfilter Result.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_fbm_live"></a>
2.1.36 test_vproc_fbm_live</h3>
<p >Run the test_vproc_fbm_live application to generate the disparity map using FBM in a live demo. The available test_vproc_fbm_live options are as follows: </p><pre class="fragment">  -b --bin                 Path to vproc.bin; for example, -b /usr/share/ambarella/vproc/vproc.bin
  -i  --input              Input canvas buffer ID; for example, -i 2
  -o --overlay-stream      Output stream ID; for example, -o 1
  -s --resolution          Resize input to WxH; for example, -s 720x640
  -A --roi                 ROI configuration [x#y#w#h]; for example, -A 320#180#640#480, not supported in CV7x version
  -w --SAD-winsize         SAD window size; for example, -w 15
  -g --SAD-thresh          SAD threshold; the suggested value is from 4000 to 50000. For example, -g 10000
  -n --disparity-num       Disparity number,CV2x: range in [27, 135], must be times of 9. CV7x: range in [33, 143],must be times of 11.  For example, -n 66,
  -t --min-disparity       Minimum disparity value; for example, -t -32
  -u --unique-ratio        Unique ratio, range is [0,100]. For example, -u 10
  -f --pre-post-filter     With post / pre-filter; for example, -f 1, [0x01:pre-filter, 0x02:post-filter, 0x03:both filter ]
  -d --max-speckle-diff    Maximum disparity speckle difference; for example, -d 15
  -a --max-speckle-size    Maximum disparity speckle size; for example, -a 7, range in [2,11]
  -k --texture-threshold   Texture threshold range is [0,100]; for example, -k 5
  -j --render-color-scale  Render color scale; for example, -j 1
</pre><p >Follow the example below to run test_vproc_fbm_live. </p><div class="fragment"><div class="line">board # test_vproc_fbm_live -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i 2 -o 0  -w 15 -g 50000 -n 81  -t 0 -A 0#0#0#0  -u 10  -s 960x640 -d 16  -a 5 -f 2 -k 5 -j 1</div>
</div><!-- fragment --> <div class="image">
<img src="../../fbm_live_disp.png" alt=""/>
<div class="caption">
Figure 2-25. FBM Live Demo.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_fbm_render_live"></a>
2.1.37 test_vproc_fbm_render_live</h3>
<p >Run the test_vproc_fbm_render_live application to render the point cloud for the FBM result in the live demo. The available test_vproc_fbm_render_live options are as follows: </p><pre class="fragment">  -b --bin                 Path to vproc.bin; for example, -b /usr/share/ambarella/vproc/vproc.bin
  -i --input               Input canvas buffer ID; for example, -i 2
  -o --overlay-stream      Output stream ID; for example, -o 1
  -s --resolution          Resize input to [WxH]; for example, -s 720x640
  -A --roi                 ROI configuration [x#y#w#h]; for example, -A 320#180#640#480, not supported in CV7x version
  -w --SAD-winsize         SAD window size; for example, -w 15
  -g --SAD-thresh          SAD threshold, suggested range is from 4000 to 50000. For example, -g 10000
  -n --disparity-num       Disparity number,CV2x: range in [27, 135], must be times of 9. CV7x: range in [33, 143], must be times of 11.  For example, -n 66,
  -t --min-disparity       Minimum disparity value; for example; -t -32
  -u --unique-ratio        Unique ratio, range [0,100]; for example, -u 10
  -f --pre-post-filter     With post / pre-filter; for example, -f 1, [0x01: pre-filter, 0x02: post-filter, 0x03: both filters]
  -d --max-speckle-diff    Maximum disparity speckle difference; for example, -d 15
  -a --max-speckle-size    Maximum disparity speckle size; for example, -a 7, range is [2,11]
  -F --lens-focal-length   Lens focal length. -F 820
  -B --baseline            Baseline (unit mm); for example, -B 40
  -Q --pc-depth-range      Point cloud rendering depth range; for example, -Q 100#500
  -k --texture-threshold   Texture threshold range [0,100]; for example, -k 20
  -r --render-stride       Render stride; for example, -r 3
  -R --rotation            Rotations (Pitch#Roll#Yaw); for example, -R 10#10#10
  -C --center-shift        Center shift [X#Y#Z]; for example, -C 0#0#-250
  -T --trans-shift         Transfer shift [X#Y#Z]; for example, -T 0#0#250
</pre><p >Follow the example below to run test_vproc_fbm_render_live. </p><div class="fragment"><div class="line">board # test_vproc_fbm_render_live -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i 2 -o 0  -w 15 -g 50000 -n 81  -t 0 -A 0#0#0#0  -u 10  -s 960x640 -d 16  -a 5 -f 2 -k 5 -Q  0#32000 -F 820 -B 40 -r 4 -C 0#-100#-1000 -R  0#0#10 -T -400#0#500</div>
</div><!-- fragment --> <div class="image">
<img src="../../fbm_live_render.png" alt=""/>
<div class="caption">
Figure 2-26. FBM Live Demo.</div></div>
<h3><a class="anchor" id="vproc_library_test_vproc_flatten"></a>
2.1.38 test_vproc_flatten</h3>
<p >The test_vproc_flatten uses the VProc library to flatten the shape of input. The available options of test_vproc_flatten are as follows: </p><pre class="fragment">  -b --bin          Path to bin binary
  -i --input        Path to input binary
  -o --output       Path to output binary
  -s --ires         Input image resolution WxHxD
  -p --ipch         Input data pitch
  -I --in_df        Input data format [sign] [datasize] [exp_offset] [exp_bits]. Default is uint8(0,0,0,0)
  -O --out_df       Output data format [sign] [datasize] [exp_offset] [exp_bits]. Default is uint8(0,0,0,0)
  -c --cspace       Color space of image. 0: VECT; 1: RGB; 2: BGR; 11: Y; 12: ITL. Default is 0(VECT)
  -t --time         Measure runtime
</pre><p >One example is provided using the command below: </p><div class="fragment"><div class="line">board # test_vproc_flatten -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> /usr/share/ambarella/vproc/vproc.bin -i /tmp/in.bin -o /tmp/out.bin -s 1920x1080x3 -c 0 -t</div>
</div><!-- fragment --><hr  />
<h1><a class="anchor" id="sec_vproc"></a>
3. VProc Performance</h1>
<p >The table below shows the VProc performance on CV chips. </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadNone">VProc Fun   </th><th class="markdownTableHeadNone">CV2   </th><th class="markdownTableHeadNone">CV22 (DRAM: 1800 MHz, VP: 1008 MHz)   </th><th class="markdownTableHeadNone">CV25   </th><th class="markdownTableHeadNone">CV28   </th><th class="markdownTableHeadNone">CV5   </th><th class="markdownTableHeadNone">CV72    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">yuv2rgb   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">4.3 ms (3840x2160)<br  />
1.1 ms (1920x1080)<br  />
0.5 ms (1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">resize   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">2.8 ms (RGB, 3840x2160 -&gt; 1920x1080)<br  />
0.9 ms (RGB, 1920x1080 -&gt; 1280x720)<br  />
2.1 ms (NV12, 3840x2160 -&gt; 1920x1080)<br  />
0.84 (NV12, 1920x1080 -&gt; 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">submean   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">1.3 ms (RGB, 1920x1080)<br  />
0.76 ms (RGB, 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">scale   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">1.6 ms (RGB; 1920x1080)<br  />
0.78 ms (RGB; 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">dtcvt   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">2 ms (RGB, 1920x1080)<br  />
0.9 ms (RGB, 1290x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">rotate   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">5.9 ms (RGB, 1920x1080, r90)<br  />
1.5 ms (RGB, 1920x1080, r180)<br  />
5.6 ms (RGB, 1920x1080, r270)<br  />
2.3 (RGB, 1280x720, r90)<br  />
0.66 ms (RGB, 1280x720, r180)<br  />
2.3 ms (RGB, 1280x720, r270)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">harris   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">8 ms (can reach 5.2 ms after 8-bit optimization, 1920x1080)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">4ms    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">wrap   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">11.97 ms (generic warp, 1920x1080, warp mat size: 640x360)<br  />
8.69 ms (generic warp, 1280x720, warp mat size: 640x360)<br  />
1.48 ms (warp affine, 1920x1080 -&gt; 960x720)<br  />
0.55 ms (warp affine, 1280x720 -&gt; 640x320)<br  />
19.16 ms (warp perspective, 1920x1080)<br  />
8.66 ms (warp perspective, 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">perspective   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">13.1 ms (1280x800)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">cdist   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">89 ms (RGB, 1920x1080)<br  />
40 ms (RGB, 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">imhist   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">2.2 ms (RGB, 1920x1080)<br  />
1 ms (RGB, 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">imcvt   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">4.1 ms (1920x1080, ocv -&gt; ambaRGB)<br  />
1.8 ms (1280x720, ocv -&gt; ambaRGB)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">merge_uv   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0.61 ms (image res: 1920x1080)<br  />
0.31 ms (image res: 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">split_uv   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0.32 ms (image res: 1920x1080)<br  />
0.2 ms (image res: 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">cvfilter   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">2.8 ms (1080p, filter size=3x3)<br  />
4 ms (1080p, filter size=11x11)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">morph   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">3.3 ms (dilate, RGB, 1920x1080)<br  />
1.6 ms (dilate, RGB, 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">optlk   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">9 ms (720p)<br  />
4.9 ms (720x640)<br  />
0.3 ms (120x80)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">memcpy   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">1.6 ms (RGB, 1080p)<br  />
0.76 ms (RGB, 720p)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">memset   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0.61 ms (RGB, 1080p)<br  />
0.3 ms (RGB, 720p)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">statistics   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">6.2 ms (RGB, 1080p)<br  />
2.84 ms (RGB, 720p)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">epnr   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">15 ms (1080p)<br  />
2.5 ms (640x480)<br  />
1 ms (384x288)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">bayer2bgr   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">14.1 ms (1920x1080)<br  />
6.6 ms (1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">cclb   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">0.21 ms (128x128)<br  />
0.22 ms (256x256)<br  />
0.4 ms (512x512)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">alpha_blend   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">2.3 ms (RGB, 1920x1080)<br  />
1.05 ms (RGB, 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">abs   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">1.28 ms (RGB, 1920x1080)<br  />
0.67 ms (RGB, 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">transpose   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">13.59 ms (RGB, 960x720, chw2hwc)<br  />
17.43 ms (RGB, 960x720, hwc2chw)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">bitwise   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">1.78 ms (RGB, 1920x1080, a &amp; b)<br  />
0.83 ms (RGB, 1280x720, a &amp; b)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">flatten   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">1.37 ms (RGB, 1920x1080)<br  />
0.67 ms (RGB, 1280x720)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyNone">render3D   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">5 ms (400x600, drawing stride is 2)<br  />
10 ms (400x600, drawing stride is 1)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyNone">FBM   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">30 ms (640x480, disparity number is 63) <br  />
90 ms (1280x720, disparity number is 63)   </td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone"></td><td class="markdownTableBodyNone">22 ms <br  />
70 ms   </td><td class="markdownTableBodyNone">16 ms (disparity number is 66)<br  />
46 ms (disparity number is 66)   </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="sec_vproc_api"></a>
4. VProc API</h1>
<p >Visit the following link for details on API functions.</p><ul>
<li><a class="el" href="../../d5/d03/group__vproc-api-details.html">VProc Library API details</a> shows API lists.</li>
<li><a class="el" href="../../da/dac/group__vproc-api-details-mfd.html">VProc Library MFD API details</a> shows memory file descriptor (MFD) lists for API use.</li>
<li><a class="el" href="../../df/dd0/group__vproc-helper.html">VProc Library API helper</a> shows related macros, enumerations, and structures.</li>
</ul>
<hr  />
<h1><a class="anchor" id="sec_vproc_lic"></a>
5. License</h1>
<p >Copyright (c) 2024 Ambarella International LP.</p>
<p >This file and its contents ( "Software" ) are protected by intellectual property rights including, without limitation, U.S. and/or foreign copyrights. This Software is also the confidential and proprietary information of Ambarella International LP and its licensors. You may not use, reproduce, disclose, distribute, modify, or otherwise prepare derivative works of this Software or any portion thereof except pursuant to a signed license agreement or nondisclosure agreement with Ambarella International LP or its authorized affiliates. In the absence of such an agreement, you agree to promptly notify and return this Software to Ambarella International LP.</p>
<p >THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL AMBARELLA INTERNATIONAL LP OR ITS AFFILIATES BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; COMPUTER FAILURE OR MALFUNCTION; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3 </li>
  </ul>
</div>
</body>
</html>
