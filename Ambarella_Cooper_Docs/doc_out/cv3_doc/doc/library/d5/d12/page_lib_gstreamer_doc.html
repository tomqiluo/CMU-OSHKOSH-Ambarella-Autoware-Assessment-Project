<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Library: Amba GStreamer Solution</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<link rel="search" href="../../search_opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Library"/>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="../../../library/mathjax/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-ambarella.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../Ambarella.png"/></td>
  <td id="projectalign">
   <div id="projectname">Library<span id="projectnumber">&#160;Cooper_1.6.0 (CV72 &amp; CV3) @ 2024.07.10 14:12:44</span>
   </div>
   <div id="projectbrief">placeholder</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,true,'search.html','Search');
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d5/d12/page_lib_gstreamer_doc.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">Amba GStreamer Solution </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="gstreamer_doc_history"></a>
0. Revision History</h1>
<a class="anchor" id="table_gstreamer_doc_history"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Updated Date </th><th align="left">Modification </th></tr>
<tr>
<td>20230601 </td><td>Initial Version </td></tr>
<tr>
<td rowspan="2">20231018 </td><td>1. Updated the element informations of NNStreamer <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#amba_cvflow_in_nns">1.3.3 Ambarella CVflow® in NNStreamer</a> </td></tr>
<tr>
<td>2. Fixed some issues of AAC cmdlines, add multi-input NN cases <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#amba_test_cases">2.4 Ambarella Test Cases</a> </td></tr>
<tr>
<td>20240116 </td><td>Added some use cases in Lychee OS <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#use_in_lychee">2.4.9 Use GStreamer in Lychee OS</a> </td></tr>
<tr>
<td rowspan="2">20240118 </td><td>1. Updated tensor_deocder information of NNStreamer <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#amba_cvflow_in_nns">1.3.3 Ambarella CVflow® in NNStreamer</a> </td></tr>
<tr>
<td>2. Added prepared works on CV52 / CV72, fixed some issues of commandlines, and added RTSP cases <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#amba_test_cases">2.4 Ambarella Test Cases</a> </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="introduction"></a>
1. Introduction</h1>
<p >This chapter introduces the GStreamer framework and provides solutions based on GStreamer to manage multi-media, machine learning, and more on Ambarella platforms.<br  />
 The following shows an overall view of the connections among GStreamer, the GStreamer Daemon (GstD), and third-party plugins such as NNStreamer, Amba Gst Plugins, and more. <br  />
 Along with the core and base elements, GStreamer provides a large collection of plugins that cover more functions. Amba Gst Plugins, NNStreamer, and others can be added as GStreamer plugins. <br  />
 In the GStreamer Daemon, via TCP messages, users can create a GStreamer pipeline, then play, pause, change speed, skip around, and change element parameter settings all while the pipeline is active. <br  />
</p>
<div class="image">
<img src="../../overall_diagram_of_amba_gstreamer.png" alt=""/>
<div class="caption">
Figure 1-6. Overall Diagram of Amba GStreamer.</div></div>
<p> <br  />
 This chapter includes the following sections:</p><ul>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#gstreamer">1.1 GStreamer</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#gstreamer_daemon">1.2 GStreamer Daemon</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#nnstreamer">1.3 NNStreamer</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#amba_gstreamer_plugins">1.4 Amba GStreamer Plugins</a></li>
</ul>
<h2><a class="anchor" id="gstreamer"></a>
1.1 GStreamer</h2>
<p >GStreamer is an open source multi-media framework (released under the LGPL) for constructing graphs of media-handling components. The applications it supports range from simple Ogg / Vorbis playback, audio / video streaming to complex audio (mixing) and video (non-linear editing) processing. <br  />
</p>
<p >The following are the GStreamer core functions that provide a framework for plugins, data flow, and media type management / negotiation. GStreamer also provides application programming interfaces (APIs) to write applications using the various plugins. <br  />
</p>
<p >GStreamer provides the following:</p>
<ul>
<li>APIs for multi-media applications<br  />
</li>
<li>Plugin architecture <br  />
</li>
<li>Pipeline architecture <br  />
</li>
<li>Mechanism for media type management / negotiation<br  />
</li>
<li>Synchronization mechanism <br  />
</li>
<li>Over 250 plugins providing more than 1,000 elements <br  />
</li>
<li>A set of tools <br  />
</li>
</ul>
<p >The GStreamer framework is designed to facilitate writing applications that manage audio, video, or any type of data flow. The framework is based on plugins that provide a variety of coders / decoders (codecs) and other functionalities. The plugins can be linked and arranged in a pipeline that defines the flow of the data. <br  />
 GStreamer plugins can be classified as follows: <br  />
</p>
<ul>
<li><b>Protocol management </b> <br  />
</li>
<li><b>Sources:</b> for audio and video (includes protocol plugins) <br  />
</li>
<li><b>Formats:</b> parsers, formaters, muxers, demuxers, metadata, and subtitles <br  />
</li>
<li><b>Codecs:</b> coders and decoders <br  />
</li>
<li><b>Filters:</b> converters, mixers, effects, and more <br  />
</li>
<li><b>Sinks:</b> for audio and video (includes protocol plugins) <br  />
</li>
</ul>
<div class="image">
<img src="../../gstreamer-overview.png" alt=""/>
<div class="caption">
Figure 1-1. GStreamer Overview.</div></div>
<p> <br  />
</p>
<p >GStreamer details can be found at the following official website link: <br  />
 <a href="https://gstreamer.freedesktop.org/">https://gstreamer.freedesktop.org/</a> <br  />
</p>
<h3><a class="anchor" id="gstreamer_history"></a>
1.1.1 Library Revision History</h3>
<a class="anchor" id="table_gstreamer_history"></a>
<table class="doxtable">
<caption>Table 1-1. History of GStreamer Library.</caption>
<tr>
<th>Library Version </th><th>License </th><th>Updated Date </th><th>Modification </th></tr>
<tr>
<td>1.20.5 </td><td>LGPL </td><td>20221219 </td><td>Initial Version </td></tr>
</table>
<h3><a class="anchor" id="gstreamer_core_library"></a>
1.1.2 GStreamer Core Library</h3>
<p >The core library <code>gstreamer</code> provides all core GStreamer services, including initialization, plugin management, and types, as well as the object hierarchy that defines elements and bins, along with some more specialized elements. Characteristics of the Gstreamer core are listed below: <br  />
</p>
<ul>
<li>Based on the GLib 2.0 object model for object-oriented design and inheritance <br  />
</li>
<li>Graph-based structure enables arbitrary pipeline construction, such as multi-threaded pipelines <br  />
</li>
<li>Clean, simple, and stable APIs for both plugin and application developers <br  />
</li>
<li>Complete debugging system for both core and plugin / application developers <br  />
</li>
<li>Extremely lightweight data passing for very high performance / low latency <br  />
</li>
<li>Clocking to ensure global inter-stream synchronization (audio / video sync) <br  />
</li>
<li>Quality of service (QoS) to ensure best possible quality under high CPU load <br  />
</li>
</ul>
<p >Details of these characteristics can be found at the following official website link: <br  />
 <a href="https://gstreamer.freedesktop.org/documentation/gstreamer/gi-index.html?gi-language=c">https://gstreamer.freedesktop.org/documentation/gstreamer/gi-index.html?gi-language=c</a> <br  />
</p>
<h3><a class="anchor" id="gstreamer_community_library"></a>
1.1.3 GStreamer Community Library</h3>
<p >The following are some community libraries in GStreamer: <br  />
</p>
<ul>
<li><b>gst-plugins-base:</b> an essential exemplary set of elements <br  />
</li>
<li><b>gst-plugins-good:</b> a set of good-quality plugins under LGPL <br  />
</li>
<li><b>gst-plugins-ugly:</b> a set of good-quality plugins that may pose distribution problems <br  />
</li>
<li><b>gst-plugins-bad:</b> a set of plugins that require better quality <br  />
</li>
<li><b>gst-libav:</b> a set of plugins that wrap libav for decoding and encoding <br  />
</li>
<li>Other packages <br  />
</li>
</ul>
<p ><b>gst-plugins-base</b> <br  />
 This is a well-groomed and well-maintained collection of GStreamer plugins and elements that cover a wide range of possible elements types. The library includes examples, documentation, and regression tests. These are continuously kept up-to-date with any core changes during the development series. <br  />
</p>
<p ><b>gst-plugins-good</b> <br  />
 This is a collection of plugins that have good quality code, correct functionality, and a preferred license (LGPL for the plugin code, LGPL or LGPL-compatible for the supporting library). This is an excellent model that can be used as a basis for user-created plugins. <br  />
</p>
<p ><b>gst-plugins-ugly</b> <br  />
 This is a collection of plugins that have good quality and correct functionality, but may pose problems during distribution. The license on either the plugins or the supporting libraries may not reach Ambarella standards. These plugins may have a patent noose around their neck, a lock-up license, or another issue. <br  />
</p>
<p ><b>gst-plugins-bad</b> <br  />
 This is a collection of plugins that are not up to par, compared to the rest of the plugins. They may be close to good quality, but are missing something - be it a good code review, some documentation, a set of tests, a live maintainer, or some actual wide use. Though the plugins may appear useful, Ambarella does not recommend using this library. <br  />
</p>
<p ><b>gst-libav</b> <br  />
 This is a collection of FFmpeg plugins. The details of the supported elements list for FFmpeg can be found at the following official website link: <br  />
 <a href="https://gstreamer.freedesktop.org/documentation/libav/index.html?gi-language=c#plugin-libav">https://gstreamer.freedesktop.org/documentation/libav/index.html?gi-language=c#plugin-libav</a> <br  />
</p>
<p >More tools, APIs, elements, and plugins that supported in these GStreamer libraries can be found in the following official document: <br  />
 <a href="https://gstreamer.freedesktop.org/documentation/?gi-language=c">https://gstreamer.freedesktop.org/documentation/?gi-language=c</a> <br  />
</p>
<h2><a class="anchor" id="gstreamer_daemon"></a>
1.2 GStreamer Daemon</h2>
<h3><a class="anchor" id="gstd_history"></a>
1.2.1 Library Revision History</h3>
<a class="anchor" id="table_gstd_history"></a>
<table class="doxtable">
<caption>Table 1-2. History of GstD Library.</caption>
<tr>
<th>Library Version </th><th>License </th><th>Updated Date </th><th>Modification </th></tr>
<tr>
<td>0.15.0 </td><td>LGPL2+ </td><td>20220823 </td><td>Initial Version </td></tr>
</table>
<h3><a class="anchor" id="gstd_introduction"></a>
1.2.2 Introduction</h3>
<p >GstD is a GStreamer framework for controlling audio and video streaming using InterProcess Communication (IPC) protocol (TCP messages). Users can create a GStreamer pipeline, then play, pause, change speed, skip, and change element parameter settings all while the pipeline is active in the GStreamer Daemon. <br  />
</p>
<p >The GStreamer Daemon is designed for production deployment, where the control logic runs in a separate process from the audio-video streaming server. Isolating the control logic from the streaming logic solves many difficult issues, from setting priorities, to avoiding audio drop out, to supporting a functioning user interface if the streaming application encounters corrupt data. Creating automated audio / video tests, extending a product's features to support remote control, and enabling the control application streaming daemon can be developed independently and easily. <br  />
</p>
<p >The GStreamer Daemon design follows a model-view-controller (MVC) architecture. <br  />
</p>
<ul>
<li>The GStreamer daemon provides the core and IPC endpoint <br  />
</li>
<li>The custom application provides view and client logic <br  />
</li>
</ul>
<div class="image">
<img src="../../Gstd_mvc.png" alt=""/>
<div class="caption">
Figure 1-2. GStreamer Daemon MVC Architecture.</div></div>
<p> <br  />
</p>
<p >The GStreamer Daemon project packages the core, the commandline client, and the IPC interfaces. The GstD core is a standalone process that is on top of the GStreamer framework. GstdClient is a simple, commandline-based application that communicates via TCP with the GStreamer Daemon. This application is ideal for rapid prototyping and for shell script automation. GstdClient provides users with several active pipelines with the ability to control the pipeline and receive feedback once the pipeline has been created.</p>
<div class="image">
<img src="../../Gstd_layers.png" alt=""/>
<div class="caption">
Figure 1-3. GstD Layer Diagram.</div></div>
<p> <br  />
</p>
<p >Details on this topic can be found at the following official website link: <br  />
 <a href="https://developer.ridgerun.com/wiki/index.php/GStreamer_Daemon">https://developer.ridgerun.com/wiki/index.php/GStreamer_Daemon</a> <br  />
</p>
<h2><a class="anchor" id="nnstreamer"></a>
1.3 NNStreamer</h2>
<h3><a class="anchor" id="nns_history"></a>
1.3.1 Library Revision History</h3>
<a class="anchor" id="table_nns_history"></a>
<table class="doxtable">
<caption>Table 1-3. History of NNStreamer Library.</caption>
<tr>
<th>Library Version </th><th>License </th><th>Updated Date </th><th>Modification </th></tr>
<tr>
<td>lts_2.0.1 </td><td>LGPL-2.1 </td><td>20180614 </td><td>Initial Version </td></tr>
</table>
<h3><a class="anchor" id="nns_introduction"></a>
1.3.2 Introduction</h3>
<p >NNStreamer is a set of GStreamer plugins that provide easy methods to construct media streams with neural network (NN) models using the de-facto-standard media stream framework, GStreamer. <br  />
</p>
<ul>
<li><b>GStreamer users:</b> uses NN models as if they are yet another media filter <br  />
</li>
<li><b>NN developers:</b> manages media streams easily and efficiently <br  />
</li>
</ul>
<p >NN framework connectivities (for example, TensorFlow, TensorFlow-lite, Caffe, Caffe2, PyTorch, OpenVINO, ArmNN, and NEURUN) were provided by NNStreamer for GStreamer streams.</p>
<ul>
<li><b>Efficient streaming for artificial intelligence (AI) projects:</b> applies efficient and flexible stream pipelines to neural networks <br  />
</li>
<li><b>Intelligent media filters:</b> uses an NN model as a media filter / converter <br  />
</li>
<li><b>Composite models:</b> multiple NN models in a single stream pipeline instance <br  />
</li>
<li><b>Multi-modal intelligence:</b> multiple sources and stream paths for NN models <br  />
</li>
</ul>
<div class="image">
<img src="../../nnstreamer_diagram.png" alt=""/>
<div class="caption">
Figure 1-4. NNStreamer Diagram.</div></div>
<p> <br  />
</p>
<p >The following elements are supported in NNstreamer:</p>
<ul>
<li><b>tensor_converter:</b> converts video, audio, text, and more to the tensor frame wrapping format <br  />
</li>
<li><b>tensor_filter:</b> NN framework filters, such as TensorFlow, TensorFlow-lite, Caffe2, ArmNN, and more <br  />
</li>
<li><b>tensor_decoder:</b> post-processing, such as direct video conversion, image classification labeling, bounding boxes, image segmentation, body posing, and more <br  />
</li>
<li><b>tensor_sink:</b> appsink-like element <br  />
</li>
<li><b>tensor_source:</b> appsrc-like element <br  />
</li>
</ul>
<p >More details of supported elements can be found at the following official website link: <br  />
 <a href="https://github.com/nnstreamer/nnstreamer/tree/main/Documentation">https://github.com/nnstreamer/nnstreamer/tree/main/Documentation</a> <br  />
 <a href="https://github.com/nnstreamer/nnstreamer/blob/main/Documentation/component-description.md">https://github.com/nnstreamer/nnstreamer/blob/main/Documentation/component-description.md</a> <br  />
</p>
<h3><a class="anchor" id="amba_cvflow_in_nns"></a>
1.3.3 Ambarella CVflow® in NNStreamer</h3>
<p >The Ambarella CVflow framework provides functions for running neural network models. CVflow, as well as a pipeline neural network filter, can be added to NNstreamer. <br  />
</p>
<ul>
<li><b>tensor_converter:</b> adds support for more video formats to convert to tensor format <br  />
</li>
<li><b>tensor_filter:</b> adds the sub-plugin filter <code>amba_cvflow</code> to run NN models <br  />
</li>
<li><b>tensor_decoder:</b> adds YOLOv5 / tiny YOLOv3 / YOLOP post-processing examples in <code>tensordec-boundingbox</code> <br  />
</li>
</ul>
<div class="image">
<img src="../../diagram_of_nnstreamer_sub_plugin.png" alt=""/>
<div class="caption">
Figure 1-5. NNStreamer Sub-Plugin Diagram.</div></div>
<p> <br  />
</p>
<p ><b>tensor_converter</b> <br  />
</p>
<p >For more efficient calculation, Amba CNNGen always treats the input as if it were NCHW format, even though TensorFlow is typically in NHWC format. To reduce unnecessary storage format conversions (NHWC -&gt; NCHW), add support for RGBP / BGRP / NV12 video formats in <code>tensor_convert</code>. The following is the list of supported video formats in <code>tensor_convert</code>. <br  />
</p>
<a class="anchor" id="table_video_fmt_in_tensor_convert"></a>
<table class="doxtable">
<caption>Table 1-4. Supported Video Formats in tensor_convert.</caption>
<tr>
<th>GstVideoFormat </th><th>Tensor Dimensions </th><th>Storage Format </th></tr>
<tr>
<td>GRAY8 </td><td>0:1,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>RGB </td><td>0:3,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>BGR </td><td>0:3,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>RGBx </td><td>0:4,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>BGRx </td><td>0:4,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>xRGB </td><td>0:4,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>xBGR </td><td>0:4,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>RGBA </td><td>0:4,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>BGRA </td><td>0:4,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>ARGB </td><td>0:4,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>ABGR </td><td>0:4,1:W,2:H,3:1 </td><td>NHWC </td></tr>
<tr>
<td>RGBP </td><td>0:W,1:H,2:3,3:1 </td><td>NCHW </td></tr>
<tr>
<td>BGRP </td><td>0:W,1:H,2:3,3:1 </td><td>NCHW </td></tr>
<tr>
<td>NV12 </td><td>0:W,1:H,2:2,3:1 </td><td>NCHW </td></tr>
</table>
<p ><b>tensor_filter </b> <br  />
</p>
<p >The <code>amba_cvflow</code> framework in <code>tensor_filter</code> provides pre-processing methods to facilitate running NNs with CVflow. Vproc can convert YUV to RGBP / BGRP, perform resize, crop, and scale funcions, and more. Note that for some vector operations such as converting color space from interleaved to planar distribution, resizing would take the data format as (0, 0, 0, 0).</p>
<p >The following was the list of supported pre-processing features in <code>amba_cvflow</code>. <br  />
</p>
<a class="anchor" id="table_pre_process_in_amba_cvflow"></a>
<table class="doxtable">
<caption>Table 1-5. Supported Pre-Processing Features in amba_cvflow.</caption>
<tr>
<th>Pre-Process </th><th>Supported Features </th><th>Description </th></tr>
<tr>
<td>Color space conversion </td><td>RGB -&gt; RGBP, BGR -&gt; RGBP, BGRP -&gt; RGBP, NV12 -&gt; RGBP </td><td>Uses Vproc APIs and some C code to implement it </td></tr>
<tr>
<td>Resize, crop </td><td>VECTOR, RGBP, BGRP, NV12 </td><td>Vproc only supports resize+crop vectors with planer+FX8 format; adds simple C implementation for interleaved / float32 data (not recommended) </td></tr>
<tr>
<td>Scale </td><td>FX8 / FP32 -&gt; FX8 / FP32 </td><td>Uses Vproc APIs convert data type to fixed 8-bit, floating 32-bit </td></tr>
</table>
<p >The following lists added properties in the sub-plugin <code>amba_cvflow</code> of <code>tensor_filter</code>. Note that the values of <code>in_name</code>, <code>in_data_fmt</code>, <code>ROI</code>, <code>in_cs</code>, and <code>nn_cs</code> must be equal to the NN input values, and the <code>out_name</code> value must be equal to the NN output value. <br  />
</p>
<a class="anchor" id="table_property_in_amba_cvflow"></a>
<table class="doxtable">
<caption>Table 1-6. Properties in amba_cvflow.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>in_name </td><td>String </td><td>NULL+... </td><td>Required; specifies NN input names </td></tr>
<tr>
<td>out_name </td><td>String </td><td>NULL+... </td><td>Required; specifies NN output names </td></tr>
<tr>
<td>in_data_fmt </td><td>String </td><td>uint8:0.0.8.0 float32:1.2.0.7 </td><td>Specifies data formats [sign.datasize.exp_offset.exp_bits] of input tensors; if not set, decided by tensor types </td></tr>
<tr>
<td>roi </td><td>String </td><td>0.0.0.0+... </td><td>Specifies the ROIs [xoffset.yoffset.width.height] of input tensors </td></tr>
<tr>
<td>in_cs </td><td>String </td><td>NULL+... </td><td>Specifies the color spaces of input tensorsl if not set, decided by the video format of tensors </td></tr>
<tr>
<td>nn_cs </td><td>String </td><td>rgbp+... </td><td>Specifies the color spaces of NN input feature maps </td></tr>
<tr>
<td>nn_out_f32 </td><td>Integer </td><td>0 </td><td>Coerces the data format of NN outputs to FP32 </td></tr>
<tr>
<td>type </td><td>String </td><td>NULL </td><td>If post-processing in tensor_filter is required, specify the NN model type </td></tr>
<tr>
<td>label </td><td>String </td><td>NULL </td><td>If post-processing in tensor_filter is required, specify the label file path </td></tr>
<tr>
<td>f </td><td>Float </td><td>0.2 </td><td>If post-processing in tensor_filter is required, specify conf_threshold </td></tr>
<tr>
<td>nms </td><td>Float </td><td>0.3 </td><td>If post-processing in tensor_filter is required, specify nms_threshold </td></tr>
<tr>
<td>top_k </td><td>Integer </td><td>200 </td><td>If post-processing in tensor_filter is required, specify top_k </td></tr>
<tr>
<td>u </td><td>Integer </td><td>0 </td><td>If post-processing in tensor_filter is required, specify use_multi_cls </td></tr>
</table>
<p >The following lists the supported color spaces in <code>amba_cvflow</code>. <br  />
</p>
<a class="anchor" id="table_cs_in_amba_cvflow"></a>
<table class="doxtable">
<caption>Table 1-7. Supported Color Spaces in amba_cvflow.</caption>
<tr>
<th>Amba Color Space </th><th>GstVideoFormat </th><th>Command Line String </th><th>Description </th></tr>
<tr>
<td>CS_VECT </td><td>GST_VIDEO_FORMAT_UNKNOWN </td><td>vector </td><td>General vector </td></tr>
<tr>
<td>CS_RGB </td><td>GST_VIDEO_FORMAT_RGBP </td><td>rgbp </td><td>Planar RGB data </td></tr>
<tr>
<td>CS_BGR </td><td>GST_VIDEO_FORMAT_BGRP </td><td>bgrp </td><td>Planar BGR data </td></tr>
<tr>
<td>CS_RGB_ITL </td><td>GST_VIDEO_FORMAT_RGB </td><td>rgb </td><td>Element-interleaved RGB data </td></tr>
<tr>
<td>CS_BGR_ITL </td><td>GST_VIDEO_FORMAT_BGR </td><td>bgr </td><td>Element-interleaved BGR data </td></tr>
<tr>
<td>CS_NV12 </td><td>GST_VIDEO_FORMAT_NV12 </td><td>nv12 </td><td>YUV NV12 format data </td></tr>
</table>
<p >The CVflow <code>data_format</code> parameter defines the signedness, element size, and precision for each vector, which is as follows: <br  />
</p><ul>
<li><b>First argument:</b> specifies signed / unsigned; 0 is unsigned, 1 is signed<br  />
</li>
<li><b>Second argument:</b> specifies the width of the data elements (0 = 8-bit, 1 = 16-bit, and 2 = 32-bit).<br  />
</li>
<li><b>Third argument:</b> specifies the exponent offset <br  />
<ul>
<li>Fixed-point, shifts the binary point to the right by <code>expoffset</code>; maximum range is [0, 15] <br  />
</li>
<li>Float-point, applies a signed binary complement offset to the exponent; maximum range is [-8, 7] <br  />
</li>
</ul>
</li>
<li><b>Fourth argument:</b> specifies the value to determine the number of bits reserved in a data element for the exponent field; maximum value is 7 <br  />
<ul>
<li>A value of 0 indicates fixed-point numbers</li>
<li>If the value is greater than 0, the number of exponent bits is (expbits + 1); 4 means FP16, 7 means FP32</li>
<li>Integer format is supported as a special case of fixed-point numbers where the <code>expoffset</code> and <code>expbits</code> fields are both 0</li>
</ul>
</li>
</ul>
<p >For example: <br  />
 </p><div class="fragment"><div class="line">ufix8_8 (0,0,8,0)  =&gt;  [0,2^(8-0)/2^8 )=[0,1)</div>
<div class="line">sfix8_8 (1,0,8,0)  =&gt;  [-2^(8-1)/2^8 ,2^(8-1)/2^8 )=[-0.5,0.5)</div>
<div class="line">sfix16_5 (1,1,5,0) =&gt;  [-2^(16-1)/2^5 ,2^(16-1)/2^5 )=[-1024,1024)</div>
</div><!-- fragment --><p >Refer to the CNNGen document <em>Ambarella CV2x CNNGen Simple Introduction Customer</em> for more information. <br  />
</p>
<dl class="section note"><dt>Note</dt><dd><ul>
<li>The output is always set to FP32 / FP16. FP32 should be [1, 2, 0, 7]; FP16 (equal with FP16 defined in IEEE-754) should be [1, 1, 0 ,4].</li>
<li>For the input, the <code>amba_cvflow</code> framework has added support for 8- / 32-bit data format. The 16-bit data format is not supported.</li>
</ul>
</dd></dl>
<p><b>tensor_decoder </b> <br  />
</p>
<p >The <code>bounding_boxes</code> is a sub-plugin of <code>tensor_decoder</code> that provides post-processing methods for some NNs such as mobilenet-ssd and converts tensors to video stream (RGBA) with boxes on transparent background. <br  />
</p>
<p >The following lists the properties in the sub-plugin <code>bounding_boxes</code>. Note that the input dimension of option5 should be equal to the input resolution of NN model. <br  />
</p>
<a class="anchor" id="table_property_in_bounding_boxes"></a>
<table class="doxtable">
<caption>Table 1-8. Properties in bounding_boxes.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>option1 </td><td>String </td><td>NULL </td><td>Required; specifies decoder mode </td></tr>
<tr>
<td>option2 </td><td>String </td><td>NULL </td><td>Required; specifies the path of label file </td></tr>
<tr>
<td>option3 </td><td>String </td><td>NULL </td><td>Any option1-dependent values, more details in the official document </td></tr>
<tr>
<td>option4 </td><td>String </td><td>NULL </td><td>Video Output Dimension (WIDTH:HEIGHT) </td></tr>
<tr>
<td>option5 </td><td>String </td><td>NULL </td><td>Input Dimension (WIDTH:HEIGHT), decided by the resolution of NN input </td></tr>
</table>
<p >The following lists the supported decoder mode of bounding box. Three demos <code>amba_yolov5</code>, <code>amba_tiny_yolov3</code>, and <code>amba_yolop</code> were added for postprocess with NN outputs from <code>amba_cvflow</code>. <br  />
</p>
<a class="anchor" id="table_decoder_mode_in_bounding_boxes"></a>
<table class="doxtable">
<caption>Table 1-9. Supported Decoder Mode in bounding_boxes.</caption>
<tr>
<th>Decoder Mode </th></tr>
<tr>
<td>mobilenet-ssd </td></tr>
<tr>
<td>mobilenet-ssd-postprocess </td></tr>
<tr>
<td>ov-person-detection </td></tr>
<tr>
<td>ov-face-detection </td></tr>
<tr>
<td>mp-palm-detection </td></tr>
<tr>
<td>yolov5 </td></tr>
<tr>
<td>amba_yolov5 </td></tr>
<tr>
<td>amba_tiny_yolov3 </td></tr>
<tr>
<td>amba_yolop </td></tr>
</table>
<p >In option3, add some parameter settings for postprocess with yolov5 / tiny yolov3 / yolop. <br  />
 </p><a class="anchor" id="table_property_for_yolo"></a>
<table class="doxtable">
<caption>Table 1-10. Properties for Yolo.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>f </td><td>Float </td><td>0.3 </td><td>Specifies conf_threshold </td></tr>
<tr>
<td>nms </td><td>Float </td><td>0.6 </td><td>Specifies nms_threshold </td></tr>
<tr>
<td>top_k </td><td>Integer </td><td>100 </td><td>Specifies top_k </td></tr>
<tr>
<td>u </td><td>Integer </td><td>0 </td><td>Specifies use_multi_class </td></tr>
</table>
<p >To get the post-process results such as bounding boxes informations, add a new sub-plugin <code>bounding_boxes_ori</code> which was modified from <code>bounding_boxes</code> to transfer NN results directly to the next without drawing on video. The difference between them was the output encapsulation format. The NN results were stored in tensors without converting to the video.<br  />
</p>
<h2><a class="anchor" id="amba_gstreamer_plugins"></a>
1.4 Amba GStreamer Plugins</h2>
<p >This is a set of GStreamer plugins that provide multi-media and machine-learning-related processing on Ambarella platforms. <br  />
</p>
<h3><a class="anchor" id="amba_gst_plugin_history"></a>
1.4.1 Library Revision History</h3>
<a class="anchor" id="table_amba_gst_plugin_history"></a>
<table class="doxtable">
<caption>Table 1-11. History of Amba Gst Plugin Library.</caption>
<tr>
<th>Library Version </th><th>License </th><th>Updated Date </th><th>Modification </th></tr>
<tr>
<td>1.2.1 </td><td>LGPL-2.1 </td><td>20230524 </td><td>Initial Version </td></tr>
</table>
<h3><a class="anchor" id="amba_gst_plugin_element"></a>
1.4.2 List of Supported Elements</h3>
<a class="anchor" id="table_element_in_amba_gst_plugin"></a>
<table class="doxtable">
<caption>Table 1-12. Supported Elements in Amba Gst Plugin.</caption>
<tr>
<th>Element Name </th><th>Supported Since Package Version </th><th>Description </th></tr>
<tr>
<td>amba_camsrc </td><td>1.2.1 </td><td>Camera source; outputs YUV frames </td></tr>
<tr>
<td>amba_hwvdec </td><td>1.2.1 </td><td>Hardware video decoder </td></tr>
<tr>
<td>amba_venccap </td><td>1.2.1 </td><td>Video encoder: capture </td></tr>
<tr>
<td>amba_vencdemux </td><td>1.2.1 </td><td>Video encoder: demux </td></tr>
<tr>
<td>amba_venc_overlay </td><td>1.2.1 </td><td>Video encoder: overlay </td></tr>
<tr>
<td>mlinference </td><td>1.2.1 </td><td>Machine learning inference </td></tr>
<tr>
<td>amba_heicfilesink </td><td>1.2.1 </td><td>High-efficiency image container (HEIC) file sink </td></tr>
<tr>
<td>amba_vsink </td><td>1.2.1 </td><td>Video sink; do nothing </td></tr>
</table>
<h3><a class="anchor" id="element_amba_camsrc"></a>
1.4.3 amba_camsrc</h3>
<p >This element is used to capture YUV frames from the Ambarella camera source. <br  />
</p>
<p ><b>Pad Templates </b> <br  />
</p>
<div class="fragment"><div class="line">SRC <span class="keyword">template</span>: <span class="stringliteral">&#39;src&#39;</span></div>
<div class="line">    Availability: Always</div>
<div class="line">    Capabilities:</div>
<div class="line">        video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div>
<div class="line">            <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: NV12</div>
<div class="line">            width: [ 1, 2147483647 ]</div>
<div class="line">            height: [ 1, 2147483647 ]</div>
<div class="line">            framerate: [ 0/1, 2147483647/1 ]</div>
<div class="ttc" id="acJSON_8h_html_a788db922597cf2fb6389e278f822e59f"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div><div class="ttdeci">const char *const const char *const raw</div><div class="ttdef"><b>Definition:</b> cJSON.h:270</div></div>
<div class="ttc" id="acJSON_8h_html_adb411a44855a4c49231d72a0fc9a3b3b"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a></div><div class="ttdeci">char const int const cJSON_bool format</div><div class="ttdef"><b>Definition:</b> cJSON.h:163</div></div>
</div><!-- fragment --><p ><b>Properties </b> <br  />
</p>
<a class="anchor" id="table_property_in_amba_camsrc"></a>
<table class="doxtable">
<caption>Table 1-13. Properties in amba_camsrc.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>buf-id </td><td>Unsigned integer </td><td>0 </td><td>Specifies the canvas source buffer ID </td></tr>
<tr>
<td>gdma </td><td>Unsigned integer </td><td>1 </td><td>Enables graphics direct memory access (GDMA) copy </td></tr>
<tr>
<td>dump </td><td>String </td><td>NULL </td><td>Dumped file name </td></tr>
</table>
<h3><a class="anchor" id="element_amba_hwvdec"></a>
1.4.4 amba_hwvdec</h3>
<p >This element is used for the Ambarella hardware video decoder. <br  />
</p>
<p ><b>Pad Templates </b> <br  />
</p>
<div class="fragment"><div class="line">SINK <span class="keyword">template</span>: <span class="stringliteral">&#39;sink&#39;</span></div>
<div class="line">  Availability: Always</div>
<div class="line">  Capabilities:</div>
<div class="line">    video/x-h264</div>
<div class="line">        stream-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)<span class="keywordtype">byte</span>-stream, (<span class="keywordtype">string</span>)avc, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)avc3 }</div>
<div class="line">            alignment: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)nal }</div>
<div class="line">    video/x-h265</div>
<div class="line">        stream-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)<span class="keywordtype">byte</span>-stream, (<span class="keywordtype">string</span>)hvc1, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)hev1 }</div>
<div class="line">            alignment: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)nal }</div>
<div class="line"> </div>
<div class="line">SRC <span class="keyword">template</span>: <span class="stringliteral">&#39;src&#39;</span></div>
<div class="line">  Availability: Always</div>
<div class="line">  Capabilities:</div>
<div class="line">    video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div>
<div class="line">              <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: I420</div>
<div class="line">               width: [ 1, 2147483647 ]</div>
<div class="line">              height: [ 1, 2147483647 ]</div>
<div class="line">           framerate: [ 0/1, 2147483647/1 ]</div>
<div class="ttc" id="acJSON_8h_html_addf925fe055723aa55a381a1ba45bda2"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a></div><div class="ttdeci">const char *const string</div><div class="ttdef"><b>Definition:</b> cJSON.h:172</div></div>
</div><!-- fragment --><p ><b>Properties </b> <br  />
</p>
<a class="anchor" id="table_property_in_amba_hwvdec"></a>
<table class="doxtable">
<caption>Table 1-14. Properties in amba_hwvdec.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>vout-number </td><td>Unsigned char </td><td>1 </td><td>Specifies the video output (VOUT) number </td></tr>
<tr>
<td>decoder-number </td><td>Unsigned char </td><td>1 </td><td>Specifies the decoder number </td></tr>
<tr>
<td>decoder-id </td><td>Unsigned char </td><td>0 </td><td>Sets up the decoder ID </td></tr>
<tr>
<td>decoder-config-id </td><td>Unsigned char </td><td>0 </td><td>Provides the decoder ID to be configured </td></tr>
<tr>
<td>vout-id </td><td>Unsigned char </td><td>0 </td><td>Sets up VOUT ID </td></tr>
<tr>
<td>vout-config-id </td><td>Unsigned char </td><td>0 </td><td>Provides the VOUT ID to be configured </td></tr>
<tr>
<td>enable-vout </td><td>Unsigned char </td><td>1 </td><td>Enables VOUT for the configured decoder </td></tr>
<tr>
<td>enable-pb-pyramid </td><td>Unsigned char </td><td>0 </td><td>Enables PB pyramid for the configured decoder </td></tr>
<tr>
<td>enable-hevc-per-tile </td><td>Unsigned char </td><td>0 </td><td>Enables high-efficiency video coding (HEVC) per tile </td></tr>
<tr>
<td>hevc-tile-num </td><td>Unsigned char </td><td>3 </td><td>Sets up HEVC tile number </td></tr>
<tr>
<td>vout-mode </td><td>String </td><td>NULL </td><td>Sets up VOUT mode for the configured decoder </td></tr>
<tr>
<td>vout-sink-type </td><td>String </td><td>NULL </td><td>Sets up VOUT sink type for the configured decoder </td></tr>
<tr>
<td>vout-device </td><td>String </td><td>NULL </td><td>Sets up VOUT device for the configured decoder </td></tr>
<tr>
<td>enable-vout-digital </td><td>Unsigned char </td><td>0 </td><td>Enables VOUT digital for the configured decoder </td></tr>
<tr>
<td>enable-vout-hdmi </td><td>Unsigned char </td><td>0 </td><td>Enables the VOUT high-definition multimedia interface (HDMIÂ®) for the configured decoder </td></tr>
<tr>
<td>enable-vout-cvbs </td><td>Unsigned char </td><td>0 </td><td>Enables VOUT composite video with blanking and sync (CVBS) for the configured decoder </td></tr>
<tr>
<td>cap-max-codec-height </td><td>Unsigned int </td><td>480 </td><td>Caps the maximum codec height for the configured decoder </td></tr>
<tr>
<td>cap-max-codec-width </td><td>Unsigned int </td><td>720 </td><td>Caps the maximum codec width for the configured decoder </td></tr>
<tr>
<td>max-gop-size </td><td>Unsigned char </td><td>0 </td><td>Sets up the maximum group of pictures (GOP) size </td></tr>
<tr>
<td>cur-gop-size </td><td>Unsigned char </td><td>0 </td><td>Sets up the current GOP size </td></tr>
<tr>
<td>codec-format </td><td>Unsigned int </td><td>0x01 </td><td>Sets up the codec format for the configured decoder </td></tr>
<tr>
<td>frame-rate-num </td><td>Unsigned int </td><td>0 </td><td>Frame rate number </td></tr>
<tr>
<td>frame-rate-den </td><td>Unsigned int </td><td>0 </td><td>Frame rate den </td></tr>
<tr>
<td>add-gop-header </td><td>Unsigned char </td><td>0 </td><td>Adds a GOP header </td></tr>
<tr>
<td>stream-format </td><td>String </td><td>"h264" </td><td>the stream format </td></tr>
</table>
<h3><a class="anchor" id="element_amba_venccap"></a>
1.4.5 amba_venccap</h3>
<p >This element is used to capture streams from the Ambarella video encoder. <br  />
</p>
<p ><b>Pad Templates </b> <br  />
</p>
<div class="fragment"><div class="line">SRC <span class="keyword">template</span>: <span class="stringliteral">&#39;src&#39;</span></div>
<div class="line">  Availability: Always</div>
<div class="line">  Capabilities:</div>
<div class="line">    video/x-h264</div>
<div class="line">        stream-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)<span class="keywordtype">byte</span>-stream, (<span class="keywordtype">string</span>)avc, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)avc3 }</div>
<div class="line">            framerate: [ 0/1, 2147483647/1 ]</div>
<div class="line">            alignment: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)nal }</div>
<div class="line">    video/x-h265</div>
<div class="line">        stream-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)<span class="keywordtype">byte</span>-stream, (<span class="keywordtype">string</span>)hvc1, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)hev1 }</div>
<div class="line">            framerate: [ 0/1, 2147483647/1 ]nal }</div>
<div class="line">            alignment: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)nal }</div>
</div><!-- fragment --><p ><b>Properties </b> <br  />
</p>
<a class="anchor" id="table_property_in_amba_venccap"></a>
<table class="doxtable">
<caption>Table 1-15. Properties in amba_venccap.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>enc </td><td>String </td><td>"stream_id:0" </td><td>Encoding setting </td></tr>
<tr>
<td>alloc_mem </td><td>Unsigned int </td><td>0 </td><td>Allocates memory for the output buffer </td></tr>
<tr>
<td>sync </td><td>Boolean </td><td>true </td><td>Synchronizes to the pipeline clock </td></tr>
</table>
<h3><a class="anchor" id="element_amba_vencdemux"></a>
1.4.6 amba_vencdemux</h3>
<p >This element is used to demux streams from the Ambarella video encoder. <br  />
</p>
<p ><b>Pad Templates </b> <br  />
</p>
<div class="fragment"><div class="line">SINK <span class="keyword">template</span>: <span class="stringliteral">&#39;sink&#39;</span></div>
<div class="line">  Availability: Always</div>
<div class="line">  Capabilities:</div>
<div class="line">    ANY</div>
<div class="line"> </div>
<div class="line">SRC <span class="keyword">template</span>: <span class="stringliteral">&#39;stream_%u&#39;</span></div>
<div class="line">  Availability: Sometimes</div>
<div class="line">  Capabilities:</div>
<div class="line">    ANY</div>
</div><!-- fragment --><p ><b>Properties </b> <br  />
</p>
<a class="anchor" id="table_property_in_amba_vencdemux"></a>
<table class="doxtable">
<caption>Table 1-16. Properties in amba_vencdemux.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>filename-base </td><td>String </td><td>NULL </td><td>Locations of the file to write </td></tr>
<tr>
<td>heic-capture-id </td><td>String </td><td>"-1" </td><td>Captured HEIC stream indexes </td></tr>
<tr>
<td>heic-capture-close-id </td><td>String </td><td>"-1" </td><td>Close-captured HEIC stream index </td></tr>
</table>
<h3><a class="anchor" id="element_amba_venc_overlay"></a>
1.4.7 amba_venc_overlay</h3>
<p >This element is used to draw a bounding box on the overlay for video stream encoding. <br  />
</p>
<p ><b>Pad Templates </b> <br  />
</p>
<div class="fragment"><div class="line">SINK <span class="keyword">template</span>: <span class="stringliteral">&#39;sink&#39;</span></div>
<div class="line">  Availability: Always</div>
<div class="line">  Capabilities:</div>
<div class="line">    video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div>
<div class="line">            <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: GST_VIDEO_FORMATS_ALL</div>
<div class="line">            width: [ 1, 2147483647 ]</div>
<div class="line">            height: [ 1, 2147483647 ]</div>
<div class="line">        framerate: [ 0/1, 2147483647/1 ]</div>
</div><!-- fragment --><p ><b>Properties </b> <br  />
</p>
<a class="anchor" id="table_property_in_amba_venc_overlay"></a>
<table class="doxtable">
<caption>Table 1-17. Properties in amba_venc_overlay.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>stream_id </td><td>Unsigned int </td><td>0 </td><td>Provides the stream ID </td></tr>
<tr>
<td>roi </td><td>String </td><td>NULL </td><td>Sets up input ROIs </td></tr>
<tr>
<td>color_number </td><td>Unsigned int </td><td>360 </td><td>Sets up the color number </td></tr>
<tr>
<td>clut_start </td><td>Unsigned int </td><td>0 </td><td>Sets up the color lookup table (CLUT) start </td></tr>
<tr>
<td>clut_end </td><td>Unsigned int </td><td>127 </td><td>Sets up the CLUT end </td></tr>
<tr>
<td>clut_ratio </td><td>Unsigned int </td><td>1 </td><td>Sets up the CLUT ratio </td></tr>
<tr>
<td>buf_num </td><td>Unsigned int </td><td>4 </td><td>Sets up the buffer number </td></tr>
<tr>
<td>alpha </td><td>Unsigned int </td><td>128 </td><td>Sets up alpha </td></tr>
<tr>
<td>score_lmt </td><td>Float </td><td>0.7 </td><td>Sets up the box's score limit </td></tr>
<tr>
<td>cal_center_w </td><td>Unsigned int </td><td>10 </td><td>Sets up the calibration center width </td></tr>
<tr>
<td>cal_center_h </td><td>Unsigned int </td><td>10 </td><td>Sets up the calibration center height </td></tr>
<tr>
<td>font </td><td>String </td><td>"arial.ttf" </td><td>Sets up the font <code>*.ttf</code> file </td></tr>
</table>
<h3><a class="anchor" id="element_amba_mlinference"></a>
1.4.8 mlinference</h3>
<p >This element is used for machine learning inference with Ambarella CVflow. <br  />
</p>
<p ><b>Pad Templates </b> <br  />
</p>
<div class="fragment"><div class="line">SINK <span class="keyword">template</span>: <span class="stringliteral">&#39;sink&#39;</span></div>
<div class="line">    Availability: Always</div>
<div class="line">    Capabilities:</div>
<div class="line">      video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div>
<div class="line">                  <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)RGBP, (<span class="keywordtype">string</span>)NV12, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)RGB, (<span class="keywordtype">string</span>)RGBP, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)BGR, (<span class="keywordtype">string</span>)BGRP }</div>
<div class="line">    Capabilities:</div>
<div class="line">      video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div>
<div class="line">                  <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)RGBP, (<span class="keywordtype">string</span>)NV12, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)RGB, (<span class="keywordtype">string</span>)RGBP, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)BGR, (<span class="keywordtype">string</span>)BGRP }</div>
<div class="line">                   width: [ 1, 2147483647 ]</div>
<div class="line">                  height: [ 1, 2147483647 ]</div>
<div class="line">               framerate: [ 0/1, 2147483647/1 ]</div>
<div class="line"> </div>
<div class="line">SRC <span class="keyword">template</span>: <span class="stringliteral">&#39;src&#39;</span></div>
<div class="line">    Availability: Always</div>
<div class="line">    Capabilities:</div>
<div class="line">      video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div>
<div class="line">                  <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: { (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)RGBP, (<span class="keywordtype">string</span>)NV12, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)RGB, (<span class="keywordtype">string</span>)BGR, (<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#addf925fe055723aa55a381a1ba45bda2">string</a>)BGRP }</div>
<div class="line">                   width: [ 1, 2147483647 ]</div>
<div class="line">                  height: [ 1, 2147483647 ]</div>
<div class="line">               framerate: [ 0/1, 2147483647/1 ]</div>
</div><!-- fragment --><p ><b>Properties </b> <br  />
</p>
<a class="anchor" id="table_property_in_mlinference"></a>
<table class="doxtable">
<caption>Table 1-18. Properties in mlinference.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>in_name </td><td>String </td><td>NULL </td><td>Required; provides NN input features' name </td></tr>
<tr>
<td>out_name </td><td>String </td><td>NULL </td><td>Required; provides NN output features's name </td></tr>
<tr>
<td>label </td><td>String </td><td>NULL </td><td>Provides label file name if post-processing is required </td></tr>
<tr>
<td>dump </td><td>String </td><td>NULL </td><td>Sets up a dumped file name if dumping NN outputs is required </td></tr>
<tr>
<td>model </td><td>String </td><td>NULL </td><td>Required; provides a model file name </td></tr>
<tr>
<td>type </td><td>String </td><td>NULL </td><td>Provides a model type if required to enable post-processing </td></tr>
<tr>
<td>conf_threshold </td><td>Float </td><td>0.2 </td><td>Sets up a conf threshold for post-processing </td></tr>
<tr>
<td>nms </td><td>Float </td><td>0.5 </td><td>Sets up an NMS threshold for post-processing </td></tr>
<tr>
<td>top_k </td><td>Int </td><td>100 </td><td>Sets up a top K for post-processing </td></tr>
<tr>
<td>use_multi_cls </td><td>Int </td><td>0 </td><td>Uses multiple classes for post-processing </td></tr>
<tr>
<td>color_space </td><td>String </td><td>"rgb" </td><td>Provides input feature color space of the model, if not planar RGB </td></tr>
<tr>
<td>roi </td><td>String </td><td>NULL </td><td>Sets up ROI of inputs, if required </td></tr>
</table>
<h3><a class="anchor" id="element_amba_heicfilesink"></a>
1.4.9 amba_heicfilesink</h3>
<p >This element is used to dump HEIC files. <br  />
</p>
<p ><b>Pad Templates </b> <br  />
</p>
<div class="fragment"><div class="line">SINK <span class="keyword">template</span>: <span class="stringliteral">&#39;sink&#39;</span></div>
<div class="line">  Availability: Always</div>
<div class="line">  Capabilities:</div>
<div class="line">    ANY</div>
</div><!-- fragment --><p ><b>Properties </b> <br  />
</p>
<a class="anchor" id="table_property_in_amba_heicfilesink"></a>
<table class="doxtable">
<caption>Table 1-19. Properties in amba_heicfilesink.</caption>
<tr>
<th>Property </th><th>Type </th><th>Default </th><th>Description </th></tr>
<tr>
<td>filename-base </td><td>String </td><td>NULL </td><td>Specifies the dumped HEIC file name </td></tr>
</table>
<h3><a class="anchor" id="element_amba_vsink"></a>
1.4.10 amba_vsink</h3>
<p >This element functions as a black hole that absorbs video data, similar to <code>fakesink</code> in GStreamer, which discards unwanted data. <br  />
</p>
<p ><b>Pad Templates </b> <br  />
</p>
<div class="fragment"><div class="line">SINK <span class="keyword">template</span>: <span class="stringliteral">&#39;sink&#39;</span></div>
<div class="line">  Availability: Always</div>
<div class="line">  Capabilities:</div>
<div class="line">    video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>(ANY)</div>
<div class="line">    <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>: GST_VIDEO_FORMATS_ALL</div>
</div><!-- fragment --><hr  />
<h1><a class="anchor" id="gstreamer_user_guide"></a>
2. User Guide</h1>
<p >This chapter provides demonstrates how to compile GStreamer-related libraries on Ambarella platforms, how to run and debug GStreamer on the board, and provides test cases for typical scenarios such as recording, playing, machine learning, and more. <br  />
</p>
<p >This chapter includes the following sections:</p><ul>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#compilation">2.1 Compilation</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#command_line_tools">2.2 Command Line Tools</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#debug">2.3 Debugging</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#amba_test_cases">2.4 Ambarella Test Cases</a></li>
</ul>
<h2><a class="anchor" id="compilation"></a>
2.1 Compilation</h2>
<p >Confirm that all GStreamer-related options are selected under menuconfig. <br  />
</p>
<div class="fragment"><div class="line">$ cd $(SDK)/ambarella</div>
<div class="line"><span class="preprocessor"># recommend to compile Gstreamer with yocto-build</span></div>
<div class="line"><span class="preprocessor"># for example on cv22</span></div>
<div class="line">$ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> build/env/yocto-build.env cv22_walnut</div>
<div class="line"><span class="preprocessor"># There&#39;re some config files for Gstreamer test which named `*_gst_config`</span></div>
<div class="line">$ make ipcam_gst_config</div>
<div class="line"><span class="preprocessor"># select ambarella gstreamer plugin, nnstreamer, gstd and so in menuconfig</span></div>
<div class="line">$ make menuconfig</div>
<div class="line">  -&gt; meta-ambalib</div>
<div class="line">    -&gt; recipes-ambagstreamer</div>
<div class="line">      -&gt; libgstamba</div>
<div class="line">        -&gt; Build Ambarella GStreamer Plugin</div>
<div class="line">      -&gt; libgstnnstreamer</div>
<div class="line"> </div>
<div class="line">    -&gt; recipes-video</div>
<div class="line">      -&gt; liblwmedia (meta-ambalib/recipes-video/liblwmedia)</div>
<div class="line">        -&gt; Build lw_media unit test</div>
<div class="line">$ make -j16</div>
<div class="ttc" id="avin__init_8c_html_a07a87b2e6ed927503e2f95f119c9fc23"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a></div><div class="ttdeci">int source</div></div>
</div><!-- fragment --><h2><a class="anchor" id="command_line_tools"></a>
2.2 Command Line Tools</h2>
<p >GStreamer includes several commandline tools to help developers prototype their applications. <br  />
 This section includes the following sub-sections:</p><ul>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#gst_inspect_x">2.2.1 gst-inspect-1.0</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#gst_launch_x">2.2.2 gst-launch-1.0</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#gstd_cmdline">2.2.3 GStreamer Daemon Commandline</a></li>
</ul>
<h3><a class="anchor" id="gst_inspect_x"></a>
2.2.1 gst-inspect-1.0</h3>
<p >The <code>gst-inspect-1.0</code> tool prints information on available GStreamer plugins regarding a particular plugin or a particular element. <br  />
</p>
<p >Ambarella recommends creating a checkout on the board at the first instance to verify that all user-required plugins exist. <br  />
</p>
<p ><b>Options </b> <br  />
</p>
<p >There are two common modes of operation. When executed without arguments, <code>gst-inspect-1.0</code> prints a list of all plugins and elements in GStreamer. When executed with a <b>PLUGIN</b> or an <b>ELEMENT</b> argument, <code>gst-inspect-1.0</code> prints information about that plugin or element. <br  />
</p>
<ul>
<li><b>No argument:</b> prints a list of all plugins and elements together with a summary <br  />
</li>
<li><b>PLUGIN:</b> the plugin name <br  />
</li>
<li><b>ELEMENT:</b> the element name <br  />
</li>
<li><b>FILENAME:</b> specifies a file as a GStreamer plugin and prints the list of elements in this plugin <br  />
</li>
<li><b>-h, &ndash;help:</b> prints a help synopsis and available FLAGS <br  />
</li>
<li><b>&ndash;help-all:</b> prints all help options <br  />
</li>
<li><b>&ndash;help-gst:</b> prints GStreamer options <br  />
</li>
<li><b>-a, &ndash;print-all:</b> prints all plugins and elements <br  />
</li>
<li><b>-b, &ndash;print-blacklist:</b> prints a list of blacklisted files <br  />
</li>
<li><b>&ndash;print-plugin-auto-install-info:</b> prints a machine-parsable list of features that the specified plugin provides <br  />
</li>
<li><b>&ndash;gst-info-mask=FLAGS:</b> sets GStreamer information flags (list with &ndash;help) <br  />
</li>
<li><b>&ndash;gst-debug-mask=FLAGS:</b> sets GStreamer debugging flags (list with &ndash;help) <br  />
</li>
<li><b>&ndash;gst-mask=FLAGS:</b> sets GStreamer information and debugging flags (list with &ndash;help) <br  />
</li>
<li><b>&ndash;gst-plugin-spew:</b> sets GStreamer information flags to enable printout of errors while loading GStreamer plugins <br  />
</li>
<li><b>&ndash;gst-plugin-path=PATH:</b> adds directories separated with <code>:</code> to the plugin search path <br  />
</li>
</ul>
<p ><b>Examples </b> <br  />
</p>
<p >Check and print element or plugin information with names in GStreamer. <br  />
 </p><div class="fragment"><div class="line">gst-inspect-1.0 videoconvert</div>
</div><!-- fragment --><p> <br  />
 Check and print element or plugin information with a keyword in GStreamer. <br  />
 </p><div class="fragment"><div class="line">gst-inspect-1.0 | grep video</div>
</div><!-- fragment --><p> <br  />
</p>
<p >Check and print Ambarella plugin information. <br  />
 </p><div class="fragment"><div class="line">gst-inspect-1.0 amba</div>
</div><!-- fragment --><p> <br  />
 Check and print element information in Ambarella plugins. <br  />
 </p><div class="fragment"><div class="line">gst-inspect-1.0 amba_camsrc</div>
</div><!-- fragment --><p> <br  />
 Check and print NNstreamer plugin information. <br  />
 </p><div class="fragment"><div class="line">gst-inspect-1.0 nnstreamer</div>
</div><!-- fragment --><p> <br  />
</p>
<h3><a class="anchor" id="gst_launch_x"></a>
2.2.2 gst-launch-1.0</h3>
<p >The <code>gst-launch-1.0</code> command tool is used to build and run basic GStreamer pipelines.</p>
<div class="fragment"><div class="line">gst-launch-1.0 [OPTIONS] [PIPELINE-DESCRIPTION]</div>
</div><!-- fragment --><p ><b>Options </b> <br  />
</p>
<p >The <code>gst-launch-1.0</code> tool accepts the following options: <br  />
</p>
<ul>
<li><b>&ndash;help:</b> prints help synopsis and available FLAGS <br  />
</li>
<li><b>-v, &ndash;verbose:</b> outputs status information and property notifications <br  />
</li>
<li><b>-q, &ndash;quiet:</b> do not print any progress information <br  />
</li>
<li><b>-m, &ndash;messages:</b> outputs messages posted on the pipeline's bus <br  />
</li>
<li><b>-t, &ndash;tags:</b> outputs tags (also known as metadata) <br  />
</li>
<li><b>-o FILE, &ndash;output=FILE:</b> saves XML representation of the pipeline to FILE and exits <br  />
</li>
<li><b>-f, &ndash;no_fault:</b> do not install a fault handler <br  />
</li>
<li><b>-T, &ndash;trace:</b> prints memory allocation traces; this feature must be enabled at compilation time to function <br  />
</li>
</ul>
<p ><b>Pipeline Description </b> <br  />
</p>
<p >The <code>gst-launch-1.0</code> tool takes a pipeline described as a string to instantiate and run it. <b>PIPELINE-DESCRIPTION</b> is a linked list of elements separated by exclamation marks <code>!</code>.</p>
<div class="fragment"><div class="line">$ gst-launch-1.0 [ELEMENTTYPE] [PROPERTY=...] ! [ELEMENTTYPE] [PROPERTY=...] ...</div>
</div><!-- fragment --><p> <br  />
 For example: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc ! videoconvert ! autovideosink</div>
</div><!-- fragment --><p> <br  />
 A simple pipeline consists of the following parts: <br  />
</p>
<ul>
<li><b>Source elements:</b> interval; only smart rate control (SRC) pads exist in the element <br  />
</li>
<li><b>Filter / filter-like elements:</b> options; both sink pads and SRC pads exist in the element which operate on data received at input (sink) pads, and feed data at their output (source) pads <br  />
</li>
<li><b>Sink elements:</b> interval; only sink pads exist in the element which take in data, but do not produce anything <br  />
</li>
<li><b>!:</b> interval; link mark <br  />
</li>
<li><b>Capabilities:</b> options; specifies what type of information can travel through the pad <br  />
</li>
</ul>
<p ><b>Elements </b> <br  />
</p>
<p >The most important object in GStreamer for developers is the GstElement. Elements are the basic building blocks of multi-media pipelines. <br  />
 Elements can be visualized as black boxes. On one hand, users may place something into the elements which helps perform some functions. On the other hand, users may receive another output from the elements. Pads allow information to enter and leave an element. <br  />
</p>
<p >Create an element of the type <b>ELEMENTTYPE</b> and set its <b>PROPERTIES</b>. The tool <code>gst-inspect-1.0</code> can be used to find information regarding properties and permitted values of different elements. If spaces exist in a property value, users can place them in single or double quotes. <br  />
</p>
<div class="fragment"><div class="line">[ELEMENTTYPE] [PROPERTY1=VALUE1 PROPERTY2=VALUE2 ...]</div>
</div><!-- fragment --><p >For example: </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc pattern=11 ! videoconvert ! autovideosink</div>
</div><!-- fragment --><p ><b>Source Elements </b> <br  />
</p>
<p >A source element is an element that provides data to the pipeline. It does typically not possess any sink (input) pads. <br  />
 Typical source elements include the following:</p>
<ul>
<li><b>File readers:</b> load files <br  />
</li>
<li><b>Network elements:</b> load and run networks, lively or not lively <br  />
</li>
<li><b>Capture elements:</b> capture video, audio, and more <br  />
</li>
<li><b>Generators:</b> generate signals, video, audio, and more <br  />
</li>
</ul>
<div class="image">
<img src="../../source_element.png" alt=""/>
<div class="caption">
Figure 2-1. Source Element.</div></div>
<p> <br  />
</p>
<p ><b>Filter / Filter-Like Elements </b> <br  />
</p>
<p >Filter / filter-like elements have both input (sink) and output (source) pads. They operate on data received at input pads and feed data to their output pads. <br  />
 Typical filter / filter-like elements include the following:</p>
<ul>
<li><b>Filters </b> <br  />
</li>
<li><b>Convertors </b> <br  />
</li>
<li><b>Demuxers </b> <br  />
</li>
<li><b>Muxers </b> <br  />
</li>
<li><b>Codecs </b> <br  />
</li>
</ul>
<div class="image">
<img src="../../filter_element.png" alt=""/>
<div class="caption">
Figure 2-2. Filter Element.</div></div>
<p> <br  />
</p>
<div class="image">
<img src="../../demuxer_element.png" alt=""/>
<div class="caption">
Figure 2-3. Demuxer Element.</div></div>
<p> <br  />
</p>
<p ><b>Sink Elements </b> <br  />
</p>
<p >Sink elements consume data and typically have no source pads. <br  />
 Typical sink elements include the following:</p>
<ul>
<li><b>Audio / video renderers </b> <br  />
</li>
<li><b>Network sinks </b> <br  />
</li>
<li><b>Filesinks </b> <br  />
</li>
</ul>
<div class="image">
<img src="../../sink_element.png" alt=""/>
<div class="caption">
Figure 2-4. Sink Element.</div></div>
<p> <br  />
</p>
<p ><b>Links </b> <br  />
</p>
<p >The simplest link is an exclamation mark <code>!</code>. <br  />
</p>
<p >Names can be set on elements using the name property. If the name is omitted, the element that was specified directly in front of or after the link is used. <br  />
</p>
<div class="fragment"><div class="line">[[ELEMENTTYPE] [<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=NAME1] ! ... [NAME1.] ! ...</div>
<div class="ttc" id="acJSON_8h_html_a25d22ecc7e656d2c59332072684e8766"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a></div><div class="ttdeci">const char *const name</div><div class="ttdef"><b>Definition:</b> cJSON.h:264</div></div>
</div><!-- fragment --><p >Users can use element names to implement complex pipelines with multiple branches. This is common for elements with multiple output / input (mux, demux, tee, and more). <br  />
</p>
<p >The following command creates two branches from tee, each for different sinks. After one branch is finished (reaching the sink), users can create a new branch with a name followed by a dot ([NAME.]). <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc ! videoconvert ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t ! queue ! autovideosink t. ! queue ! autovideosink</div>
</div><!-- fragment --><p >In the same way, multiple branches can also be merged into one. First, decode the files, encode the video to H.264 and the audio to MP3, and finally merge them to produce a TS file. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=surround.mp4 ! decodebin <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dmux ! queue ! audioconvert ! lamemp3enc ! mux. \</div>
<div class="line">  dmux. ! queue ! x264enc ! mpegtsmux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux ! queue ! filesink location=out.ts</div>
</div><!-- fragment --><p >In the example above, for elements which have only one input / output pad, there is no need to connect with pads. If a pad name is provided in an element, the link is performed using that pad. If no pad names are provided, all possibilities are tried and a compatible pad is used. If multiple pad names are provided, both sides must have the same number of pads specified and multiple links are performed in the given order. The tool <code>gst-inspect-1.0</code> can help find all pads in a specific element. <br  />
</p>
<p >Link the element with the name <b>SRCELEMENT</b> to the element with the name <b>SINKELEMENT</b>. <br  />
 </p><div class="fragment"><div class="line">[[SRCELEMENT].[PAD1,...]] ! [[SINKELEMENT].[PAD1,...]]</div>
</div><!-- fragment --><p >For example: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=a autovideosink <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> a.src ! <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a>.sink</div>
<div class="ttc" id="acJSON_8h_html_a1a175e87536301df98c805ac0636ad7c"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a></div><div class="ttdeci">const cJSON *const b</div><div class="ttdef"><b>Definition:</b> cJSON.h:255</div></div>
</div><!-- fragment --><p >However, because there are no other symbols but spaces before and after element names, the order between elements and link marks is not important for <code>gst-launch-1.0</code>. The example is as shown below: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=a a.src ! <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a>.sink autovideosink <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a></div>
</div><!-- fragment --><p >A simplified version is as shown below: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc ! autovideosink</div>
</div><!-- fragment --><p ><b>Capabilities </b> <br  />
</p>
<p >The capabilities (caps) of a pad specify what type of information can travel through the pad. In order for two elements to be linked together, they must share a common subset of capabilities. However, the actual information traveling from pad to pad must have only one well-specified type through a process known as negotiation. The caps filter functions as an element that only accepts the specified data type and passes the data to the next element, which can effectively solve the ambiguity issue. <br  />
</p>
<p >The following links the element with the name <b>SRCELEMENT</b> to the element with the name &lt;bSINKELEMENT, using the capability specified in <b>CAPS</b> as a filter. <br  />
</p>
<div class="fragment"><div class="line">[[SRCELEMENT].[PAD1,...]] ! CAPS ! [[SINKELEMENT].[PAD1,...]]</div>
</div><!-- fragment --><p >Users can create a capability with the provided mimetype and optionally with provided properties. The mimetype can be escaped using '"' or '''. If users want to use chain caps, they can add more caps in the same format afterwards. <br  />
</p>
<div class="fragment"><div class="line">MIMETYPE [, PROPERTY[, PROPERTY ...]]] [; CAPS[; CAPS ...]]</div>
</div><!-- fragment --><p >For example: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc ! <span class="stringliteral">&#39;video/x-raw, width=1920, height=1080&#39;</span> ! autovideosink</div>
<div class="line">$ gst-launch-1.0 videotestsrc ! <span class="stringliteral">&quot;video/x-raw, width=1920, height=1080&quot;</span> ! autovideosink</div>
</div><!-- fragment --><p> <br  />
</p>
<p >Note that the properties of <b>CAPS</b> are separated by commas; this is different from that of elements whose properties are separated by whitespace. <br  />
</p>
<p >For types of caps properties, GStreamer provides keywords to convert: <br  />
</p>
<ul>
<li><b>i or int:</b> integer values or ranges <br  />
</li>
<li><b>f or float:</b> float values or ranges <br  />
</li>
<li><b>4 or fourcc:</b> FOURCC values <br  />
</li>
<li><b>b, bool, or boolean:</b> Boolean values <br  />
</li>
<li><b>s, str, or string:</b> strings <br  />
</li>
<li><b>fraction:</b> fractions <br  />
</li>
<li><b>l or list:</b> lists <br  />
</li>
</ul>
<p >If no type was provided, the following order is attempted: integer, float, Boolean, then string. <br  />
</p>
<p ><b>Examples </b> <br  />
</p>
<p >The examples below assume that users have the correct plugins available.</p>
<p ><b>Audio / Video Playback </b> <br  />
</p>
<div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=123.mp3 ! decodebin ! audioconvert ! audioresample ! autoaudiosink</div>
</div><!-- fragment --><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=123.mp4 ! decodebin ! autovideoconvert ! autovideosink</div>
</div><!-- fragment --><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=123.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demux demux.video_0 ! queue ! decodebin ! videoconvert ! videoscale ! autovideosink</div>
</div><!-- fragment --><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=123.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demux  demux.  ! queue ! decodebin  ! autovideosink  demux. ! queue  ! decodebin  ! audioconvert ! audioresample ! autoaudiosink</div>
</div><!-- fragment --><p ><b>H.264 / H.265 Decode </b> <br  />
</p>
<div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=1.h264 ! decodebin  ! autovideosink</div>
</div><!-- fragment --><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=1.h264 ! video/x-h264 ! h264parse ! avdec_h264 ! autovideosink</div>
</div><!-- fragment --><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=1.h265 ! video/x-h265 ! h265parse ! avdec_h265 ! autovideosink</div>
</div><!-- fragment --><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=1.h264 ! video/x-h264 ! h264parse ! avdec_h264 ! filesink  location=1.yuv</div>
</div><!-- fragment --><p ><b>JPEG Encode / Decode </b> <br  />
</p>
<div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=test_mjpeg.mp4 ! qtdemux ! jpegdec ! multifilesink location=%02d.yuv</div>
</div><!-- fragment --><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc blocksize=xxx location=xxx.yuv ! <span class="stringliteral">&quot;video/x-raw,format=I420,width=1280,height=720&quot;</span> ! videoconvert ! jpegenc ! filesink location=yyy.jpg</div>
</div><!-- fragment --><p >For more details, refer to section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#amba_test_cases">2.4 Ambarella Test Cases</a>. <br  />
</p>
<h3><a class="anchor" id="gstd_cmdline"></a>
2.2.3 GStreamer Daemon Commandline</h3>
<p >This section describes how initialize and run GstD, and demonstrates how to use the GstdClient application to draft tests. <br  />
</p>
<p ><b>Local Shell </b> <br  />
</p>
<p >Start the GStreamer Daemon in the local system: <br  />
 For GstD Yocto community version 0.8.0: <br  />
 </p><div class="fragment"><div class="line">$ gstd -D</div>
</div><!-- fragment --><p >For the newer GstD version 0.15.0: <br  />
 </p><div class="fragment"><div class="line">$ gstd</div>
</div><!-- fragment --><p >This starts the process in the background. Different options can be configured for the server: <br  />
 </p><div class="fragment"><div class="line">$ gstd --help-all</div>
</div><!-- fragment --><p ><b>Remote Shell </b> <br  />
</p>
<p >Start the GStreamer client in an external system where the client application can run and request commands: <br  />
 </p><div class="fragment"><div class="line">$ gst-client</div>
</div><!-- fragment --><p >Once the server is up and running, users may use the commandline application to create, play, and stop pipelines. <br  />
</p>
<div class="fragment"><div class="line"><span class="preprocessor"># Create the pipeline</span></div>
<div class="line">$ pipeline_create testpipe videotestsrc <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=vts ! autovideosink</div>
<div class="line"><span class="preprocessor"># Play the pipeline</span></div>
<div class="line">$ pipeline_play testpipe</div>
<div class="line"><span class="preprocessor"># Change a property</span></div>
<div class="line">$ element_set testpipe vts pattern ball</div>
<div class="line"><span class="preprocessor"># Stop the pipeline</span></div>
<div class="line">$ pipeline_stop testpipe</div>
<div class="line"><span class="preprocessor"># Destroy the pipeline</span></div>
<div class="line">$ pipeline_delete testpipe</div>
</div><!-- fragment --><p >To list all possible commands in gst-client: <br  />
 </p><div class="fragment"><div class="line">$ help</div>
</div><!-- fragment --><p >Alternatively, users may use the commandline application in single-command mode, in which the command is provided as an argument. This mode is ideal for shell scripts. For example: <br  />
 </p><div class="fragment"><div class="line">$ gst-client list_pipelines</div>
</div><!-- fragment --><p >More can be found at the following official website link: <br  />
 <a href="https://developer.ridgerun.com/wiki/index.php/GStreamer_Daemon">https://developer.ridgerun.com/wiki/index.php/GStreamer_Daemon</a> <br  />
</p>
<h2><a class="anchor" id="debug"></a>
2.3 Debugging</h2>
<p >This section provides methods to debug GStreamer. <br  />
 This section includes the following sub-sections:</p><ul>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#gst_launch_x_debug">2.3.1 Debug with gst-launch-1.0</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#gstd_debug">2.3.2 GstD Debug</a></li>
</ul>
<h3><a class="anchor" id="gst_launch_x_debug"></a>
2.3.1 Debug with gst-launch-1.0</h3>
<p >There is a comma-separated list of debug categories and levels to aid in developing the user's code. <br  />
 <b>&ndash;gst-debug-help </b> <br  />
 <code>--gst-debug-help</code> prints available debug categories and exits with the GStreamer commandline tool <code>gst-launch-1.0</code>. <br  />
</p>
<p ><b>&ndash;gst-debug-level </b> <br  />
 <code>--gst-debug-level LEVEL</code> sets the default debug level (which can range from 0 (no output) to 9 (everything)). <br  />
</p>
<a class="anchor" id="table_gst_debug_level"></a>
<table class="doxtable">
<caption>Table 2-1. GStreamer Debug Level.</caption>
<tr>
<th>Level </th><th>Property </th><th>Description </th></tr>
<tr>
<td>0 </td><td>none </td><td>No debug information </td></tr>
<tr>
<td>1 </td><td>ERROR </td><td>Logs all fatal errors that do not allow the core or elements to perform the requested action </td></tr>
<tr>
<td>2 </td><td>WARNING </td><td>Logs all warnings that are non-fatal, but user-visible problems </td></tr>
<tr>
<td>3 </td><td>FIXME </td><td>Logs all fixme messages that indicate something in the executed code path is not fully implemented or managed yet </td></tr>
<tr>
<td>4 </td><td>INFO </td><td>Logs all informational messages for events in the system that only occur once, or are important and rare enough to be logged at this level </td></tr>
<tr>
<td>5 </td><td>DEBUG </td><td>Logs all debug messages for events that occur a limited number of times during an object's lifetime </td></tr>
<tr>
<td>6 </td><td>LOG </td><td>Logs all log messages for events that occur repeatedly during an object's lifetime </td></tr>
<tr>
<td>7 </td><td>TRACE </td><td>Logs all trace messages for events that occur repeatedly during an object's lifetime, such as the ref / unref cycles </td></tr>
<tr>
<td>9 </td><td>MEMDUMP </td><td>Hex dump of buffer contents </td></tr>
</table>
<p >For example: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc ! fakesink --gst-debug-level 3</div>
</div><!-- fragment --><p ><b>&ndash;gst-debug </b> <br  />
</p>
<p ><code>--gst-debug LIST</code> takes a comma-separated list of <code>category_name:level pairs</code> to set specific levels for individual categories. For example: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 videotestsrc ! fakesink --gst-debug basesrc:4,basesink:5</div>
</div><!-- fragment --><p ><b>GST_DEBUG </b> <br  />
</p>
<p >Users can set the <code>GST_DEBUG</code> environment variable, which has the same effect as <code>--gst-debug</code>. For example: <br  />
 </p><div class="fragment"><div class="line">$ GST_DEBUG=basesrc:4,basesink:5 gst-launch-1.0 videotestsrc ! fakesink</div>
</div><!-- fragment --><h3><a class="anchor" id="gstd_debug"></a>
2.3.2 GstD Debug</h3>
<p >This section describes how to enable debugging for a given pipeline in the GStreamer Daemon. <br  />
</p>
<p ><b>Bus </b> <br  />
</p>
<p >A GStreamer bus forwards messages generated from the pipeline, and the GStreamer Daemon enables those messages to flow back to the client application. A basic description on how to interact with GStreamer bus properties is provided below; specifically, regarding how to receive messages from the bus. <br  />
</p>
<p ><b>Read Bus </b> <br  />
</p>
<p >Read the pipeline bus: <br  />
 </p><div class="fragment"><div class="line">$ bus_read &lt;name&gt;</div>
</div><!-- fragment --><p ><b>Read and Filter Bus </b> <br  />
</p>
<p >GstD has the capability to read and filter (error+warning+eos) the bus of the pipeline: <br  />
 </p><div class="fragment"><div class="line">$ bus_filter &lt;name&gt; &lt;filter&gt;</div>
</div><!-- fragment --><p ><b>Bus Timeout </b> <br  />
</p>
<p >By setting the pipeline bus timeout, the command will block while waiting for messages: <br  />
 </p><div class="fragment"><div class="line">$ bus_timeout &lt;name&gt; &lt;time in nanoseconds&gt;</div>
</div><!-- fragment --><p ><b>Bus Messages </b> <br  />
</p>
<p >The following table lists supported bus messages. Users can use either a hyphen or an underscore in the bus message name. <br  />
</p>
<a class="anchor" id="table_bus_messgae"></a>
<table class="doxtable">
<caption>Table 2-2. Bus Messages in GstD.</caption>
<tr>
<th>Bus Message </th><th>Version </th><th>Meaning </th></tr>
<tr>
<td>eos </td><td>all </td><td>After the pipeline sink element finishes processing EOS, the bus reports the event to the application </td></tr>
<tr>
<td>error </td><td>all </td><td>An element in the pipeline is in the error state </td></tr>
<tr>
<td>warning </td><td>all </td><td>An element in the pipeline encounters a recoverable error </td></tr>
<tr>
<td>info </td><td>all </td><td>An element in the pipeline produces some information </td></tr>
<tr>
<td>tag </td><td>all </td><td>An element in the pipeline decodes metadata about the stream </td></tr>
<tr>
<td>buffering </td><td>all </td><td>An element in the pipeline that is buffering adds a delay until the buffer is full </td></tr>
<tr>
<td>clock_lost </td><td>all </td><td>The pipeline clock is unusable </td></tr>
<tr>
<td>new_clock </td><td>all </td><td>A new clock was selected for the pipeline </td></tr>
<tr>
<td>structure_change </td><td>all </td><td>The buffer flow through the pipeline changed </td></tr>
<tr>
<td>stream_status </td><td>all </td><td>The pipeline started, stopped, or paused </td></tr>
<tr>
<td>element </td><td>all </td><td>Element-specific message </td></tr>
<tr>
<td>segment_start </td><td>all </td><td>New stream segment is being processed </td></tr>
<tr>
<td>segment_done </td><td>all </td><td>Segment seek requested and segment playback completed </td></tr>
<tr>
<td>... </td><td>... </td><td>... </td></tr>
</table>
<p >Details of these messages can be found in the <code>gstd_msg_type_get_type</code> table at <a href="https://github.com/RidgeRun/gstd-1.x/blob/master/gstd/gstd_msg_type.c">https://github.com/RidgeRun/gstd-1.x/blob/master/gstd/gstd_msg_type.c</a> <br  />
</p>
<p >The examples below demonstrate how to use the bus filter and bus read. <br  />
</p>
<p >Error bus filter: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># Create the pipeline that generate an error</span></div>
<div class="line">$ pipeline_create p filesrc location=/tmp/test.avi ! identity error-after=2000 ! avidemux ! avdec_mpeg4 ! fpsdisplaysink</div>
<div class="line"><span class="preprocessor"># Filter only a message error</span></div>
<div class="line">$ bus_filter p error</div>
<div class="line"><span class="preprocessor"># Play the pipeline</span></div>
<div class="line">$ pipeline_play p</div>
<div class="line"><span class="preprocessor"># Waiting until bus read a message error</span></div>
<div class="line">$ bus_read p</div>
</div><!-- fragment --><p >Error bus filter and timeout: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># Create the pipeline that generate an error</span></div>
<div class="line">$ pipeline_create p filesrc location=/tmp/test.avi ! identity error-after=2000 ! avidemux ! avdec_mpeg4 ! fpsdisplaysink</div>
<div class="line"><span class="preprocessor"># Filter only a message error</span></div>
<div class="line">$ bus_filter p error</div>
<div class="line"><span class="preprocessor"># wait 100s to read message error, if not, returns</span></div>
<div class="line">$ bus_timeout p 100000000000</div>
<div class="line"><span class="preprocessor"># Play the pipeline</span></div>
<div class="line">$ pipeline_play p</div>
<div class="line"><span class="preprocessor"># Waiting until bus read a message error</span></div>
<div class="line">$ bus_read p</div>
</div><!-- fragment --><p >Error+EOS bus filter: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># Create the pipeline that generate an eos</span></div>
<div class="line">$ pipeline_create p filesrc location=/tmp/test.avi  ! avidemux ! avdec_mpeg4 ! fpsdisplaysink</div>
<div class="line"><span class="preprocessor"># Filter a message error and EOS message</span></div>
<div class="line">$ bus_filter p error+eos</div>
<div class="line"><span class="preprocessor"># Play the pipeline</span></div>
<div class="line">$ pipeline_play p</div>
<div class="line"><span class="preprocessor"># Waiting until bus read a message error or eos message</span></div>
<div class="line">$ bus_read p</div>
</div><!-- fragment --><p ><b>Debug Subsystem </b> <br  />
</p>
<p ><b>Enabling the Debug Subsystem </b> <br  />
</p>
<p >This section demonstrates how to enable the debug to a given pipeline in the GStreamer Daemon. <br  />
</p>
<p ><b>Enable Debug </b> <br  />
</p>
<div class="fragment"><div class="line">$ debug_enable <span class="keyword">true</span>/<span class="keyword">false</span></div>
</div><!-- fragment --><p ><b>Debug Level </b> <br  />
</p>
<p >Along with specifying a single level, users can also provide a list of comma-separated category:level pairs, such as <code>v4l2src:3,GST_EVENT:5</code> to monitor both what is happening with the v4l2src element and the GStreamer events that are occurring. <br  />
</p>
<div class="fragment"><div class="line">$ debug_threshold threshold</div>
</div><!-- fragment --><p >Refer to <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#gst_launch_x_debug">2.3.1 Debug with gst-launch-1.0</a>; for all possible debug categories, run the following: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 --gst-debug-help</div>
</div><!-- fragment --><p ><b>Enable Debug Colors </b> <br  />
</p>
<div class="fragment"><div class="line">$ debug_color <span class="keyword">true</span>/<span class="keyword">false</span></div>
</div><!-- fragment --><p >The example below demonstrates how to debug a pipeline: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># Create a pipeline p1</span></div>
<div class="line">$ pipeline_create p1 videotestsrc ! autovideosink</div>
<div class="line"><span class="preprocessor"># Put it to playing</span></div>
<div class="line">$ pipeline_play p1</div>
<div class="line"><span class="preprocessor"># Enable debug</span></div>
<div class="line">$ debug_enable <span class="keyword">true</span></div>
<div class="line"><span class="preprocessor"># Set the debug level on 6</span></div>
<div class="line">$ debug_threshold *sink*:6</div>
<div class="line"><span class="preprocessor"># Enable the debug color</span></div>
<div class="line">$ debug_color <span class="keyword">true</span></div>
</div><!-- fragment --><h2><a class="anchor" id="amba_test_cases"></a>
2.4 Ambarella Test Cases</h2>
<p >This section demonstrates typical scenarios and cases to test Ambarella GStreamer plugins associated with GStreamer core / community plugins and third-party open source plugins (NNstreamer and others). <br  />
</p>
<p >All Lua files tested below were in the path <br  />
 <code>\ambarella\packages\amba_gst_plugins\additional\lua_scripts\</code> <br  />
</p>
<p >This section includes the following sub-sections:</p><ul>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#record_scenario">2.4.1 Record Scenarios</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#playback_scenario">2.4.2 Playback Scenario</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#machine_learning_scenario">2.4.3 Machine Learning Scenarios</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#setup_encoding_params">2.4.4 Set Up Encoding Parameters</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#mimic_dual_vin_scenarios">2.4.5 Mimic Dual Video Input Scenarios</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#jpeg_scenarios">2.4.6 JPEG Scenarios</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#rtsp_scenarios">2.4.7 RTSP Scenarios</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#debug_cases">2.4.8 Debug Cases</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#use_in_lychee">2.4.9 Use GStreamer in Lychee OS</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#known_issues">2.4.10 Known Issues</a></li>
<li>Section <a class="el" href="../../d5/d12/page_lib_gstreamer_doc.html#notice">2.4.11 Notice</a></li>
</ul>
<h3><a class="anchor" id="record_scenario"></a>
2.4.1 Record Scenarios</h3>
<p >Refer to the <code>amba_venccap</code> and <code>amba_vencdemux</code> elements; the following shows how to encode and record streams. <br  />
</p>
<h3><a class="anchor" id="example_record_2_streams"></a>
Example 1: Record One or Two Streams</h3>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --hdmi 1080p --resource-cfg /home/root/dualvin.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/cv28_dualvin.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/cv52_vin0_1_1080p_linear.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/cv72_vin0_1_1080p_linear.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
</div><!-- fragment --><p ><b>H.264 to MP4</b> <br  />
 Start two streams of H.264 encoding: <br  />
 </p><div class="fragment"><div class="line">$ test_encode -A -h 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -h 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e</div>
</div><!-- fragment --><p >Record one stream of video (H.264 to MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm dm.stream0 ! queue ! h264parse ! mp4mux ! filesink location=/tmp/h264.mp4</div>
</div><!-- fragment --><p >Record two streams of video (H.264 to MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=vencdemux vencdemux.stream0 ! queue ! h264parse ! mp4mux ! filesink location=/tmp/h264_0.mp4 \</div>
<div class="line">  vencdemux.stream1 ! queue ! h264parse ! mp4mux ! filesink location=/tmp/h264_1.mp4</div>
</div><!-- fragment --><p >Record one stream of video / audio (H.264 + opus -&gt; MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! queue ! opusenc ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux ! filesink location=/tmp/h264_opus.mp4 \</div>
<div class="line">  -e amba_venccap sync=<a class="code hl_define" href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h264parse ! mux.</div>
<div class="ttc" id="aik__data__type_8h_html_aa8cecfc5c5c054d2875c03e77b7be15d"><div class="ttname"><a href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a></div><div class="ttdeci">#define TRUE</div><div class="ttdef"><b>Definition:</b> ik_data_type.h:59</div></div>
</div><!-- fragment --><p >Record two streams of video / audio (H.264 + opus -&gt; MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! queue ! opusenc ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t t.src_0 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! filesink location=/tmp/h264_opus_0.mp4 \</div>
<div class="line">  -e amba_venccap sync=<a class="code hl_define" href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h264parse ! mux0. \</div>
<div class="line">  t.src_1 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux1 ! filesink location=/tmp/h264_opus_1.mp4 d.stream1 ! queue ! h264parse ! mux1.</div>
</div><!-- fragment --><p >Record one stream of video / audio (H.264 + advanced audio coding (AAC) -&gt; MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! audio/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,rate=48000 ! audioconvert ! avenc_aac ! queue ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux ! filesink location=/tmp/h264_aac.mp4 \</div>
<div class="line">  -e amba_venccap sync=<a class="code hl_define" href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h264parse ! mux.</div>
</div><!-- fragment --><p >Record two streams of video / audio (H.264 + AAC -&gt; MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! audio/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,rate=48000 ! audioconvert ! avenc_aac ! queue ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t t.src_0 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! filesink location=/tmp/h264_aac_0.mp4 \</div>
<div class="line">  -e amba_venccap sync=<a class="code hl_define" href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h264parse ! mux0. \</div>
<div class="line">  t.src_1 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux1 ! filesink location=/tmp/h264_aac_1.mp4 d.stream1 ! queue ! h264parse ! mux1.</div>
</div><!-- fragment --><p >Stop encoding: <br  />
 </p><div class="fragment"><div class="line">$ test_encode -A -s -B -s</div>
</div><!-- fragment --><p ><b>H.265 to MP4</b> <br  />
 Start H.265 encoding: <br  />
 </p><div class="fragment"><div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e</div>
</div><!-- fragment --><p >Record one stream of video (H.265 to MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm dm.stream0 ! queue ! h265parse ! mp4mux ! filesink location=/tmp/h265.mp4</div>
</div><!-- fragment --><p >Record one stream of video (H.265 -&gt; MP4 + HEIC): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux heic-capture-<span class="keywordtype">id</span>=0 filename-base=/tmp/amba%06d.heic <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm dm.stream0 \</div>
<div class="line">  ! queue ! h265parse ! mp4mux ! filesink location=/tmp/h265.mp4</div>
</div><!-- fragment --><p >Record two streams of video (H.265 to MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=vencdemux vencdemux.stream0 ! queue ! h265parse ! mp4mux ! filesink location=/tmp/h265_0.mp4 \</div>
<div class="line">  vencdemux.stream1 ! queue ! h265parse ! mp4mux ! filesink location=/tmp/h265_1.mp4</div>
</div><!-- fragment --><p >Record one stream of video / audio (H.265 + opus -&gt; MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! queue ! opusenc ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux ! filesink location=/tmp/h265_opus.mp4 \</div>
<div class="line">  -e amba_venccap sync=<a class="code hl_define" href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h265parse ! mux.</div>
</div><!-- fragment --><p >Record two streams of video / audio (H.265 + opus -&gt; MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! queue ! opusenc ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t t.src_0 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! filesink location=/tmp/h265_opus_0.mp4 \</div>
<div class="line">  -e amba_venccap sync=<a class="code hl_define" href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h265parse ! mux0. t.src_1 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux1 ! filesink location=/tmp/h265_opus_1.mp4 \</div>
<div class="line">  d.stream1 ! queue ! h265parse ! mux1.</div>
</div><!-- fragment --><p >Record one stream of video / audio (H.265 + AAC -&gt; MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! audio/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,rate=48000 ! audioconvert ! avenc_aac ! queue ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux ! filesink location=/tmp/h265_aac.mp4 \</div>
<div class="line">  -e amba_venccap sync=<a class="code hl_define" href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h265parse ! mux.</div>
</div><!-- fragment --><p >Record two streams of video / audio (H.265 + AAC -&gt; MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! audio/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,rate=48000 ! audioconvert ! avenc_aac ! queue ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t t.src_0 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! filesink location=/tmp/h265_aac_0.mp4 \</div>
<div class="line">  -e amba_venccap sync=<a class="code hl_define" href="../../df/d99/ik__data__type_8h.html#aa8cecfc5c5c054d2875c03e77b7be15d">TRUE</a> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h265parse ! mux0. t.src_1 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux1 ! filesink location=/tmp/h265_aac_1.mp4 \</div>
<div class="line">  d.stream1 ! queue ! h265parse ! mux1.</div>
</div><!-- fragment --><p >Stop encoding: <br  />
 </p><div class="fragment"><div class="line">$ test_encode -A -s -B -s</div>
</div><!-- fragment --><h3><a class="anchor" id="example_record_6_streams"></a>
Example 2: Record Six Streams</h3>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --hdmi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"><span class="preprocessor"># Start six streams of encoding</span></div>
<div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -h 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e -C -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -e -D -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -e -E -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e -S 5 -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -e</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"><span class="preprocessor"># Start six streams of encoding</span></div>
<div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -h 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e -C -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -e -D -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -e -E -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e -S 5 -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -e</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/cv52_four_vin_1080p_linear_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"><span class="preprocessor"># start six streams encoding</span></div>
<div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -h 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e -C -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -e -D -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -e -E -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e -S 5 -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -e</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/cv72_four_vin_1080p_linear_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"><span class="preprocessor"># start six streams encoding</span></div>
<div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -h 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e -C -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -e -D -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -e -E -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e -S 5 -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -e</div>
</div><!-- fragment --><p >Record six streams of video (H.264 / H.265):<br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux  ! filesink location=/tmp/h265_0.mp4 \</div>
<div class="line">  d.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_1.mp4 \</div>
<div class="line">  d.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_2.mp4 \</div>
<div class="line">  d.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_3.mp4 \</div>
<div class="line">  d.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_4.mp4 \</div>
<div class="line">  d.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_5.mp4</div>
</div><!-- fragment --><p >Record six streams of video / audio (H.264 / H.265 + opus):<br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! opusenc ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t t.src_0 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! filesink location=/tmp/h265_opus_0.mp4 \</div>
<div class="line">  -e amba_venccap sync=<span class="keyword">true</span> ! amba_vencdemux heic-capture-<span class="keywordtype">id</span>=0 filename-base=/tmp/amba%06d.heic <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux0. \</div>
<div class="line">  t.src_1 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux1 ! filesink location=/tmp/h264_opus_1.mp4 d.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux1. \</div>
<div class="line">  t.src_2 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux2 ! filesink location=/tmp/h265_opus_2.mp4 d.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux2. \</div>
<div class="line">  t.src_3 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux3 ! filesink location=/tmp/h264_opus_3.mp4 d.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux3. \</div>
<div class="line">  t.src_4 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux4 ! filesink location=/tmp/h265_opus_4.mp4 d.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux4. \</div>
<div class="line">  t.src_5 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux5 ! filesink location=/tmp/h264_opus_5.mp4 d.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux5.</div>
</div><!-- fragment --><p >Record six streams of video / audio (H.264 / H.265 + AAC): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e alsasrc ! audio/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,rate=48000 ! audioconvert ! avenc_aac ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t t.src_0 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! filesink location=/tmp/h265_aac_0.mp4 \</div>
<div class="line">  -e amba_venccap sync=<span class="keyword">true</span> ! amba_vencdemux heic-capture-<span class="keywordtype">id</span>=0 filename-base=/tmp/amba%06d.heic <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux0. \</div>
<div class="line">  t.src_1 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux1 ! filesink location=/tmp/h264_aac_1.mp4 d.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux1. \</div>
<div class="line">  t.src_2 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux2 ! filesink location=/tmp/h265_aac_2.mp4 d.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux2. \</div>
<div class="line">  t.src_3 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux3 ! filesink location=/tmp/h264_aac_3.mp4 d.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux3. \</div>
<div class="line">  t.src_4 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux4 ! filesink location=/tmp/h265_aac_4.mp4 d.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux4. \</div>
<div class="line">  t.src_5 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux5 ! filesink location=/tmp/h264_aac_5.mp4 d.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux5.</div>
</div><!-- fragment --><p >Stop six streams of encoding: <br  />
 </p><div class="fragment"><div class="line">$ test_encode -A -s -B -s -C -s -D -s -E -s -S 5 -s</div>
</div><!-- fragment --><h3><a class="anchor" id="playback_scenario"></a>
2.4.2 Playback Scenario</h3>
<p >This section demonstrates how to decode and play back streams. <br  />
</p>
<p >Refer to the <code>amba_hwvdec</code> element; the following shows how to play back streams with the Ambarella hardware decoder. <br  />
 Note that the <code>amba_hwvdec</code> element supports decoding streams that are encoded from Amba venc. <br  />
</p>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_vout --hdmi 1080p</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28, `mipi_dsi` in the `amba_hwvdec` element is not supported; skip this section.</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_vout --mipi_dsi 1080p</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Since there&#39;s some issue of DSP V6 existed in amba-gst-plugin,</span></div>
<div class="line"><span class="preprocessor"># `amba_hwvdec` is not supported on CV52/CV72/CV3 now; skip this section.</span></div>
</div><!-- fragment --><p >Play back H.264 + opus (MP4): <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for audio</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/h264_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! opusdec ! audioconvert ! autoaudiosink</div>
<div class="line"><span class="preprocessor"># for video</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/h264_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! h264parse ! amba_hwvdec ! amba_vsink</div>
<div class="line"><span class="preprocessor"># for video + audio</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/h264_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! opusdec ! audioconvert ! autoaudiosink \</div>
<div class="line">  demuxer. ! queue ! h264parse ! amba_hwvdec ! amba_vsink async=<span class="keyword">false</span></div>
</div><!-- fragment --><p >Play back H.265 + opus (MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/h265_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! opusdec ! audioconvert ! autoaudiosink \</div>
<div class="line">  demuxer. ! queue ! h265parse ! amba_hwvdec ! amba_vsink async=<span class="keyword">false</span></div>
</div><!-- fragment --><p >Play back H.264 + AAC (MP4): <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for audio</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/h264_aac.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! avdec_aac ! audioconvert ! autoaudiosink</div>
<div class="line"><span class="preprocessor"># for video</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/h264_aac.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! h264parse ! amba_hwvdec ! amba_vsink</div>
<div class="line"><span class="preprocessor"># for video + audio</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/h264_aac.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! avdec_aac ! audioconvert ! autoaudiosink \</div>
<div class="line">  demuxer. ! queue ! h264parse ! amba_hwvdec ! amba_vsink async=<span class="keyword">false</span></div>
</div><!-- fragment --><p >Play back H.265 + AAC (MP4): <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/h265_aac.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! avdec_aac ! audioconvert ! autoaudiosink \</div>
<div class="line">  demuxer. ! queue ! h265parse ! amba_hwvdec ! amba_vsink async=<span class="keyword">false</span></div>
</div><!-- fragment --><p >Note that the digital signal processor (DSP) must return to the idle mode before decoding each time. <br  />
 </p><div class="fragment"><div class="line">$ test_encode --idle --nopreview</div>
</div><!-- fragment --><h3><a class="anchor" id="machine_learning_scenario"></a>
2.4.3 Machine Learning Scenarios</h3>
<p >This section demonstrates how to run neural networks with Ambarella CVflow. <br  />
</p>
<h3><a class="anchor" id="example_ml_in_amba_plugin"></a>
Example 3: Machine Learning in the Amba Gst Plugin</h3>
<p >With the <code>mlinference</code> element in the Amba Gst Plugins, the following shows how to test NN models. <br  />
</p>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --hdmi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line"><span class="preprocessor"># Please configure canvas encode dummy latency first, and enc_dummy_latency should be &gt; 0.</span></div>
<div class="line">$ test_encode --resource-cfg cv52_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line"><span class="preprocessor"># Please configure canvas encode dummy latency first, and enc_dummy_latency should be &gt; 0.</span></div>
<div class="line">$ test_encode --resource-cfg cv72_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line">$ modprobe cavalry</div>
<div class="line">$ cavalry_load -f /lib/firmware/cavalry.bin -r</div>
<div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e -C -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -e -D -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -e -E -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e -S 5 -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -e</div>
<div class="line">$ rtsp_server&amp;</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Since there&#39;s some issue of DSP V6 existed in amba-gst-plugin,</span></div>
<div class="line"><span class="preprocessor"># `amba_venc_overlay` is not supported on CV52/CV72/CV3 now.</span></div>
</div><!-- fragment --><p ><b>amba_camsrc to Machine Learning </b> <br  />
</p>
<p >Run a tested YOLOv5 model with post-processing, and then draw boxes on the overlay. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 \</div>
<div class="line">  label = /tmp/nn/in/coco_class_names.txt model = /tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  type = yolov5s conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 ! queue ! amba_venc_overlay stream_id = 0 alpha = 0 \</div>
<div class="line">  font = /tmp/arial.ttf clut_start = 22 clut_end = 70 color_number = 300 score_lmt = 0.25</div>
<div class="ttc" id="agroup__cavalry__opt__layers-api-details_html_gaaebc4f5976b0ca899e54fa28ee499eb2"><div class="ttname"><a href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a></div><div class="ttdeci">AMBA_API int nms(OUT half *out, IN half *in, IN int in_count, IN float iou_thresh, IN int out_lim)</div></div>
</div><!-- fragment --><p >Run a tested YOLOv5 model with an region of interest (ROI). <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 \</div>
<div class="line">  label = /tmp/nn/in/coco_class_names.txt model= /tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  type = yolov5s conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 roi=640.360.1280.720 ! queue ! amba_venc_overlay stream_id = 0 alpha = 0 \</div>
<div class="line">  font = /tmp/arial.ttf clut_start = 22 clut_end = 70 color_number = 300 score_lmt = 0.25 roi=640.360.1280.720</div>
</div><!-- fragment --><p >Run a tested tiny YOLOv3 model with post-processing, and then draw boxes on the overlay. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = data out_name = layer115-conv out_name = layer125-conv \</div>
<div class="line">  label = /tmp/nn/in/live_voc_labels.txt model = /tmp/nn/model/yolov3_fastest_xl_cavalry.bin \</div>
<div class="line">  type = yolov3x conf_threshold = 0.8 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.3 top_k = 100 ! queue ! amba_venc_overlay stream_id = 0 alpha = 0 \</div>
<div class="line">  font = /tmp/arial.ttf clut_start = 22 clut_end = 70 color_number = 300 score_lmt = 0.8</div>
</div><!-- fragment --><p >If not performing post-processing, remove the property <code>type=xxx</code>. <br  />
</p>
<p >Run a tested efficientnet model without post-processing. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = input out_name = 672 \</div>
<div class="line">  label = /tmp/efficientnet/coco_ids.yaml model = /tmp/efficientnet/efficientnet_cavalry.bin \</div>
<div class="line">  conf_threshold = 0.2 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.5 top_k = 100 ! queue ! fakesink</div>
</div><!-- fragment --><p >Run a tested <code>tf_efficientdet_lite0</code> model without post-processing. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = image_arrays out_name = Sigmoid out_name = ArgMax out_name = stack_2 \</div>
<div class="line">  label = /tmp/nn/in/coco_ids.yaml model = /tmp/nn/model/tf_efficientdet_lite0_cavalry.bin \</div>
<div class="line">  conf_threshold = 0.2 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.5 top_k = 100 ! queue ! fakesink</div>
</div><!-- fragment --><p >Run a tested <code>movenet_lightning</code> model without post-processing. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = serving_default_input out_name = StatefulPartitionedCall \</div>
<div class="line">  label = /tmp/movenet_lightning/coco_ids.yaml model = /tmp/movenet_lightning/tf_movenet_lightning_cavalry.bin \</div>
<div class="line">  conf_threshold = 0.2 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.5 top_k = 100 ! queue ! fakesink</div>
</div><!-- fragment --><p >Run a tested <code>movenet_thunder</code> model without post-processing. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = serving_default_input out_name = StatefulPartitionedCall \</div>
<div class="line">  label = /tmp/movenet_thunder/coco_ids.yaml model = /tmp/movenet_thunder/tf_movenet_thunder_cavalry.bin \</div>
<div class="line">  conf_threshold = 0.2 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.5 top_k = 100 ! queue ! fakesink</div>
</div><!-- fragment --><p >Run a tested <code>fast_depth</code> model without post-processing. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = input.1 out_name = 424 \</div>
<div class="line">  model = /tmp/fast_depth/onnx_fast_depth_cavalry.bin ! queue ! fakesink</div>
</div><!-- fragment --><p ><b>Software Decoding to Machine Learning </b> <br  />
</p>
<p >Decode H.264 (MP4) to YOLOv5 with post-processing. Add <code>--gst-debug-level 3</code> to print the detected bounding box information: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8_h264.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! h264parse ! avdec_h264 ! \</div>
<div class="line">  videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 \</div>
<div class="line">  label = /tmp/nn/in/coco_class_names.txt model = /tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  type = yolov5s conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 ! queue ! fakesink</div>
</div><!-- fragment --><p >Decode H.265 (MP4) to YOLOv5 with post-processing. Add <code>--gst-debug-level 3</code> to print the detected bounding box information: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8_h265.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! h265parse ! avdec_h265 ! \</div>
<div class="line">  videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 \</div>
<div class="line">  label = /tmp/nn/in/coco_class_names.txt model = /tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  type = yolov5s conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 ! queue ! fakesink</div>
</div><!-- fragment --><p >Decode H.264 (ES) to YOLOv5 with post-processing. Add <code>--gst-debug-level 3</code> to print the detected bounding box information: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! \</div>
<div class="line">  queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 label = /tmp/nn/in/coco_class_names.txt \</div>
<div class="line">  model = /tmp/nn/model/onnx_yolov5s_cavalry.bin conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 type = yolov5s ! queue ! fakesink</div>
</div><!-- fragment --><p >Decode H.265 (ES) to YOLOv5 with post-processing. Add <code>--gst-debug-level 3</code> to print the detected bounding box information: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h265 ! h265parse ! avdec_h265 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! \</div>
<div class="line">  queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 label = /tmp/nn/in/coco_class_names.txt \</div>
<div class="line">  model = /tmp/nn/model/onnx_yolov5s_cavalry.bin conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 type = yolov5s ! queue ! fakesink</div>
</div><!-- fragment --><p >Decode motion JPEG to YOLOv5 with post-processing. Add <code>--gst-debug-level 3</code> to print the detected bounding box information: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># h264 (es) to motion jpeg</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert \</div>
<div class="line">  ! avenc_mjpeg ! qtmux ! filesink location=/tmp/mojpeg.mp4</div>
<div class="line"><span class="preprocessor"># motion jpeg to yolov5</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/mojpeg.mp4 ! qtdemux ! queue ! avdec_mjpeg ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP \</div>
<div class="line">  ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 label = /tmp/nn/in/coco_class_names.txt \</div>
<div class="line">  model = /tmp/nn/model/onnx_yolov5s_cavalry.bin type = yolov5s conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 ! fakesink</div>
</div><!-- fragment --><h3><a class="anchor" id="example_ml_in_nnstreamer"></a>
Example 4: Machine Learning in NNStreamer</h3>
<p >With the <code>amba_cvflow</code> framework in the subplugin of the modified <code>tensor_filter</code> element, the following demonstrates how to run NN models with NNStreamer plugins. <br  />
</p>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --hdmi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv52_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv72_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line">$ modprobe cavalry</div>
<div class="line">$ cavalry_load -f /lib/firmware/cavalry.bin -r</div>
<div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e -C -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -e -D -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -e -E -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e -S 5 -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -e</div>
</div><!-- fragment --><p ><b>amba_camsrc to Machine Learning </b> <br  />
</p>
<p >Run a tested YOLOv5 model with post-processing in <code>tensor_filter</code>. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! tensor_converter ! \</div>
<div class="line">  tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997,label:/tmp/nn/in/coco_class_names.txt,f:0.25,<a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a>:0.45,top_k:100,type:yolov5s,in_data_fmt:0.0.8.0 ! tensor_sink</div>
</div><!-- fragment --><p >Run a tested YOLOv5 model with post-processing in <code>tensor_decoder</code>. <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># The output data format of NN model generated by CNNGEN was usually FP16(1.1.0.4) or FP32(1.2.0.7)</span></div>
<div class="line"><span class="preprocessor"># If want to get FP32 data for postprocess, just setup `nn_out_f32:1` in tensor_filter.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># yolov5s, postprocess in bounding_boxes, output with drawed video &quot;RGBA&quot;</span>.</div>
<div class="line">$ gst-launch-1.0 -e amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! tensor_converter ! \</div>
<div class="line">  tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0,nn_out_f32:1 ! tensor_decoder mode=bounding_boxes option1=amba_yolov5 \</div>
<div class="line">  option2=/tmp/nn/in/coco_class_names.txt option3=f:0.25,<a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a>:0.45,top_k:100 option4=1280:720 option5=416:416 ! videoconvert ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># yolov5s, postprocess in bounding_boxes_ori, output with post-process results in 3 tensors(0: bboxes, 1: drive area mask(yolop), 2: lane line mask(yolop)).</span></div>
<div class="line">$ gst-launch-1.0 -e amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0,nn_out_f32:1 ! tensor_decoder mode=bounding_boxes_ori \</div>
<div class="line">  option1=amba_yolov5 option2=/tmp/nn/in/coco_class_names.txt option3=f:0.25,<a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a>:0.45,top_k:100 option5=416:416 ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># yolop model for cv72, postprocess in bounding_boxes</span></div>
<div class="line">$ gst-launch-1.0 -v -e amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/cv7x/cv72_cavalry3.0.3_onnx_yolop.bin \</div>
<div class="line">  custom=in_name:images,out_name:1159+1515+drive_area_seg+lane_line_seg+1871,in_data_fmt:0.0.0.0,nn_out_f32:1 ! \</div>
<div class="line">  tensor_decoder mode=bounding_boxes option1=amba_yolop option2=/tmp/nn/in/coco_class_names.txt \</div>
<div class="line">  option3=f:0.25,<a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a>:0.45,top_k:100 option4=1280:720 option5=640:640 ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># yolop model for cv72, postprocess in bounding_boxes_ori</span></div>
<div class="line">$ gst-launch-1.0 -v -e amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/cv7x/cv72_cavalry3.0.3_onnx_yolop.bin \</div>
<div class="line">  custom=in_name:images,out_name:1159+1515+drive_area_seg+lane_line_seg+1871,in_data_fmt:0.0.0.0,nn_out_f32:1 ! \</div>
<div class="line">  tensor_decoder mode=bounding_boxes_ori option1=amba_yolop option2=/tmp/nn/in/coco_class_names.txt \</div>
<div class="line">  option3=f:0.25,<a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a>:0.45,top_k:100 option4=640:640 option5=640:640 ! fakesink</div>
</div><!-- fragment --><p >Run a tested YOLOv5 model without post-processing. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! tensor_converter ! \</div>
<div class="line">  tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 ! tensor_sink</div>
</div><!-- fragment --><p >Run a tested YOLOv5 model with an ROI. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! tensor_converter ! \</div>
<div class="line">  tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997,roi:640.360.1280.720,in_data_fmt:0.0.8.0 ! tensor_sink</div>
</div><!-- fragment --><p ><b>Software Decoding to Machine Learning </b> <br  />
</p>
<p >Decode H.264 (MP4) to YOLOv5 without post-processing: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8_h264.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. \</div>
<div class="line">  ! queue ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! \</div>
<div class="line">  tensor_converter ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 ! queue ! fakesink</div>
</div><!-- fragment --><p >Decode H.265 (MP4) to YOLOv5 without post-processing: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8_h265.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! \</div>
<div class="line">  h265parse ! avdec_h265 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! \</div>
<div class="line">  tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 \</div>
<div class="line">  ! queue ! fakesink</div>
</div><!-- fragment --><p >Decode H.264 (ES) to YOLOv5 without post-processing: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP \</div>
<div class="line">  ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 ! queue ! fakesink</div>
</div><!-- fragment --><p >Decode H.265 (ES) to YOLOv5 without post-processing: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h265 ! h265parse ! avdec_h265 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue \</div>
<div class="line">  ! tensor_converter ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 ! queue ! fakesink</div>
</div><!-- fragment --><p ><b>Machine Learning with Multiple Inputs </b> <br  />
</p>
<p >Run a tested <code>tf_mobilenetv2</code> model without post-processing. <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># $ test_nnctrl -b /tmp/multi_inputs_model/cv22_cavalry2.2.8.4_tf_mobilenetv2_nv12.bin --dummy -e</span></div>
<div class="line"><span class="preprocessor"># Input: 0 [x] dim: (1, 2, 112, 112), pitch: 128, dram_fmt: 0, bitvector: 0, data_fmt: (0, 0, 0, 0), loop_cnt: 1, size: 28672, phys: 0x6083e000, virt: 0x7fbb36b000</span></div>
<div class="line"><span class="preprocessor"># Input: 1 [x.1] dim: (1, 1, 224, 224), pitch: 224, dram_fmt: 0, bitvector: 0, data_fmt: (0, 0, 0, 0), loop_cnt: 1, size: 50176, phys: 0x60845000, virt: 0x7fbb372000</span></div>
<div class="line"><span class="preprocessor"># Output: 0 [dense_1/BiasAdd] dim: (1, 1000, 1, 1), pitch: 32, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 32000, phys: 0x6087ec00, virt: 0x7fbb3abc00</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># input tensors: dims=112:112:2:1+224:224:1:1, types=uint8+uint8(0.0.0.0+0.0.0.0)</span></div>
<div class="line">$ gst-launch-1.0 -v filesrc location=/tmp/src_112x112x2_u8.bin blocksize=25088 ! application/octet-stream ! \</div>
<div class="line">  tensor_converter input-dim=112:112:2:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#adde6aaee8457bee49c2a92621fe22b79">uint8</a> ! queue ! mux.sink_0 \</div>
<div class="line">  filesrc location=/tmp/src_224x224x1_u8.bin blocksize=50176 ! application/octet-stream ! tensor_converter input-dim=224:224:1:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#adde6aaee8457bee49c2a92621fe22b79">uint8</a> ! queue ! mux.sink_1 \</div>
<div class="line">  tensor_mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux sync_mode=nosync ! queue ! tensor_filter framework=amba_cvflow model=/tmp/multi_inputs_model/cv22_cavalry2.2.8.4_tf_mobilenetv2_nv12.bin \</div>
<div class="line">  custom=in_name:x+x.1,out_name:dense_1/BiasAdd,in_data_fmt:0.0.0.0+0.0.0.0 ! queue ! filesink location=/tmp/nns_tf_mobilenet_v2_out.bin</div>
<div class="line">  tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  custom=in_name:images,out_name:1037+1017+997 ! tensor_sink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># input tensors: dims=2880:1856:2:1+2880:1856:1:1, types=uint8+uint8(0.0.0.0+0.0.0.0)</span></div>
<div class="line">$ gst-launch-1.0 -v filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! \</div>
<div class="line">  queue ! tensor_converter ! tensor_split <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=split tensorseg=2880:1856:2:1,2880:1856:1:1 \</div>
<div class="line">  split.src_0 ! queue ! mux.sink_0 split.src_1 ! queue ! mux.sink_1 tensor_mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux sync_mode=nosync ! queue ! \</div>
<div class="line">  tensor_filter framework=amba_cvflow model=/tmp/multi_inputs_model/cv22_cavalry2.2.8.4_tf_mobilenetv2_nv12.bin \</div>
<div class="line">  custom=in_name:x+x.1,out_name:dense_1/BiasAdd,in_data_fmt:0.0.0.0+0.0.0.0 ! queue ! filesink location=/tmp/nns_tf_mobilenet_v2_out.bin</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># input tensors: dims=112:112:2:1+224:224:1:1, types=float32+uint8(1.2.0.7+0.0.0.0)</span></div>
<div class="line">$ gst-launch-1.0 -v filesrc location=/tmp/src_112x112x2_f32.bin blocksize=100352 ! application/octet-stream ! \</div>
<div class="line">  tensor_converter input-dim=112:112:2:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#aacdc525d6f7bddb3ae95d5c311bd06a1">float32</a> ! queue ! mux.sink_0 \</div>
<div class="line">  filesrc location=/tmp/src_224x224x1_u8.bin blocksize=50176 ! application/octet-stream ! tensor_converter input-dim=224:224:1:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#adde6aaee8457bee49c2a92621fe22b79">uint8</a> ! queue ! mux.sink_1 \</div>
<div class="line">  tensor_mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux sync_mode=nosync ! queue ! tensor_filter framework=amba_cvflow model=/tmp/multi_inputs_model/cv22_cavalry2.2.8.4_tf_mobilenetv2_nv12.bin \</div>
<div class="line">  custom=in_name:x+x.1,out_name:dense_1/BiasAdd,in_data_fmt:1.2.0.7+0.0.0.0 ! queue ! filesink location=/tmp/nns_tf_mobilenet_v2_out.bin * </div>
<div class="ttc" id="aik__data__type_8h_html_aacdc525d6f7bddb3ae95d5c311bd06a1"><div class="ttname"><a href="../../df/d99/ik__data__type_8h.html#aacdc525d6f7bddb3ae95d5c311bd06a1">float32</a></div><div class="ttdeci">float float32</div><div class="ttdef"><b>Definition:</b> ik_data_type.h:44</div></div>
<div class="ttc" id="aik__data__type_8h_html_adde6aaee8457bee49c2a92621fe22b79"><div class="ttname"><a href="../../df/d99/ik__data__type_8h.html#adde6aaee8457bee49c2a92621fe22b79">uint8</a></div><div class="ttdeci">unsigned char uint8</div><div class="ttdef"><b>Definition:</b> ik_data_type.h:33</div></div>
</div><!-- fragment --><p >Run a tested <code>onnx_robust_video_matting</code> model without post-processing. <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># $ test_nnctrl -b /tmp/multi_inputs_model/cv22_cavalry2.2.8.4_onnx_robust_video_matting.bin --dummy -e</span></div>
<div class="line"><span class="preprocessor"># Input: 0 [r1i] dim: (1, 16, 135, 240), pitch: 960, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 2073600, phys: 0x607b9000, virt: 0x7f89790000</span></div>
<div class="line"><span class="preprocessor"># Input: 1 [src] dim: (1, 3, 1080, 1920), pitch: 1920, dram_fmt: 0, bitvector: 0, data_fmt: (0, 0, 0, 0), loop_cnt: 1, size: 6220800, phys: 0x609b3400, virt: 0x7f8998a400</span></div>
<div class="line"><span class="preprocessor"># Input: 2 [r4i] dim: (1, 64, 17, 30), pitch: 128, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 139264, phys: 0x60fa2000, virt: 0x7f89f79000</span></div>
<div class="line"><span class="preprocessor"># Input: 3 [r3i] dim: (1, 40, 34, 60), pitch: 256, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 348160, phys: 0x60fc4000, virt: 0x7f89f9b000</span></div>
<div class="line"><span class="preprocessor"># Input: 4 [r2i] dim: (1, 20, 68, 120), pitch: 480, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 652800, phys: 0x61019000, virt: 0x7f89ff0000</span></div>
<div class="line"><span class="preprocessor"># Output: 0 [pha] dim: (1, 1, 1080, 1920), pitch: 7680, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 8294400, phys: 0x6275e800, virt: 0x7f8b735800</span></div>
<div class="line"><span class="preprocessor"># Output: 1 [r1o] dim: (1, 16, 135, 240), pitch: 960, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 2073600, phys: 0x62f47800, virt: 0x7f8bf1e800</span></div>
<div class="line"><span class="preprocessor"># Output: 2 [r2o] dim: (1, 20, 68, 120), pitch: 480, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 652800, phys: 0x6208ad80, virt: 0x7f8b061d80</span></div>
<div class="line"><span class="preprocessor"># Output: 3 [r3o] dim: (1, 40, 34, 60), pitch: 256, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 348160, phys: 0x6212a380, virt: 0x7f8b101380</span></div>
<div class="line"><span class="preprocessor"># Output: 4 [r4o] dim: (1, 64, 17, 30), pitch: 128, dram_fmt: 0, bitvector: 0, data_fmt: (1, 2, 0, 7), loop_cnt: 1, size: 139264, phys: 0x62187f80, virt: 0x7f8b15ef80</span></div>
<div class="line"> </div>
<div class="line">$ gst-launch-1.0 -v tensor_mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux sync-mode=nosync ! tensor_filter framework=amba_cvflow model=/tmp/multi_inputs_model/cv22_cavalry2.2.8.4_onnx_robust_video_matting.bin \</div>
<div class="line">  custom=in_name:r1i+src+r4i+r3i+r2i,out_name:pha+r1o+r2o+r3o+r4o,in_data_fmt:1.2.0.7+0.0.0.0+1.2.0.7+1.2.0.7+1.2.0.7 ! \</div>
<div class="line">  queue ! tensor_demux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demux demux.src_0 ! queue ! filesink location=/tmp/dst_1920x1080x1_f32.bin \</div>
<div class="line">  demux.src_1 ! queue ! filesink location=/tmp/dst_240x135x16_f32.bin \</div>
<div class="line">  demux.src_2 ! queue ! filesink location=/tmp/dst_120x68x20_f32.bin \</div>
<div class="line">  demux.src_3 ! queue ! filesink location=/tmp/dst_60x34x40_f32.bin \</div>
<div class="line">  demux.src_4 ! queue ! filesink location=/tmp/dst_30x17x64_f32.bin \</div>
<div class="line">  filesrc location=/tmp/src_240x135x16_f32.bin blocksize=2073600 ! application/octet-stream ! tensor_converter input-dim=240:135:16:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#aacdc525d6f7bddb3ae95d5c311bd06a1">float32</a> ! queue ! mux.sink_0 \</div>
<div class="line">  filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! queue ! mux.sink_1 \</div>
<div class="line">  filesrc location=/tmp/src_30x17x64_f32.bin blocksize=130560 ! application/octet-stream ! tensor_converter input-dim=30:17:64:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#aacdc525d6f7bddb3ae95d5c311bd06a1">float32</a> ! queue ! mux.sink_2 \</div>
<div class="line">  filesrc location=/tmp/src_60x34x40_f32.bin blocksize=326400 ! application/octet-stream ! tensor_converter input-dim=60:34:40:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#aacdc525d6f7bddb3ae95d5c311bd06a1">float32</a> ! queue ! mux.sink_3 \</div>
<div class="line">  filesrc location=/tmp/src_120x68x20_f32.bin blocksize=652800 ! application/octet-stream ! tensor_converter input-dim=120:68:20:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#aacdc525d6f7bddb3ae95d5c311bd06a1">float32</a> ! queue ! mux.sink_4</div>
</div><!-- fragment --><p ><b>Machine Learning with RNN </b> <br  />
</p>
<p >Running an RNN converted by the Amba CNNGEN tool is similar to running a typical NN. <br  />
</p>
<p >Run a tested long short-term memory (LSTM) model without post-processing. <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># $ test_nnctrl -b /tmp/lstm_model/warpctc_one_shot_cavalry.bin --dummy -e</span></div>
<div class="line"><span class="preprocessor"># Total neural network num: 1</span></div>
<div class="line"><span class="preprocessor"># Input: 0 [input] dim: (1, 3, 30, 80), pitch: 96, dram_fmt: 0, bitvector: 0, data_fmt: (0, 0, 8, 0), loop_cnt: 1, size: 8640, phys: 0x6042e000, virt: 0x7fb975d000</span></div>
<div class="line"><span class="preprocessor"># Input: 1 [indicator] dim: (1, 1, 1, 1), pitch: 32, dram_fmt: 0, bitvector: 0, data_fmt: (0, 0, 0, 0), loop_cnt: 80, size: 2560, phys: 0x604301c0, virt: 0x7fb975f1c0</span></div>
<div class="line"><span class="preprocessor"># Output: 0 [fc1] dim: (1, 80, 1, 11), pitch: 32, dram_fmt: 0, bitvector: 0, data_fmt: (1, 0, 1, 0), loop_cnt: 1, size: 2560, phys: 0x604592c0, virt: 0x7fb97882c0</span></div>
<div class="line"> </div>
<div class="line">$ gst-launch-1.0 -v filesrc location=/tmp/lstm_model/00000-50337.bin blocksize=7200 ! application/octet-stream ! \</div>
<div class="line">  tensor_converter input-dim=80:30:3:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#adde6aaee8457bee49c2a92621fe22b79">uint8</a> ! queue ! mux.sink_0 \</div>
<div class="line">  filesrc location=/tmp/lstm_model/indicator.bin blocksize=1 ! application/octet-stream ! tensor_converter input- dim=1:1:1:1 input-type=<a class="code hl_typedef" href="../../df/d99/ik__data__type_8h.html#adde6aaee8457bee49c2a92621fe22b79">uint8</a> ! queue ! mux.sink_1 \</div>
<div class="line">  tensor_mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux sync_mode=nosync ! queue ! tensor_filter framework=amba_cvflow model=/tmp/lstm_model/warpctc_one_shot_cavalry.bin \</div>
<div class="line">  custom=in_name:input+indicator,out_name:fc1,in_data_fmt:0.0.8.0+0.0.0.0 ! queue ! filesink location=/tmp/nns_lstm_out.bin</div>
</div><!-- fragment --><dl class="section note"><dt>Note</dt><dd>The number of input tensors in <code>tensor_filter</code> must be equal to the number of NN input feature maps.</dd></dl>
<h3><a class="anchor" id="setup_encoding_params"></a>
2.4.4 Set Up Encoding Parameters</h3>
<p >This section demonstrates how to set up encoding parameters with the <code>amba_venccap</code> element or the <code>test_encode</code> application. <br  />
</p>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/dualvin_12_streams.lua --enc-mode 0</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_12_streams.lua --enc-mode 0</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv52_vin0_1_12_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv72_vin0_1_12_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
</div><!-- fragment --><p ><b>Set parameters in the setup stage</b> <br  />
</p>
<p >Set the encoding parameters via the <code>amba_venccap</code> element: <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -v -e amba_venccap enc=stream_id:0,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,frame_factor:1/15,idr_interval:1,M:1,N:30,start:1,\</div>
<div class="line">  stream_id:1,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,bitrate:1000000,N:150,start:1,\</div>
<div class="line">  stream_id:2,stop:1,canvas-id:1,type:h265,stream-output:0.0.1280.720,bc:vbr,vbr_bitrate:10000~1000000,N:30,start:1,\</div>
<div class="line">  stream_id:3,stop:1,canvas-id:1,type:h264,stream-output:0.0.1280.720,bitrate:800000,N:30,start:1,\</div>
<div class="line">  stream_id:4,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,bitrate:150000,N:150,start:1,\</div>
<div class="line">  stream_id:5,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,bitrate:10000,N:30,frame_factor:1/15,start:1 \</div>
<div class="line">  ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm dm.stream0 ! queue ! h265parse ! mp4mux ! filesink location=/tmp/h265.mp4</div>
</div><!-- fragment --><p >Set encoding parameters via the <code>test_encode</code> application first, then change the parameters using the <code>amba_venccap</code> element. <br  />
 </p><div class="fragment"><div class="line">$ test_encode  -S 0 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -H 1080p --frame-factor 1/15 --idr 1 -M 1 -N 30 -e \</div>
<div class="line">  -S 1 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -H 1080p --bitrate 1000000 -N 150 -e \</div>
<div class="line">  -S 2 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -H 720p --bc vbr --vbr-bitrate 10000~1000000 -N 30 -e \</div>
<div class="line">  -S 3 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -h 720p --bitrate 800000 -N 30 -e \</div>
<div class="line">  -S 4 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -H 360p --bitrate 150000 -N 150 -e \</div>
<div class="line">  -S 5 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -H 360p --bitrate 10000 -N 30 --frame-factor 1/15 -e \</div>
<div class="line">  -S 6 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -H 2560x1440 --frame-factor 1/30 -e \</div>
<div class="line">  -S 7 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -H 2560x1440 --bitrate 4000000 -N 300 -e \</div>
<div class="line">  -S 8 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -H 720p --bitrate 1000000 -N 48 --frame-factor 4/5 -e \</div>
<div class="line">  -S 9 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -h 720p --bitrate 800000 -N 40 --frame-factor 2/3 -e \</div>
<div class="line">  -S 10 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -H 360p --bitrate 200000 -N 150 --frame-factor 1/2 -e \</div>
<div class="line">  -S 11 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -H 360p --bitrate 10000 -N 30 --frame-factor 1/30 -e</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Change encoding parameters via amba_venccap.</span></div>
<div class="line">$ gst-launch-1.0 -v -e amba_venccap enc=stream_id:0,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,frame_factor:1/15,idr_interval:1,M:1,N:30,start:1,\</div>
<div class="line">  stream_id:1,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,bitrate:1000000,N:150,start:1,\</div>
<div class="line">  stream_id:2,stop:1,canvas-id:1,type:h265,stream-output:0.0.1280.720,bc:vbr,vbr_bitrate:10000~1000000,N:30,start:1,\</div>
<div class="line">  stream_id:3,stop:1,canvas-id:1,type:h264,stream-output:0.0.1280.720,bitrate:800000,N:30,start:1,\</div>
<div class="line">  stream_id:4,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,bitrate:150000,N:150,start:1,\</div>
<div class="line">  stream_id:5,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,bitrate:10000,N:30,frame_factor:1/15,start:1 \</div>
<div class="line">  ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm dm.stream0 ! queue ! h265parse ! mp4mux ! filesink location=/tmp/h265.mp4</div>
</div><!-- fragment --><p ><b>Update Encoding Parameters at Runtime</b> <br  />
</p>
<p >The following was set up in the GStreamer Daemon. </p><div class="fragment"><div class="line"><span class="preprocessor"># run gstd in local shell</span></div>
<div class="line">$ gstd</div>
<div class="line"><span class="preprocessor"># run client application in an external remote shell</span></div>
<div class="line">$ gst-client</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Request commands in gst-client below</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Create pipeline</span></div>
<div class="line">$ pipeline_create p1 amba_venccap <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=venc enc=stream_id:0,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,start:1 \</div>
<div class="line">  ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm dm.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265.mp4</div>
<div class="line"><span class="preprocessor"># play pipeline</span></div>
<div class="line">$ pipeline_play p1</div>
<div class="line"><span class="preprocessor"># change bitrate</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,bitrate:1000000</div>
<div class="line"><span class="preprocessor"># change absolute bitrate</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,stop:1,abs-br:1,bitrate:1000000,start:1</div>
<div class="line"><span class="preprocessor"># change vbr range</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,vbr_bitrate:10000~1000000</div>
<div class="line"><span class="preprocessor"># change bitrate control: cbr, vbr, cbr-quality, vbr-quality</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,bc:cbr,bitrate:1000000</div>
<div class="line"><span class="preprocessor"># force IDR</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,force_idr:1</div>
<div class="line"><span class="preprocessor"># stop encoding</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,stop:1</div>
<div class="line"><span class="preprocessor"># change resolution of canvas buffer and stream</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,stop:1,chan-id:0,srcbuf-id:2,srcbuf-input:320.180.1280.720,srcbuf-output:0.0.640.480,stream-output:0.0.640.480,sar:1/1,start:1</div>
<div class="line"><span class="preprocessor"># not ready: demux issue. change source buffer, frame_factor, idr_interval, M, N, codec type, stream-output and start encoding</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,canvas-id:0,frame_factor:1/15,idr_interval:1,M:1,N:30,type:h265,stream-output:0.0.1280.720,start:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># send eos</span></div>
<div class="line">$ event_eos p1</div>
<div class="line"><span class="preprocessor"># stop pipeline</span></div>
<div class="line">$ pipeline_stop p1</div>
<div class="line"><span class="preprocessor"># destroy pipeline</span></div>
<div class="line"><span class="preprocessor"># pipeline_delete p1</span></div>
</div><!-- fragment --><h3><a class="anchor" id="mimic_dual_vin_scenarios"></a>
2.4.5 Mimic Dual Video Input Scenarios</h3>
<p >This section mimics dual-VIN source scenarios. <br  />
</p>
<h3><a class="anchor" id="example_mimic_dualvin_with_12s"></a>
Example 5: Mimic Dual-VIN with 12 Streams</h3>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line"><span class="preprocessor"># for cv25, add  --check-disable-all 1</span></div>
<div class="line">$ test_encode --resource-cfg /home/root/dualvin_12_streams.lua --enc-mode 0 --enc-dummy-latency 2</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_12_streams.lua --enc-mode 0 --enc-dummy-latency 2</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296  <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv52_vin0_1_12_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296  <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv72_vin0_1_12_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line">$ modprobe cavalry</div>
<div class="line">$ cavalry_load -f /lib/firmware/cavalry.bin -r</div>
<div class="line">$ rtsp_server&amp;</div>
</div><!-- fragment --><p >Run GstD: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># run gstd in local shell</span></div>
<div class="line">$ gstd</div>
<div class="line"><span class="preprocessor"># run client application in an external remote shell</span></div>
<div class="line">$ gst-client</div>
</div><!-- fragment --><p >Run 12 streams in GstD: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># request commands in gst-client below</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># create pipeline</span></div>
<div class="line"><span class="preprocessor"># For too many streams, it&#39;s needed to setup `alloc_mem=1` in amba_venccap element,</span></div>
<div class="line"><span class="preprocessor"># `max-size-time=0 max-size-bytes=0 max-size-buffers=0` in queue.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># a. creat a pipeline with setting encoding params in amba_venccap element.</span></div>
<div class="line">$ pipeline_create p1 amba_venccap <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=venc alloc_mem=1 enc=\</div>
<div class="line">  stream_id:0,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,abs-br:1,bitrate:1000000,N:150,start:1,\</div>
<div class="line">  stream_id:1,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,trigger_frame:1,N:1,start:1,\</div>
<div class="line">  stream_id:2,stop:1,canvas-id:1,type:h265,stream-output:0.0.1280.720,abs-br:1,bitrate:750000,N:30,start:1,\</div>
<div class="line">  stream_id:3,stop:1,canvas-id:1,type:h264,stream-output:0.0.1280.720,abs-br:1,bitrate:800000,N:30,start:1,\</div>
<div class="line">  stream_id:4,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:150000,N:150,start:1,\</div>
<div class="line">  stream_id:5,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:10000,N:60,frame_factor:1/30,start:1,\</div>
<div class="line">  stream_id:6,stop:1,canvas-id:3,type:h265,stream-output:0.0.2560.1440,abs-br:1,bitrate:4000000,N:300,start:1,\</div>
<div class="line">  stream_id:7,stop:1,canvas-id:3,type:h265,stream-output:0.0.2560.1440,trigger_frame:1,N:1,start:1,\</div>
<div class="line">  stream_id:8,stop:1,canvas-id:4,type:h265,stream-output:0.0.1280.720,abs-br:1,bitrate:1000000,N:48,frame_factor:4/5,start:1,\</div>
<div class="line">  stream_id:9,stop:1,canvas-id:4,type:h264,stream-output:0.0.1280.720,abs-br:1,bitrate:800000,N:40,frame_factor:2/3,start:1,\</div>
<div class="line">  stream_id:10,stop:1,canvas-id:5,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:200000,N:150,frame_factor:1/2,start:1,\</div>
<div class="line">  stream_id:11,stop:1,canvas-id:5,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:10000,N:60,frame_factor:1/60,start:1 \</div>
<div class="line">  ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm filename-base=/tmp/heic_0_%06d.heic \</div>
<div class="line">  dm.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_0.mp4 \</div>
<div class="line">  dm.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_2.mp4 \</div>
<div class="line">  dm.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_0_3.mp4 \</div>
<div class="line">  dm.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_4.mp4 \</div>
<div class="line">  dm.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_5.mp4 \</div>
<div class="line">  dm.stream6 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_0.mp4 \</div>
<div class="line">  dm.stream8 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_2.mp4 \</div>
<div class="line">  dm.stream9 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_1_3.mp4 \</div>
<div class="line">  dm.stream10 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_4.mp4 \</div>
<div class="line">  dm.stream11 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_5.mp4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># b. create a pipleine, with `test_encode` app to setup encoding params.</span></div>
<div class="line">$ test_encode -S 0 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -H 1080p --abs-br 1 --bitrate 1000000 -N 150 -e \</div>
<div class="line">  -S 1 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -H 1080p --trigger-frame 1 -N 1 -e \</div>
<div class="line">  -S 2 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -H 720p --abs-br 1 --bitrate 750000 -N 30 -e \</div>
<div class="line">  -S 3 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -h 720p --abs-br 1 --bitrate 800000 -N 30 -e \</div>
<div class="line">  -S 4 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -H 360p --abs-br 1 --bitrate 150000 -N 150 -e \</div>
<div class="line">  -S 5 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -H 360p --abs-br 1 --bitrate 10000 -N 60 --frame-factor 1/30 -e \</div>
<div class="line">  -S 6 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -H 2560x1440 --abs-br 1 --bitrate 4000000 -N 300 -e \</div>
<div class="line">  -S 7 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -H 2560x1440 --trigger-frame 1 -N 1 -e \</div>
<div class="line">  -S 8 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -H 720p --abs-br 1 --bitrate 1000000 -N 48 --frame-factor 4/5 -e \</div>
<div class="line">  -S 9 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -h 720p --abs-br 1 --bitrate 800000 -N 40 --frame-factor 2/3 -e \</div>
<div class="line">  -S 10 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -H 360p --abs-br 1 --bitrate 200000 -N 150 --frame-factor 1/2 -e \</div>
<div class="line">  -S 11 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -H 360p --abs-br 1 --bitrate 10000 -N 60 --frame-factor 1/60 -e</div>
<div class="line">$ pipeline_create p1 amba_venccap <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=venc alloc_mem=1 ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm heic-capture-<span class="keywordtype">id</span>=1,7 filename-base=/tmp/heic_0_%06d.heic \</div>
<div class="line">  dm.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_0.mp4 \</div>
<div class="line">  dm.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_2.mp4 \</div>
<div class="line">  dm.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_0_3.mp4 \</div>
<div class="line">  dm.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_4.mp4 \</div>
<div class="line">  dm.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_5.mp4 \</div>
<div class="line">  dm.stream6 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_0.mp4 \</div>
<div class="line">  dm.stream8 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_2.mp4 \</div>
<div class="line">  dm.stream9 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_1_3.mp4 \</div>
<div class="line">  dm.stream10 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_4.mp4 \</div>
<div class="line">  dm.stream11 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_5.mp4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># c. create a pipeline using frame factor 1/15 for trigger frame.</span></div>
<div class="line">$ pipeline_create p1 amba_venccap <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=venc alloc_mem=1 enc=\</div>
<div class="line">  stream_id:0,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,abs-br:1,bitrate:1000000,N:150,start:1,\</div>
<div class="line">  stream_id:1,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,frame_factor:1/30,N:1,start:1,\</div>
<div class="line">  stream_id:2,stop:1,canvas-id:1,type:h265,stream-output:0.0.1280.720,abs-br:1,bitrate:750000,N:30,start:1,\</div>
<div class="line">  stream_id:3,stop:1,canvas-id:1,type:h264,stream-output:0.0.1280.720,abs-br:1,bitrate:800000,N:30,start:1,\</div>
<div class="line">  stream_id:4,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:150000,N:150,start:1,\</div>
<div class="line">  stream_id:5,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:10000,N:60,frame_factor:1/30,start:1,\</div>
<div class="line">  stream_id:6,stop:1,canvas-id:3,type:h265,stream-output:0.0.2560.1440,abs-br:1,bitrate:4000000,N:300,start:1,\</div>
<div class="line">  stream_id:7,stop:1,canvas-id:3,type:h265,stream-output:0.0.2560.1440,frame_factor:1/30,N:1,start:1,\</div>
<div class="line">  stream_id:8,stop:1,canvas-id:4,type:h265,stream-output:0.0.1280.720,abs-br:1,bitrate:1000000,N:48,frame_factor:4/5,start:1,\</div>
<div class="line">  stream_id:9,stop:1,canvas-id:4,type:h264,stream-output:0.0.1280.720,abs-br:1,bitrate:800000,N:40,frame_factor:2/3,start:1,\</div>
<div class="line">  stream_id:10,stop:1,canvas-id:5,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:200000,N:150,frame_factor:1/2,start:1,\</div>
<div class="line">  stream_id:11,stop:1,canvas-id:5,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:10000,N:60,frame_factor:1/60,start:1 \</div>
<div class="line">  ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm \</div>
<div class="line">  dm.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_0.mp4 \</div>
<div class="line">  dm.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! amba_heicfilesink filename-base=/tmp/heic_0_%06d.heic \</div>
<div class="line">  dm.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_2.mp4 \</div>
<div class="line">  dm.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_0_3.mp4 \</div>
<div class="line">  dm.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_4.mp4 \</div>
<div class="line">  dm.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_5.mp4 \</div>
<div class="line">  dm.stream6 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_0.mp4 \</div>
<div class="line">  dm.stream7 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! amba_heicfilesink filename-base=/tmp/heic_1_%06d.heic \</div>
<div class="line">  dm.stream8 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_2.mp4 \</div>
<div class="line">  dm.stream9 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_1_3.mp4 \</div>
<div class="line">  dm.stream10 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_4.mp4 \</div>
<div class="line">  dm.stream11 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_5.mp4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># play pipeline</span></div>
<div class="line">$ pipeline_play p1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># stop image capture streams (stream 1 and stream 7)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:1,stop:1</div>
<div class="line">$ element_set p1 venc enc stream_id:7,stop:1</div>
<div class="line"><span class="preprocessor"># start image capture stream (stream 1 and stream 7)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:1,start:1</div>
<div class="line">$ element_set p1 venc enc stream_id:7,start:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># stop event trigger stream (stream 2 and stream 8)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:2,stop:1</div>
<div class="line">$ element_set p1 venc enc stream_id:8,stop:1</div>
<div class="line"><span class="preprocessor"># start event trigger stream (stream 2 and stream 8)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:2,start:1</div>
<div class="line">$ element_set p1 venc enc stream_id:8,start:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># stop webRTC stream (stream 3 and stream 9)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:3,stop:1</div>
<div class="line">$ element_set p1 venc enc stream_id:9,stop:1</div>
<div class="line"><span class="preprocessor"># start webRTC trigger stream (stream 3 and stream 9)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:3,start:1</div>
<div class="line">$ element_set p1 venc enc stream_id:9,start:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># stop hyperlapse stream (stream 5 and stream 11)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:5,stop:1</div>
<div class="line">$ element_set p1 venc enc stream_id:11,stop:1</div>
<div class="line"><span class="preprocessor"># start hyperlapse trigger stream (stream 3 and stream 9)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:5,start:1</div>
<div class="line">$ element_set p1 venc enc stream_id:11,start:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># capture heic in stream id X</span></div>
<div class="line">$ element_set p1 dm heic-capture-<span class="keywordtype">id</span> 1,7</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># frame trigger image capture (stream 1 and stream 7)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:1,trigger_frame_num:1</div>
<div class="line">$ element_set p1 venc enc stream_id:7,trigger_frame_num:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># bitrate control (stream X)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:X,stop:1,abs-br:1,bitrate:1000000,start:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># VIN fps (vin 1)</span></div>
<div class="line">$ element_set p1 venc enc vsrc:1,vin_frame_rate:15</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># force IDR (stream 1 and stream 7)</span></div>
<div class="line">$ element_set p1 venc enc stream_id:1,force_idr:1</div>
<div class="line">$ element_set p1 venc enc stream_id:7,force_idr:1</div>
<div class="line"> </div>
<div class="line">change webRCT stream resolution (stream 3 and stream 9)</div>
<div class="line">$ element_set p1 venc enc stream_id:3,stop:1,stream-output:0.0.640.360,start:1</div>
<div class="line">$ element_set p1 venc enc stream_id:9,stop:1,stream-output:0.0.640.360,start:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># send eos for pipeline</span></div>
<div class="line">$ event_eos p1</div>
<div class="line"><span class="preprocessor"># stop pipeline</span></div>
<div class="line">$ pipeline_stop p1</div>
<div class="line"><span class="preprocessor"># destory pipeline</span></div>
<div class="line">$ pipeline_delete p1</div>
</div><!-- fragment --><p >Mimic running several NNs (yolov5, efficient net, tf_efficientdet_lite0): <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># request commands in gst-client below</span></div>
<div class="line"> </div>
<div class="line">$ pipeline_create p2 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 \</div>
<div class="line">  label = /tmp/nn/in/coco_class_names.txt model = /tmp/nn/model/onnx_yolov5s_cavalry.bin type = yolov5s conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 \</div>
<div class="line">  ! queue ! amba_venc_overlay stream_id = 0 alpha = 0 font = /tmp/arial.ttf clut_start = 22 clut_end = 70 color_number = 300 score_lmt = 0.25</div>
<div class="line"> </div>
<div class="line">$ pipeline_create p3 amba_camsrc buf-<span class="keywordtype">id</span> = 4 ! queue ! mlinference in_name = input out_name = 672  \</div>
<div class="line">  model = /tmp/nn/model/efficientnet_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line">$ pipeline_create p4 amba_camsrc buf-<span class="keywordtype">id</span> = 4 ! queue ! mlinference in_name = image_arrays out_name = Sigmoid out_name = ArgMax out_name = stack_2 \</div>
<div class="line">  model = /tmp/nn/model/tf_efficientdet_lite0_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># play pipeline</span></div>
<div class="line">$ pipeline_play p2</div>
<div class="line">$ pipeline_play p3</div>
<div class="line">$ pipeline_play p4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># stop pipeline</span></div>
<div class="line">$ pipeline_stop p2</div>
<div class="line">$ pipeline_stop p3</div>
<div class="line">$ pipeline_stop p4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># delete pipeline</span></div>
<div class="line">$ pipeline_delete p2</div>
<div class="line">$ pipeline_delete p3</div>
<div class="line">$ pipeline_delete p4</div>
</div><!-- fragment --><h3><a class="anchor" id="example_mimic_dualvin_with_8s"></a>
Example 6: Mimic Dual-VIN with Eight Streams</h3>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/dualvin_8_streams.lua --enc-mode 0</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_8_streams.lua --enc-mode 0</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296  <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv52_vin0_1_8_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296  <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv72_vin0_1_8_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line">$ modprobe cavalry</div>
<div class="line">$ cavalry_load -f /lib/firmware/cavalry.bin -r</div>
<div class="line">$ rtsp_server&amp;</div>
</div><!-- fragment --><p >Run GstD: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># run gstd in local shell</span></div>
<div class="line">$ gstd</div>
<div class="line"><span class="preprocessor"># run client application in an external remote shell</span></div>
<div class="line">$ gst-client</div>
</div><!-- fragment --><p >Mimic an eight-stream recording scenario: </p><div class="fragment"><div class="line"><span class="preprocessor"># create a pipeline</span></div>
<div class="line">$ pipeline_create p1 amba_venccap <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=venc alloc_mem=1 enc=\</div>
<div class="line">  stream_id:0,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,abs-br:1,bitrate:1000000,idr_interval:1,M:1,N:150,start:1,\</div>
<div class="line">  stream_id:1,stop:1,canvas-id:1,type:h265,stream-output:0.0.1280.720,abs-br:1,bitrate:750000,N:30,start:1,\</div>
<div class="line">  stream_id:2,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:150000,N:150,start:1,\</div>
<div class="line">  stream_id:3,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:10000,N:60,frame_factor:1/30,start:1,\</div>
<div class="line">  stream_id:4,stop:1,canvas-id:3,type:h265,stream-output:0.0.2560.1440,abs-br:1,bitrate:4000000,N:300,start:1,\</div>
<div class="line">  stream_id:5,stop:1,canvas-id:4,type:h265,stream-output:0.0.1280.720,abs-br:1,bitrate:1000000,N:48,frame_factor:4/5,start:1,\</div>
<div class="line">  stream_id:6,stop:1,canvas-id:5,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:20000,N:150,frame_factor:1/2,start:1,\</div>
<div class="line">  stream_id:7,stop:1,canvas-id:5,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:10000,N:60,frame_factor:1/60,start:1 \</div>
<div class="line">  ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm dm.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_0.mp4 \</div>
<div class="line">  dm.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_1.mp4 \</div>
<div class="line">  dm.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_2.mp4 \</div>
<div class="line">  dm.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_3.mp4 \</div>
<div class="line">  dm.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_0.mp4 \</div>
<div class="line">  dm.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_1.mp4 \</div>
<div class="line">  dm.stream6 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_2.mp4 \</div>
<div class="line">  dm.stream7 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_3.mp4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># play pipeline</span></div>
<div class="line">$ pipeline_play p1</div>
<div class="line"><span class="preprocessor"># change framerate (frame factor, idr interval, M, N), bitrate, force IDR</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,frame_factor:1/2,idr_interval:1,M:1,N:30</div>
<div class="line">$ element_set p1 venc enc stream_id:0,stop:1,abs-br:1,bitrate:1000000,start:1</div>
<div class="line">$ element_set p1 venc enc stream_id:0,force_idr:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># stop pipeline</span></div>
<div class="line">$ event_eos p1</div>
<div class="line">$ pipeline_stop p1</div>
<div class="line"><span class="preprocessor"># delete pipeline</span></div>
<div class="line">$ pipeline_delete p1</div>
</div><!-- fragment --><div class="fragment"><div class="line"><span class="preprocessor"># create a pipeline</span></div>
<div class="line">$ pipeline_create p1 amba_venccap <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=venc alloc_mem=1 enc=\</div>
<div class="line">  stream_id:0,stop:1,canvas-id:0,type:h265,stream-output:0.0.1920.1080,abs-br:1,bitrate:1000000,idr_interval:1,M:1,N:150,start:1,\</div>
<div class="line">  stream_id:1,stop:1,canvas-id:1,type:h264,stream-output:0.0.1280.720,abs-br:1,bitrate:800000,N:30,start:1,\</div>
<div class="line">  stream_id:2,stop:1,canvas-id:2,type:h264,stream-output:0.0.640.360,abs-br:1,bitrate:400000,N:30,start:1,\</div>
<div class="line">  stream_id:3,stop:1,canvas-id:2,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:10000,N:60,frame_factor:1/30,start:1,\</div>
<div class="line">  stream_id:4,stop:1,canvas-id:3,type:h265,stream-output:0.0.2560.1440,abs-br:1,bitrate:4000000,N:300,start:1,\</div>
<div class="line">  stream_id:5,stop:1,canvas-id:4,type:h264,stream-output:0.0.1280.720,abs-br:1,bitrate:800000,N:40,frame_factor:2/3,start:1,\</div>
<div class="line">  stream_id:6,stop:1,canvas-id:5,type:h264,stream-output:0.0.640.360,abs-br:1,bitrate:400000,N:40,frame_factor:2/3,start:1,\</div>
<div class="line">  stream_id:7,stop:1,canvas-id:5,type:h265,stream-output:0.0.640.360,abs-br:1,bitrate:10000,N:60,frame_factor:1/60,start:1 \</div>
<div class="line">  ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=dm dm.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_0.mp4 \</div>
<div class="line">  dm.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_0_1.mp4 \</div>
<div class="line">  dm.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_0_2.mp4 \</div>
<div class="line">  dm.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_0_3.mp4 \</div>
<div class="line">  dm.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_0.mp4 \</div>
<div class="line">  dm.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_1_1.mp4 \</div>
<div class="line">  dm.stream6 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux ! filesink location=/tmp/h264_1_2.mp4 \</div>
<div class="line">  dm.stream7 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux ! filesink location=/tmp/h265_1_3.mp4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># play pipeline</span></div>
<div class="line">$ pipeline_play p1</div>
<div class="line"><span class="preprocessor"># change bitrate, force IDR</span></div>
<div class="line">$ element_set p1 venc enc stream_id:0,stop:1,abs-br:1,bitrate:1000000,start:1</div>
<div class="line">$ element_set p1 venc enc stream_id:0,force_idr:1</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># stop pipeline</span></div>
<div class="line">$ event_eos p1</div>
<div class="line">$ pipeline_stop p1</div>
<div class="line"><span class="preprocessor"># delete pipeline</span></div>
<div class="line">$ pipeline_delete p1</div>
</div><!-- fragment --><p >Mimic running several NNs (YOLOv5, efficient net, efficientdet_lite0): <br  />
 </p><div class="fragment"><div class="line">$ pipeline_create p2 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 \</div>
<div class="line">  label = /tmp/nn/in/coco_class_names.txt model = /tmp/nn/model/onnx_yolov5s_cavalry.bin type = yolov5s conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 \</div>
<div class="line">  ! queue ! amba_venc_overlay stream_id = 0 alpha = 0 font = /tmp/arial.ttf clut_start = 22 clut_end = 70 color_number = 300 score_lmt = 0.25</div>
<div class="line"> </div>
<div class="line">$ pipeline_create p3 amba_camsrc buf-<span class="keywordtype">id</span> = 4 ! queue ! mlinference in_name = input out_name = 672  \</div>
<div class="line">  model = /tmp/nn/model/efficientnet_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line">$ pipeline_create p4 amba_camsrc buf-<span class="keywordtype">id</span> = 4 ! queue ! mlinference in_name = image_arrays out_name = Sigmoid out_name = ArgMax out_name = stack_2 \</div>
<div class="line">  model = /tmp/nn/model/tf_efficientdet_lite0_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># play pipeline</span></div>
<div class="line">$ pipeline_play p2</div>
<div class="line">$ pipeline_play p3</div>
<div class="line">$ pipeline_play p4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># stop pipeline</span></div>
<div class="line">$ pipeline_stop p2</div>
<div class="line">$ pipeline_stop p3</div>
<div class="line">$ pipeline_stop p4</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># delete pipeline</span></div>
<div class="line">$ pipeline_delete p2</div>
<div class="line">$ pipeline_delete p3</div>
<div class="line">$ pipeline_delete p4</div>
</div><!-- fragment --><h3><a class="anchor" id="jpeg_scenarios"></a>
2.4.6 JPEG Scenarios</h3>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/dualvin.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/cv28_dualvin.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/cv52_vin0_1_1080p_linear.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg /home/root/cv72_vin0_1_1080p_linear.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line">$ test_encode -A -h 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e</div>
</div><!-- fragment --><p >YUV to JPEG: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># gst-launch-1.0 amba_camsrc buf-id = 0 ! jpegenc ! filesink location=/tmp/test.jpg</span></div>
</div><!-- fragment --><h3><a class="anchor" id="rtsp_scenarios"></a>
2.4.7 RTSP Scenarios</h3>
<p >GStreamer includes some RTSP / RTP /... protocols related elements. This section demonstrates some cases about how to use and link these elements. Currently, there are still some issues existed in <code>amba_venccap</code> when trying to work with these servers / clients. Ambarella video encoding element would be improved in the future. <br  />
</p>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --hdmi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv52_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv72_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line">$ modprobe cavalry</div>
<div class="line">$ cavalry_load -f /lib/firmware/cavalry.bin -r</div>
<div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -h 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e -C -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -e -D -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -e -E -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e -S 5 -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -e</div>
</div><!-- fragment --><p ><b>RTSP</b> <br  />
 There is an example tool named <code>test-launch</code> in Gstreamer-rtsp-server plugin to help create a RTSP server and test stream. The tool can be generated in the SDK path below: <br  />
 <code>/ambarella/out/yocto_out/cvxx/tmp/work/cortexaxx-poky-linux/gstreamer1.0-rtsp-server/x.xx.x-r0/build/examples/</code> <br  />
 To enable the RTSP server to send multiple streams, add a new tool named <code>test-launch-v2</code> in the unit test of amba-gst-plugin. The <code>test-launch-v2</code> was modified from <code>test-lauch</code> and can be backward-compatible. <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># VLC network URL below: rtsp:</span><span class="comment">//10.0.0.2:8554/test</span></div>
<div class="line"><span class="preprocessor"># h264</span></div>
<div class="line">$ ./test-launch <span class="stringliteral">&quot;( amba_venccap ! amba_vencdemux name=d d.stream1 ! queue ! h264parse ! rtph264pay name=pay0 pt=96 )&quot;</span></div>
<div class="line">$ test-launch-v2 <span class="stringliteral">&quot;( amba_venccap ! amba_vencdemux name=d d.stream1 ! queue ! h264parse ! rtph264pay name=pay0 pt=96 )&quot;</span></div>
<div class="line"><span class="preprocessor"># h265</span></div>
<div class="line">$ ./test-launch <span class="stringliteral">&quot;( amba_venccap ! amba_vencdemux name=d d.stream0 ! queue ! h265parse ! rtph265pay name=pay0 pt=96 )&quot;</span></div>
<div class="line">$ test-launch-v2 <span class="stringliteral">&quot;( amba_venccap ! amba_vencdemux name=d d.stream0 ! queue ! h265parse ! rtph265pay name=pay0 pt=96 )&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># 6 streams, just give a flow of creating a port with 6 mounts by test-launch-v2.</span></div>
<div class="line"><span class="preprocessor"># Notice that `amba_venccap` cannot be called by different pipelines at the same time which would cause issues now.</span></div>
<div class="line"><span class="preprocessor"># VLC network URL below: rtsp:</span><span class="comment">//10.0.0.2:8554/test0, rtsp://10.0.0.2:8554/test1, rtsp://10.0.0.2:8554/test2......</span></div>
<div class="line"><span class="preprocessor"># &quot;-c&quot;</span> was used for setup the counts of video streams or pipelines, default 1.</div>
<div class="line">$ test-launch-v2 -c 6 <span class="stringliteral">&quot;( amba_venccap stream-id= 0 ! amba_vencdemux name=d d.stream0 ! queue ! h265parse ! rtph265pay name=pay0 pt=96 )&quot;</span> \</div>
<div class="line">  <span class="stringliteral">&quot;( amba_venccap stream-id= 1 ! amba_vencdemux name=d d.stream1 ! queue ! h264parse ! rtph264pay name=pay0 pt=96 )&quot;</span> \</div>
<div class="line">  <span class="stringliteral">&quot;( amba_venccap stream-id= 2 ! amba_vencdemux name=d d.stream2 ! queue ! h265parse ! rtph265pay name=pay0 pt=96 )&quot;</span> \</div>
<div class="line">  <span class="stringliteral">&quot;( amba_venccap stream-id= 3 ! amba_vencdemux name=d d.stream3 ! queue ! h264parse ! rtph264pay name=pay0 pt=96 )&quot;</span> \</div>
<div class="line">  <span class="stringliteral">&quot;( amba_venccap stream-id= 4 ! amba_vencdemux name=d d.stream4 ! queue ! h265parse ! rtph265pay name=pay0 pt=96 )&quot;</span> \</div>
<div class="line">  <span class="stringliteral">&quot;( amba_venccap stream-id= 5 ! amba_vencdemux name=d d.stream5 ! queue ! h264parse ! rtph264pay name=pay0 pt=96 )&quot;</span></div>
</div><!-- fragment --><p ><b>UDP</b> <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># h265</span></div>
<div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h265parse ! rtph265pay ! queue ! udpsink host=127.0.0.1 port=8554</div>
<div class="line">$ gst-launch-1.0 -e udpsrc port=8554 ! application/x-rtp,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H265 ! queue ! rtph265depay ! queue ! h265parse ! qtmux ! filesink location=/tmp/h265_0.mp4</div>
<div class="line"><span class="preprocessor"># h264</span></div>
<div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream1 ! queue ! h264parse ! rtph264pay ! queue ! udpsink host=127.0.0.1 port=8555</div>
<div class="line">$ gst-launch-1.0 -e udpsrc port=8555 ! application/x-rtp,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H264 ! queue ! rtph264depay ! queue ! h264parse ! qtmux ! filesink location=/tmp/h264_1.mp4</div>
<div class="line"><span class="preprocessor"># 6 streams</span></div>
<div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h265parse ! rtph265pay ! queue ! udpsink host=<span class="stringliteral">&quot;127.0.0.1&quot;</span> port=8554 \</div>
<div class="line">  d.stream1 ! queue ! h264parse ! rtph264pay ! queue ! udpsink host=<span class="stringliteral">&quot;127.0.0.1&quot;</span> port=8555 \</div>
<div class="line">  d.stream2 ! queue ! h265parse ! rtph265pay ! queue ! udpsink host=<span class="stringliteral">&quot;127.0.0.1&quot;</span> port=8556 \</div>
<div class="line">  d.stream3 ! queue ! h264parse ! rtph264pay ! queue ! udpsink host=<span class="stringliteral">&quot;127.0.0.1&quot;</span> port=8557 \</div>
<div class="line">  d.stream4 ! queue ! h265parse ! rtph265pay ! queue ! udpsink host=<span class="stringliteral">&quot;127.0.0.1&quot;</span> port=8558 \</div>
<div class="line">  d.stream5 ! queue ! h264parse ! rtph264pay ! queue ! udpsink host=<span class="stringliteral">&quot;127.0.0.1&quot;</span> port=8559</div>
<div class="line">$ gst-launch-1.0 -e udpsrc port=8554 ! application/x-rtp,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H265 ! queue ! rtph265depay ! queue ! h265parse ! qtmux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux ! filesink location=/tmp/h265_0.mp4 \</div>
<div class="line">  -e udpsrc port=8555 ! application/x-rtp,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H264 ! queue ! rtph264depay ! queue ! h264parse ! qtmux ! filesink location=/tmp/h264_1.mp4 \</div>
<div class="line">  -e udpsrc port=8556 ! application/x-rtp,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H265 ! queue ! rtph265depay ! queue ! h265parse ! qtmux ! filesink location=/tmp/h265_2.mp4 \</div>
<div class="line">  -e udpsrc port=8557 ! application/x-rtp,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H264 ! queue ! rtph264depay ! queue ! h264parse ! qtmux ! filesink location=/tmp/h264_3.mp4 \</div>
<div class="line">  -e udpsrc port=8558 ! application/x-rtp,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H265 ! queue ! rtph265depay ! queue ! h265parse ! qtmux ! filesink location=/tmp/h265_4.mp4 \</div>
<div class="line">  -e udpsrc port=8559 ! application/x-rtp,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H264 ! queue ! rtph264depay ! queue ! h264parse ! qtmux ! filesink location=/tmp/h264_5.mp4</div>
</div><!-- fragment --><p ><b>TCP</b> <br  />
 Report issues in <code>amba_venccap</code>: Buffer has no PTS. Just give a test flow now. <br  />
 </p><div class="fragment"><div class="line">$ gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue ! h265parse ! rtph265pay ! rtpstreampay ! queue ! tcpserversink host=127.0.0.1 port=8554</div>
<div class="line">$ gst-launch-1.0 -e tcpclientsrc host=127.0.0.1 port=8554 <span class="keywordflow">do</span>-timestamp=<span class="keyword">true</span> ! application/x-rtp-stream,encoding-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=H265 ! queue ! rtpstreamdepay ! rtph265depay ! queue ! h265parse ! qtmux ! filesink location=/tmp/h265_0.mp4</div>
</div><!-- fragment --><h3><a class="anchor" id="debug_cases"></a>
2.4.8 Debug Cases</h3>
<p ><b>Validate Machine Learning </b> <br  />
</p>
<p >The following demonstrates how to validate the outputs from NNs in file mode. <br  />
</p>
<p >Prepare on the board: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --hdmi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296  <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv52_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296  <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv72_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line">$ modprobe cavalry</div>
<div class="line">$ cavalry_load -f /lib/firmware/cavalry.bin -r</div>
</div><!-- fragment --><p >For the <code>ml_inference</code> element without post-processing, dump outputs of NN: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># yolov5</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue \</div>
<div class="line">  ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 model = /tmp/nn/model/onnx_yolov5s_cavalry.bin dump=/tmp/dump.bin ! queue ! fakesink</div>
<div class="line"><span class="preprocessor"># tiny yolov3</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue \</div>
<div class="line">  ! mlinference in_name = data out_name = layer115-conv out_name = layer125-conv model = /tmp/nn/model/yolov3_fastest_xl_cavalry.bin dump=/tmp/dump.bin ! queue ! fakesink</div>
<div class="line"><span class="preprocessor"># efficientnet</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue \</div>
<div class="line">  ! mlinference in_name = input out_name = 672 model = /tmp/nn/model/efficientnet_cavalry.bin dump=/tmp/dump.bin ! queue ! fakesink</div>
<div class="line"><span class="preprocessor"># tf_efficientdet_lite0</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue \</div>
<div class="line">  ! mlinference in_name = image_arrays out_name = Sigmoid out_name = ArgMax out_name = stack_2 model = /tmp/nn/model/tf_efficientdet_lite0_cavalry.bin dump=/tmp/dump.bin ! queue ! fakesink</div>
<div class="line"><span class="preprocessor"># movenet_lightning</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue \</div>
<div class="line">  ! mlinference in_name = serving_default_input out_name = StatefulPartitionedCall model = /tmp/movenet_lightning/tf_movenet_lightning_cavalry.bin dump=/tmp/dump.bin ! queue ! fakesink</div>
<div class="line"><span class="preprocessor"># movenet_thunder</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue \</div>
<div class="line">  ! mlinference in_name = serving_default_input out_name = StatefulPartitionedCall model = /tmp/movenet_thunder/tf_movenet_thunder_cavalry.bin dump=/tmp/dump.bin ! queue ! fakesink</div>
<div class="line"><span class="preprocessor"># fast_depth</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue \</div>
<div class="line">  ! mlinference in_name = input.1 out_name = 424 model = /tmp/fast_depth/onnx_fast_depth_cavalry.bin dump=/tmp/dump.bin ! queue ! fakesink</div>
</div><!-- fragment --><p >For the <code>amba_cvflow</code> framework in <code>tensor_filter</code>, dump outputs of NN: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># yolov5</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow \</div>
<div class="line">  model=/tmp/nn/model/onnx_yolov5s_cavalry.bin custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 ! queue ! filesink location=/tmp/result.bin</div>
<div class="line"><span class="preprocessor"># tiny yolov3</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow \</div>
<div class="line">  model=/tmp/nn/model/yolov3_fastest_xl_cavalry.bin custom=in_name:data,out_name:layer115-conv+layer125-conv,in_data_fmt:0.0.8.0 ! queue ! filesink location=/tmp/result.bin</div>
<div class="line"><span class="preprocessor"># efficientnet</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow \</div>
<div class="line">  model = /tmp/nn/model/efficientnet_cavalry.bin custom=in_name:input,out_name:672,in_data_fmt:0.0.0.0 ! queue ! filesink location=/tmp/result.bin</div>
<div class="line"><span class="preprocessor"># tf_efficientdet_lite0</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow \</div>
<div class="line">  model = /tmp/nn/model/tf_efficientdet_lite0_cavalry.bin custom=in_name:image_arrays,out_name:Sigmoid+ArgMax+stack_2,in_data_fmt:0.0.0.0 ! queue ! filesink location=/tmp/result.bin</div>
<div class="line"><span class="preprocessor"># movenet_lightning</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow \</div>
<div class="line">  model = /tmp/movenet_lightning/tf_movenet_lightning_cavalry.bin custom=in_name:serving_default_input,out_name:StatefulPartitionedCall,in_data_fmt:0.0.0.0 ! queue ! filesink location=/tmp/result.bin</div>
<div class="line"><span class="preprocessor"># movenet_thunder</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow \</div>
<div class="line">  model = /tmp/movenet_thunder/tf_movenet_thunder_cavalry.bin custom=in_name:serving_default_input,out_name:StatefulPartitionedCall,in_data_fmt:0.0.0.0 ! queue ! filesink location=/tmp/result.bin</div>
<div class="line"><span class="preprocessor"># fast_depth</span></div>
<div class="line">$ gst-launch-1.0 filesrc location=/tmp/IMX490_road_8.h264 ! h264parse ! avdec_h264 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow \</div>
<div class="line">  model = /tmp/fast_depth/onnx_fast_depth_cavalry.bin custom=in_name:input.1,out_name:424,in_data_fmt:0.0.0.0 ! queue ! filesink location=/tmp/result.bin</div>
</div><!-- fragment --><p >Using the same inputs and the same models, compare the outputs of NNs when running each time. <br  />
</p>
<p ><b>Validate Performance and Memory Leaks </b> <br  />
</p>
<p >This section demonstrates how to test the performance of pipelines and validate memory leaks. <br  />
 For performance, set up <code>GST_DEBUG</code> as shown below at the beginning of <code>gst-launch-1.0</code>, and then obtain <code>avg frame diff</code> for the average time per frame in the log. <br  />
 </p><div class="fragment"><div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 ...</div>
<div class="line"> </div>
<div class="line">For example, in the log:</div>
<div class="line">...</div>
<div class="line">avg frame diff 0:00:00.329551990</div>
<div class="line">...</div>
</div><!-- fragment --><p >For memory leaks, use the commandline below in another console to get <code>DIRTY</code> for CPU occupancy. <br  />
 </p><div class="fragment"><div class="line">$ top -m</div>
<div class="line">...</div>
<div class="line"> PID^^^VSZ^VSZRW   RSS (SHR) DIRTY (SHR) STACK COMMAND</div>
<div class="line">...</div>
</div><!-- fragment --><p> Valgrind tool also can be used to make a checkout on memory leak. <br  />
 </p><div class="fragment"><div class="line">$ make menuconfig</div>
<div class="line">  Main menu                                                                                                                          ©¦</div>
<div class="line">    -&gt; meta                                                                                                                          ©¦</div>
<div class="line">      -&gt; recipes-devtools</div>
<div class="line">        [*] valgrind (meta/recipes-devtools/valgrind)</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># check xxx on board</span></div>
<div class="line">$ valgrind --leak-check=full xxx</div>
</div><!-- fragment --><p> <br  />
 For VProc occupancy, use the tool <code>cavalry_top</code>. <br  />
 </p><div class="fragment"><div class="line">$ cavalry_top</div>
<div class="line">...</div>
<div class="line">PID     NID     VP%     CMD</div>
<div class="line">...</div>
</div><!-- fragment --><p >Check dynamic random access memory (DRAM) bandwidth statistics:<br  />
 </p><div class="fragment"><div class="line">$ echo duration=10000 interval=1000 verbose=1 &gt; /proc/ambarella/dram_statistics</div>
<div class="line">$ cat /proc/ambarella/dram_statistics</div>
</div><!-- fragment --><p >Hardware encoding scenario: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --hdmi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_encode --mipi_dsi 1080p --resource-cfg /home/root/dualvin_sixstreams.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv52</span></div>
<div class="line">$ init.sh --na; modprobe max9296  <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv52_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv72</span></div>
<div class="line">$ init.sh --na; modprobe max9296  <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8; modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_encode --resource-cfg cv72_vin0_1_6_streams.lua --vout-cfg /usr/share/ambarella/lua_scripts/vout_hdmi.lua</div>
<div class="line"> </div>
<div class="line">$ modprobe cavalry</div>
<div class="line">$ cavalry_load -f /lib/firmware/cavalry.bin -r</div>
<div class="line">$ test_encode -A -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 -e -B -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e -C -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 2 -e -D -H 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 3 -e -E -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e -S 5 -h 480p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 5 -e</div>
<div class="line">$ rtsp_server&amp;</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (yolov5) + amba_venc_overlay</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 \</div>
<div class="line">  label = /tmp/nn/in/coco_class_names.txt model= /tmp/nn/model/onnx_yolov5s_cavalry.bin \</div>
<div class="line">  type = yolov5s conf_threshold = 0.25 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.45 top_k = 100 ! queue ! amba_venc_overlay stream_id = 0 alpha = 0 \</div>
<div class="line">  font = /tmp/arial.ttf clut_start = 22 clut_end = 70 color_number = 300 score_lmt = 0.25</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (tiny yolov3) + amba_venc_overlay</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = data out_name = layer115-conv out_name = layer125-conv \</div>
<div class="line">  label = /tmp/nn/in/live_voc_labels.txt model = /tmp/nn/model/yolov3_fastest_xl_cavalry.bin \</div>
<div class="line">  type = yolov3x conf_threshold = 0.8 <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.3 top_k = 100 ! queue ! amba_venc_overlay stream_id = 0 alpha = 0 \</div>
<div class="line">  font = /tmp/arial.ttf clut_start = 22 clut_end = 70 color_number = 300 score_lmt = 0.8</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + videoscale + videoconvert + mlinference (yolov5) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! videoscale ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,width=416,height=416,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=NV12 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP \</div>
<div class="line">  ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 model= /tmp/nn/model/onnx_yolov5s_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (yolov5) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = images out_name = 1037 out_name = 1017 out_name = 997 model= /tmp/nn/model/onnx_yolov5s_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (tiny yolov3) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = data out_name = layer115-conv out_name = layer125-conv model= /tmp/nn/model/yolov3_fastest_xl_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (efficientnet) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = input out_name = 672 model = /tmp/nn/model/efficientnet_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (tf_efficientdet_lite0) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = image_arrays out_name = Sigmoid out_name = ArgMax out_name = stack_2 model = /tmp/nn/model/tf_efficientdet_lite0_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (movenet_lightning) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = serving_default_input out_name = StatefulPartitionedCall model = /tmp/movenet_lightning/tf_movenet_lightning_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (movenet_thunder) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = serving_default_input out_name = StatefulPartitionedCall model = /tmp/movenet_thunder/tf_movenet_thunder_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + mlinference (fast_depth) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! mlinference in_name = input.1 out_name = 424 model = /tmp/fast_depth/onnx_fast_depth_cavalry.bin ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + videoscale + videoconvert + tensor_converter + tensor_filter (yolov5) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! videoscale ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,width=416,height=416,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=NV12 ! videoconvert ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! queue ! tensor_converter \</div>
<div class="line">  ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + tensor_converter + tensor_filter (yolov5) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/onnx_yolov5s_cavalry.bin custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + tensor_converter + tensor_filter (tiny yolov3) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model=/tmp/nn/model/yolov3_fastest_xl_cavalry.bin \</div>
<div class="line">  custom=in_name:data,out_name:layer115-conv+layer125-conv,in_data_fmt:0.0.8.0 ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + tensor_converter + tensor_filter (efficientnet) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model = /tmp/nn/model/efficientnet_cavalry.bin custom=in_name:input,out_name:672,in_data_fmt:0.0.0.0 ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + tensor_converter + tensor_filter (tf_efficientdet_lite0) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model = /tmp/nn/model/tf_efficientdet_lite0_cavalry.bin \</div>
<div class="line">  custom=in_name:image_arrays,out_name:Sigmoid+ArgMax+stack_2,in_data_fmt:0.0.0.0 ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + tensor_converter + tensor_filter (movenet_lightning) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model = /tmp/movenet_lightning/tf_movenet_lightning_cavalry.bin \</div>
<div class="line">  custom=in_name:serving_default_input,out_name:StatefulPartitionedCall,in_data_fmt:0.0.0.0 ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + tensor_converter + tensor_filter (movenet_thunder) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model = /tmp/movenet_thunder/tf_movenet_thunder_cavalry.bin \</div>
<div class="line">  custom=in_name:serving_default_input,out_name:StatefulPartitionedCall,in_data_fmt:0.0.0.0 ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_camsrc + tensor_converter + tensor_filter (fast_depth) + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 amba_camsrc buf-<span class="keywordtype">id</span> = 0 ! queue ! tensor_converter ! tensor_filter framework=amba_cvflow model = /tmp/fast_depth/onnx_fast_depth_cavalry.bin \</div>
<div class="line">  custom=in_name:input.1,out_name:424,in_data_fmt:0.0.0.0 ! queue ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_venccap + amba_vencdemux + h265parse/h264parse + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 -e amba_venccap ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! fakesink \</div>
<div class="line">  d.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! fakesink \</div>
<div class="line">  d.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! fakesink \</div>
<div class="line">  d.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! fakesink \</div>
<div class="line">  d.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! fakesink \</div>
<div class="line">  d.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># For mux related elements, do not use `top -m` to check memory. Use valgrind tool instead if enable.</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># alsasrc + opusenc + mp4mux + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 -e alsasrc ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! opusenc ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># alsasrc + avenc_aac + mp4mux + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 -e alsasrc ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! avenc_aac ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_venccap + amba_vencdemux + h265parse + mp4mux + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 -e amba_venccap sync=<span class="keyword">true</span> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># amba_venccap + amba_vencdemux + h264parse + mp4mux + fakesink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 -e amba_venccap sync=<span class="keyword">true</span> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! fakesink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># six streams h265/h264 + opus</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 -e alsasrc ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! opusenc ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t t.src_0 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! fakesink \</div>
<div class="line">  -e amba_venccap sync=<span class="keyword">true</span> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux0. \</div>
<div class="line">  t.src_1 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux1 ! fakesink d.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux1. \</div>
<div class="line">  t.src_2 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux2 ! fakesink d.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux2. \</div>
<div class="line">  t.src_3 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux3 ! fakesink d.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux3. \</div>
<div class="line">  t.src_4 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux4 ! fakesink d.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux4. \</div>
<div class="line">  t.src_5 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux5 ! fakesink d.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux5.</div>
<div class="line"> </div>
<div class="line"># six streams h265/h264 + aac</div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 -e alsasrc ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! avenc_aac ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t t.src_0 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux0 ! fakesink \</div>
<div class="line">  -e amba_venccap sync=<span class="keyword">true</span> ! amba_vencdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=d d.stream0 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux0. \</div>
<div class="line">  t.src_1 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux1 ! fakesink d.stream1 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux1. \</div>
<div class="line">  t.src_2 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux2 ! fakesink d.stream2 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux2. \</div>
<div class="line">  t.src_3 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux3 ! fakesink d.stream3 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h265parse ! mux3. \</div>
<div class="line">  t.src_4 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux4 ! fakesink d.stream4 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux4. \</div>
<div class="line">  t.src_5 ! mp4mux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=mux5 ! fakesink d.stream5 ! queue max-size-time=0 max-size-bytes=0 max-size-buffers=0 ! h264parse ! mux5.</div>
</div><!-- fragment --><p >Hardware decoding scenario: <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># for cv22/cv25</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ test_vout --hdmi 1080p</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># for cv28, not support for mipi_dsi in amba_hwvdec now, skip</span></div>
<div class="line">$ init.sh --imx274_mipi</div>
<div class="line">$ test_aaa_service -a &amp;</div>
<div class="line">$ modprobe lcd_r9611</div>
<div class="line">$ test_vout --mipi_dsi 1080p</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># filesrc + qtdemux + opusdec + audioconvert + autoaudiosink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 filesrc location=h264_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! opusdec ! audioconvert ! autoaudiosink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># filesrc + qtdemux + avdec_aac + audioconvert + autoaudiosink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 filesrc location=h264_aac.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! avdec_aac ! audioconvert ! autoaudiosink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># filesrc + qtdemux + h264parse + amba_hwvdec + amba_vsink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 filesrc location=h264_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! h264parse ! amba_hwvdec ! amba_vsink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># filesrc + qtdemux + h265parse + amba_hwvdec + amba_vsink</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 filesrc location=h265_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! h265parse ! amba_hwvdec ! amba_vsink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Audio(opus) + Video(h264)</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 filesrc location=h264_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! opusdec ! audioconvert ! autoaudiosink \</div>
<div class="line">  demuxer. ! queue ! h264parse ! amba_hwvdec ! amba_vsink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Audio(opus) + Video(h265)</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 filesrc location=h265_opus.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! opusdec ! audioconvert ! autoaudiosink \</div>
<div class="line">  demuxer. ! queue ! h265parse ! amba_hwvdec ! amba_vsink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Audio(aac) + Video(h264)</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 filesrc location=h264_aac.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! avdec_aac ! audioconvert ! autoaudiosink \</div>
<div class="line">  demuxer. ! queue ! h264parse ! amba_hwvdec ! amba_vsink</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># Audio(aac) + Video(h265)</span></div>
<div class="line">$ GST_DEBUG=basesink:6 gst-launch-1.0 filesrc location=h265_aac.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! avdec_aac ! audioconvert ! autoaudiosink \</div>
<div class="line">  demuxer. ! queue ! h265parse ! amba_hwvdec ! amba_vsink</div>
</div><!-- fragment --><h3><a class="anchor" id="use_in_lychee"></a>
2.4.9 Use GStreamer in Lychee OS</h3>
<p >This section demonstrates how to use GStreamer in <b> Lychee OS </b>, including media file playback, live camera capture, and neural network (NN) inference. <br  />
 </p><dl class="section note"><dt>Note</dt><dd>Try the flows below after executing <a class="elRef" target="_blank" href="../../../system/dc/da7/page_sysdoc_lychee_os.html#lychee_os_install_lycheeos_on_cv3">install and set up Lychee OS</a> and enable dual-VOUT correctly. <br  />
</dd></dl>
<p>Prepare after login <b> Lychee OS </b>: <br  />
 The Lua configuration file <code>cv3_6vin_1080p_linear.lua</code> for six-cam-vin and shell script <code>start_prev.sh</code> to start preview are under the path in SDK: <code>ambarella\app\robotics\6v_yolop_yolov5\scripts</code> <br  />
 Ambarella recommends placing them under the <code>~/</code> in Lychee.</p>
<div class="fragment"><div class="line"><span class="preprocessor"># install amba gstremer solution related rpms</span></div>
<div class="line">Lychee$ sudo dnf update --refresh</div>
<div class="line">Lychee$ sudo dnf install gstreamer1-devel gstreamer1-plugins-base-devel alsa-lib-devel</div>
<div class="line">Lychee$ sudo dnf install libamba-lwapputils-devel libamba_gst_plugins libamba_nnstreamer</div>
<div class="line"><span class="preprocessor"># start preview</span></div>
<div class="line">Lychee$ cd ~</div>
<div class="line">Lychee$ chmod 755 start_prev.sh</div>
<div class="line">Lychee$ ./start_prev.sh</div>
</div><!-- fragment --><h3><a class="anchor" id="example_file_playback_display"></a>
Example 7: Video Decode and Display</h3>
<p >Refer to the <code>waylandsink</code> and <code>xvimagesink</code> elements in gstreamer; the following shows how to decode video file and native display on Lychee desktop. <br  />
</p>
<p >Decode h.264 and display with waylandsink: <br  />
 </p><div class="fragment"><div class="line">Lychee$ gst-launch-1.0 filesrc location=~/tmp_data/test.h264 ! h264parse ! avdec_h264 ! \</div>
<div class="line">        videoconvert ! queue ! videoscale ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,width=640,height=360 ! queue ! waylandsink</div>
</div><!-- fragment --><p >Decode mp4 and display video with xvimagesink: <br  />
 </p><div class="fragment"><div class="line">Lychee$ gst-launch-1.0 filesrc location=~/tmp_data/IMX490_road_8_h264.mp4 ! qtdemux <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=demuxer demuxer. ! queue ! h264parse ! avdec_h264 ! \</div>
<div class="line">        videoconvert ! queue ! videoscale ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,width=640,height=360 ! queue ! xvimagesink</div>
</div><!-- fragment --><p >Decode multiple h.264 files and display compositely: <br  />
 </p><div class="fragment"><div class="line">Lychee$ gst-launch-1.0 compositor <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=comp \</div>
<div class="line">        sink_0::xpos=0 sink_0::ypos=0 sink_0::width=640 sink_0::height=360 \</div>
<div class="line">        sink_1::xpos=640 sink_1::ypos=0 sink_1::width=640 sink_1::height=360 \</div>
<div class="line">        sink_2::xpos=1280 sink_2::ypos=0 sink_2::width=640 sink_2::height=360 \</div>
<div class="line">        sink_3::xpos=0 sink_3::ypos=360 sink_3::width=640 sink_3::height=360 \</div>
<div class="line">        sink_4::xpos=640 sink_4::ypos=360 sink_4::width=640 sink_4::height=360 \</div>
<div class="line">        sink_5::xpos=1280 sink_5::ypos=360 sink_5::width=640 sink_5::height=360 ! \</div>
<div class="line">        videoconvert ! queue ! xvimagesink sync=false \</div>
<div class="line">        filesrc location=~/tmp_data/test.h264 ! h264parse ! avdec_h264 ! comp.sink_0 \</div>
<div class="line">        filesrc location=~/tmp_data/test.h264 ! h264parse ! avdec_h264 ! comp.sink_1 \</div>
<div class="line">        filesrc location=~/tmp_data/test.h264 ! h264parse ! avdec_h264 ! comp.sink_2 \</div>
<div class="line">        filesrc location=~/tmp_data/test.h264 ! h264parse ! avdec_h264 ! comp.sink_3 \</div>
<div class="line">        filesrc location=~/tmp_data/test.h264 ! h264parse ! avdec_h264 ! comp.sink_4 \</div>
<div class="line">        filesrc location=~/tmp_data/test.h264 ! h264parse ! avdec_h264 ! comp.sink_5</div>
</div><!-- fragment --><h3><a class="anchor" id="example_camera_capture"></a>
Example 8: Capture Live Camera and Display</h3>
<p >Refer to the <code>waylandsink</code> and <code>xvimagesink</code> elements in GStreamer; the following shows how to capture live camera streams from <code>amba_camsrc</code> and native display on Lychee desktop. <br  />
</p>
<p >Capture single camera and display with waylandsink: <br  />
 </p><div class="fragment"><div class="line">Lychee$ gst-launch-1.0 -v amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! \</div>
<div class="line">        videoconvert ! videoscale ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,width=640,height=360 ! waylandsink</div>
</div><!-- fragment --><p >Capture single camera and display with xvimagesink: <br  />
 </p><div class="fragment"><div class="line">Lychee$ gst-launch-1.0 -v amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! \</div>
<div class="line">        videoconvert ! videoscale ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,width=640,height=360 ! xvimagesink</div>
</div><!-- fragment --><p >Capture six camera streams and display compositely: <br  />
 </p><div class="fragment"><div class="line">Lychee$ gst-launch-1.0 compositor <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=comp \</div>
<div class="line">        sink_0::xpos=0 sink_0::ypos=0 sink_0::width=640 sink_0::height=360 \</div>
<div class="line">        sink_1::xpos=640 sink_1::ypos=0 sink_1::width=640 sink_1::height=360 \</div>
<div class="line">        sink_2::xpos=1280 sink_2::ypos=0 sink_2::width=640 sink_2::height=360 \</div>
<div class="line">        sink_3::xpos=0 sink_3::ypos=360 sink_3::width=640 sink_3::height=360 \</div>
<div class="line">        sink_4::xpos=640 sink_4::ypos=360 sink_4::width=640 sink_4::height=360 \</div>
<div class="line">        sink_5::xpos=1280 sink_5::ypos=360 sink_5::width=640 sink_5::height=360 ! \</div>
<div class="line">        queue ! videoconvert ! queue ! xvimagesink \</div>
<div class="line">        amba_camsrc buf-<span class="keywordtype">id</span>=0 ! queue ! comp.sink_0 \</div>
<div class="line">        amba_camsrc buf-<span class="keywordtype">id</span>=1 ! queue ! comp.sink_1 \</div>
<div class="line">        amba_camsrc buf-<span class="keywordtype">id</span>=2 ! queue ! comp.sink_2 \</div>
<div class="line">        amba_camsrc buf-<span class="keywordtype">id</span>=3 ! queue ! comp.sink_3 \</div>
<div class="line">        amba_camsrc buf-<span class="keywordtype">id</span>=4 ! queue ! comp.sink_4 \</div>
<div class="line">        amba_camsrc buf-<span class="keywordtype">id</span>=5 ! queue ! comp.sink_5</div>
</div><!-- fragment --><h3><a class="anchor" id="example_fileinput_nn_inference_display"></a>
Example 9: NNStreamer Inference and Result Display</h3>
<p >Refer to the <code>amba_cvflow</code> framework in the sub-plugin of the modified <code>tensor_filter</code> element. The following demonstrates how to run NN models with the file input and compositely display the original image and results on Lychee desktop. <br  />
</p>
<p >Decode h.264 file, feed to yolov5s model for NN inference and display results in Lychee: <br  />
 </p><div class="fragment"><div class="line">Lychee$ gst-launch-1.0 -v filesrc location=~/tmp_data/test.h264 ! h264parse ! avdec_h264 ! queue ! \</div>
<div class="line">        videoconvert ! videoscale ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,width=1280,height=720,<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>=RGBP ! tee <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=t \</div>
<div class="line">        t. ! queue ! videoscale ! video/x-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>,width=416,height=416 ! tensor_converter ! \</div>
<div class="line">        tensor_filter framework=amba_cvflow model=~/tmp_data/cv3_yolov5s.bin custom=in_name:images,out_name:1037+1017+997,in_data_fmt:0.0.8.0 ! \</div>
<div class="line">        tensor_decoder mode=bounding_boxes option1=amba_yolov5 option2=~/tmp_data/coco_class_names.txt option4=1280:720 option5=416:416 ! \</div>
<div class="line">        comp.sink_0 \</div>
<div class="line">        t. ! queue ! comp.sink_1 \</div>
<div class="line">        compositor <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a>=comp sink_0::zorder=2 sink_1::zorder=1 ! videoconvert ! xvimagesink</div>
</div><!-- fragment --><h3><a class="anchor" id="known_issues"></a>
2.4.10 Known Issues</h3>
<p ><b>Stuck in the <code>amba_vencdemux</code> element:</b> <br  />
 When running with too many streams, <code>alloc_mem=1</code> in the <code>amba_venccap</code> element and <code>max-size-time=0 max-size-bytes=0 max-size-buffers=0</code> in the <code>queue</code> element must be set up.<br  />
</p>
<p ><b>Stuck when playbacking (hardware decoding) video and audio at the same time:</b> <br  />
 Users can set the parameter <code>async=false</code> in the sink element. <br  />
</p>
<p ><b> Issues of overlay, hardware decoder for DSP v6 </b> <br  />
 Not ready on CV52 / CV72 /CV3 now.</p>
<p ><b> RTSP / RTP issues when working with <code>amba_venccap</code> </b> <br  />
 Some test flows are provided regarding how to link with some RTSP / RTP related elements. Amba Venc element needs to be improved in the future. For example, it is required to enable call Ambarella video encoding element by different pipelines at the same time and fix the PTS issue when working with some servers / clients.</p>
<h3><a class="anchor" id="notice"></a>
2.4.11 Notice</h3>
<p ><b>Start the GStreamer Daemon:</b> <br  />
 </p><div class="fragment"><div class="line"><span class="preprocessor"># By default, for the newer version gstd_0.15.0 in recipe-oss, simply run GstD as shown below: &lt;br&gt;</span></div>
<div class="line">$ gstd</div>
<div class="line"> </div>
<div class="line"><span class="preprocessor"># For the Yocto community version of GstD (1.0+really0.8.0) in recipe-multimeida, run GstD as shown below: &lt;br&gt;</span></div>
<div class="line">$ gstd -D</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3 </li>
  </ul>
</div>
</body>
</html>
