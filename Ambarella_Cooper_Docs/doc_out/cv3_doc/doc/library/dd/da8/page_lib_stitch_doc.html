<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Library: Stitch Library API</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<link rel="search" href="../../search_opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Library"/>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="../../../library/mathjax/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-ambarella.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../Ambarella.png"/></td>
  <td id="projectalign">
   <div id="projectname">Library<span id="projectnumber">&#160;Cooper_1.6.0 (CV72 &amp; CV3) @ 2024.07.10 14:12:44</span>
   </div>
   <div id="projectbrief">placeholder</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,true,'search.html','Search');
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('dd/da8/page_lib_stitch_doc.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">Stitch Library API </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="stitch_history"></a>
0. Revision History</h1>
<a class="anchor" id="Stitch library"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Library Version </th><th align="left">Updated Date</th><th align="left">Chip</th><th align="left">Modification </th></tr>
<tr>
<td>0.3.4 </td><td>20190524 </td><td>CV2x </td><td>Initial Version </td></tr>
<tr>
<td>1.0.0 </td><td>20200109 </td><td>CV2x </td><td>Added backward mapping and raw encode for stitching </td></tr>
<tr>
<td>1.2.0 </td><td>20200213 </td><td>CV2x </td><td>Added calibration on chip </td></tr>
<tr>
<td>2.0.0 </td><td>20200426 </td><td>CV2x </td><td>Added dual fisheye lens for 360 degree panorama view stitching </td></tr>
<tr>
<td>2.0.6 </td><td>20210115 </td><td>CV2x </td><td>Added 6x4M performance <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_features">1.1 Ambarella Stitching Features</a> </td></tr>
<tr>
<td>2.0.6 </td><td>20210223 </td><td>CV2x </td><td>Added support for skipping sub source buffer blend pass <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_skip_blend">2.5.9 Stitch Skip Source Buffer Blend</a> </td></tr>
<tr>
<td>2.1.0 </td><td>20210427 </td><td>CV2x </td><td>Added support for vertical stitching with rotate input <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_pro_rotate">2.5.5 Stitch with Rotate Input on CV2x</a> </td></tr>
<tr>
<td>2.1.1 </td><td>20210629 </td><td>CV2x </td><td>Refined homography cylindrical projection formula </td></tr>
<tr>
<td>2.1.2 </td><td>20210629 </td><td>CV2x </td><td>Fixed the issue of projection formula </td></tr>
<tr>
<td>2.1.3 </td><td>20210713 </td><td>CV2x </td><td>Added support for using grid level map to perform LDC </td></tr>
<tr>
<td>2.1.4 </td><td>20210722 </td><td>CV2x </td><td>Added support for disparity difference to create configrations for specific distance stitching </td></tr>
<tr>
<td>2.2.0 </td><td>20210807 </td><td>CV2x </td><td>Added support for keeping specific output resolution </td></tr>
<tr>
<td>2.2.0 </td><td>20210904 </td><td>CV2x </td><td>Added reference link of lens / pose calibration </td></tr>
<tr>
<td>2.2.0 </td><td>20210921 </td><td>CV2x </td><td>1. Fixed issue in stitch_set_seam_line 2. Changed radius for keeping seam </td></tr>
<tr>
<td>2.3.1 </td><td>20220105 </td><td>CV2x </td><td>Added support for increasing stitching max height from 2160 to 3840 </td></tr>
<tr>
<td>2.3.2 </td><td>20220117 </td><td>CV2x </td><td>Added support for doing dewarp in pixel level </td></tr>
<tr>
<td>2.3.2 </td><td>20220119 </td><td>CV2x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_calib">2.4 Calibration Process</a> </td></tr>
<tr>
<td>2.3.2 </td><td>20220308 </td><td>CV2x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_insert_pm">2.5.8 Stitch Privacy Mask</a> </td></tr>
<tr>
<td>2.3.2 </td><td>20220328 </td><td>CV2x </td><td>Updated Section 2.5.11 Stitch Simulation </td></tr>
<tr>
<td>2.3.2 </td><td>20220510 </td><td>CV2x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#sec_stitch_faq">4 Stitch FAQ</a> </td></tr>
<tr>
<td>2.3.3 </td><td>20220510 </td><td>CV2x </td><td>Added support for specifying grid number of warp table </td></tr>
<tr>
<td>2.3.4 </td><td>20220616 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_channel_rotate">2.5.6 Stitch with Rotated channels</a> </td></tr>
<tr>
<td>2.3.5 </td><td>20220803 </td><td>CV2x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#sec_stitch_faq">4 Stitch FAQ</a> </td></tr>
<tr>
<td>2.3.5 </td><td>20220803 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_eight_channels_stitching">2.5.7 Stitch with 6x / 8x Channels</a> </td></tr>
<tr>
<td>2.3.6 </td><td>20220907 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_pro_parameters">2.5.1 Stitching Configration File Descriptions</a> 2.5.1 Stitching Configration File Descriptions </td></tr>
<tr>
<td>2.3.6 </td><td>20220908 </td><td>CV2x </td><td>Added support for alpha-blending for 6th source buffer </td></tr>
<tr>
<td>2.3.7 </td><td>20220922 </td><td>CV2x </td><td>Changed grid spacing order to grid spacing width / height pixel value. </td></tr>
<tr>
<td>2.3.8 </td><td>20221025 </td><td>CV2x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_pro_rotate">2.5.5 Stitch with with Rotated Channels</a> </td></tr>
<tr>
<td>2.3.8 </td><td>20221101 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_calib_lsc">2.4.1 LSC Calibration</a> </td></tr>
<tr>
<td>3.0.0 </td><td>20221101 </td><td>CV2x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_pro_dual">2.5.11 Stitch Dual Fisheyes for 360 Degree Panoramic</a> </td></tr>
<tr>
<td>3.0.0 </td><td>20221215 </td><td>CV2x </td><td>Updated Section 2.5.14 Stitch with Customers' Warp Table and Alpha Table </td></tr>
<tr>
<td>3.0.1 </td><td>20230110 </td><td>CV2x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_backwarp_map">2.5.12 Stitch Backward / Forward Mapping</a> </td></tr>
<tr>
<td>3.0.2 </td><td>20230327 </td><td>CV2x </td><td>Fix some warnings </td></tr>
<tr>
<td>3.0.3 </td><td>20230404 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_pro_tilt">2.5.17 Stitch in horizontal direction with angles below the horizon</a> </td></tr>
<tr>
<td>3.0.4 </td><td>20230528 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_update_warp_table">2.5.15 Stitch with updating warp table on the fly</a> </td></tr>
<tr>
<td>3.0.4 </td><td>20230528 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_simulate_with_pose_results">2.5.16 Stitch Simulation with Pose Calibration Results</a> </td></tr>
<tr>
<td>3.0.4 </td><td>20230528 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#sec_stitch_faq_q7">Question 7: How to make calibration data compatible with new version SDK?</a> </td></tr>
<tr>
<td>3.0.5 </td><td>20230727 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_pro_dual">2.5.11 Stitch Dual Fisheyes for 360 Degree Panoramic</a> </td></tr>
<tr>
<td>3.0.6 </td><td>20230802 </td><td>CV5x </td><td>Updated Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#sec_stitch_faq_q7">Question 7: How to make calibration data compatible with new version SDK?</a> </td></tr>
<tr>
<td>3.0.7 </td><td>20230802 </td><td>CV5x </td><td>Added compatibility for old warp table of vertical case </td></tr>
<tr>
<td>3.0.8 </td><td>20230811 </td><td>CV5x </td><td>Fix artifact in the boundary </td></tr>
<tr>
<td>4.0.0 </td><td>20231020 </td><td>CV5x </td><td>Added Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_pro_tilt_vhvh">2.5.19 Stitch in Vertical-Horizontal-Vertical-Horizontal Direction with Angles below the Horizon</a> </td></tr>
<tr>
<td>4.0.1 </td><td>20231221 </td><td>CV5x </td><td>Fix issues in the calculation of horizontal vector </td></tr>
<tr>
<td>4.1.0 </td><td>20231226 </td><td>CV5x </td><td>Added VH dewarp pipeline </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="stitch_introduction"></a>
1. Introduction</h1>
<p >The CV2x and CV5x series of chips support multi-channel stitching. This chapter introduces basic information on image stitching.</p><ul>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_features">1.1 Ambarella Stitching Features</a></li>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_concept">1.2 Image Stitching</a></li>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_solutions">1.3 Stitching without Alpha Blending</a></li>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_blending_solution">1.4 Stitching with Alpha Blending</a></li>
</ul>
<h2><a class="anchor" id="stitch_features"></a>
1.1 Ambarella Stitching Features</h2>
<p >Some basic stitching features are listed below. </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">Stitching Mode   </th><th class="markdownTableHeadLeft">Channels   </th><th class="markdownTableHeadLeft">Projection Mode   </th><th class="markdownTableHeadLeft">Performance    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">Horizontal stitching   </td><td class="markdownTableBodyLeft">2x/3x/4x   </td><td class="markdownTableBodyLeft">Cylindrical / perspective   </td><td class="markdownTableBodyLeft">4ch x 5MP20 HEVC    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">Vertical stitching   </td><td class="markdownTableBodyLeft">2x/../6x   </td><td class="markdownTableBodyLeft">Transverse Mercator / cylindrical   </td><td class="markdownTableBodyLeft">4ch x 5MP20 / 6ch x 4MP14 HEVC    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">Dual-channel 360 stitching   </td><td class="markdownTableBodyLeft">2x   </td><td class="markdownTableBodyLeft">Equirectangular   </td><td class="markdownTableBodyLeft">&ndash;   </td></tr>
</table>
<p >Tool versions for the software development kit (SDK) are listed below. <br  />
 </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadLeft">SDK Version (CV5x)   </th><th class="markdownTableHeadLeft">Lens Tool Version   </th><th class="markdownTableHeadLeft">Pose Tool Version    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">2.0   </td><td class="markdownTableBodyLeft">cv5x_cv2x_lens_calibration_tool_for_windows_v2.0.8_20230207.tar   </td><td class="markdownTableBodyLeft">cv5x_cv2x_pose_calibration_tool_for_windows_v0.2.5_20221024.tar    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">2.5   </td><td class="markdownTableBodyLeft">cv5x_cv2x_lens_calibration_tool_for_windows_v2.0.8_20230207.tar   </td><td class="markdownTableBodyLeft">cv5x_2x_pose_calibration_tool_for_windows_v1.0.0_20230220.tar    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">Cooper 1.0   </td><td class="markdownTableBodyLeft">cv5x_cv2x_lens_calibration_tool_for_windows_v2.0.9_20230530.tar   </td><td class="markdownTableBodyLeft">cv5x_cv2x_pose_calibration_tool_for_windows_v1.0.6_20230628.tar    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyLeft">Cooper 1.5   </td><td class="markdownTableBodyLeft">cv5x_cv2x_lens_calibration_tool_for_windows_v2.0.9_20230530.tar   </td><td class="markdownTableBodyLeft">cv5x_2x_pose_calibration_tool_for_windows_v1.3.0_20231023.tar    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyLeft">Cooper 1.6   </td><td class="markdownTableBodyLeft">cv5x_cv2x_lens_calibration_tool_for_windows_v2.0.9_20230530.tar   </td><td class="markdownTableBodyLeft">cv5x_2x_pose_calibration_tool_for_windows_v1.5.0_20240116.tar   </td></tr>
</table>
<h2><a class="anchor" id="stitch_concept"></a>
1.2 Image Stitching</h2>
<p >Image stitching is an important research direction for computer vision (CV) and image processing. It is a complex process that involves computer graphics, graph theory, software development, and more. <br  />
 The image stitching technology combines images captured by different cameras; this technology can enlarge the field of view (FoV) and raise the image resolution. The image stitching process includes the two following stages: <br  />
</p><ul>
<li>Image calibration <br  />
</li>
<li>Image stitching <br  />
 In addition, a natural intergradation effect can be obtained using the related blending algorithms to synchronize the luminance, color, exposure window of different cameras, and so on.</li>
</ul>
<h2><a class="anchor" id="stitch_solutions"></a>
1.3 Stitching without Alpha Blending</h2>
<div class="image">
<img src="../../image_stitch.jpg" alt=""/>
<div class="caption">
Figure 1-1. Image Stitching.</div></div>
<p> Fixed-line stitching is a simple method to join images together. In this example, the image to the left of the fixed line comes from the left side, and the image to the right of the fixed line comes from the right side. This solution facilitates the blending process, and ensures the quality is stable without any large fluctuations. A disadvantage of this solution is that the image boundary is noticeable.</p>
<h2><a class="anchor" id="stitch_blending_solution"></a>
1.4 Stitching with Alpha Blending</h2>
<p >As users perform fixed-line stitching, the channel junction traces are relatively shallow. However, as <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_result">6.4.1 Four-channel Stitching Example</a> shows, the traces are still there. If users want to make the channel junction almost invisible in a particular situation, Ambarella recommends that users consider alpha blending, which may result in sacrificing around 15% ~ 20% of image digital signal processor (IDSP) performance and dynamic random-access memory (DRAM) bandwidth.</p>
<h3><a class="anchor" id="stitch_solutions_linear"></a>
1.4.1 Linear-Blending Stitching</h3>
<div class="image">
<img src="../../linear_blending.jpg" alt=""/>
<div class="caption">
Figure 1-2. Linear Line-Blending Stitching Example Image.</div></div>
<p> Linear blending uses an alpha table to adjust the transparency of the overlap area. This enables the area to gradually transfer from one image to the other. The overlap width is about 15% of the original image width. If the images are aligned sufficiently, the blending width can be reduced, resulting in a better blending result for a moving object. On the other hand, if the images are misaligned, this width must be increased. The advantage of this solution is that the image border is not visible and the stitching result is stable. The disadvantage of linear stitching is that when there is a large difference in the distance between objects, at least one of the objects will be blurred.</p>
<h3><a class="anchor" id="stitch_solutions_dyna"></a>
1.4.2 Dynamic Seam Line Blending Stitching</h3>
<p >The dynamic seam line solution uses the best seam line searching algorithm. Based on the current input images, this algorithm outputs the minimum visual effect difference seam line's position of the overlap zone. The advantage of this solution is that it can bypass the areas and make the merged image appear soft and natural. The disadvantage is that video fluctuation can appear in the overlap zone. The seam line is recalculated for each frame, so it is possible that the best seam line for each frame will not be the same. Moreover, the complexity of the algorithm must be limited, given that the update period is about 30 ms per frame.</p>
<h2><a class="anchor" id="stitch_solutions_blend"></a>
1.5 Stitching Result Comparison</h2>
<p ><b>Original images:</b> </p><div class="image">
<img src="../../left_right.jpg" alt=""/>
<div class="caption">
Figure 1-3. Original Left and Right Images.</div></div>
<p ><b>Fixed line stitching:</b> </p><div class="image">
<img src="../../fix_stitching.jpg" alt=""/>
<div class="caption">
Figure 1-4. Fixed Line Stitching.</div></div>
<p ><b>Linear blending stitching:</b> </p><div class="image">
<img src="../../linear_stitching.jpg" alt=""/>
<div class="caption">
Figure 1-5. Linear Stitching.</div></div>
<p ><b>Dynamic seam line blending stitching:</b> </p><div class="image">
<img src="../../dyna_stitching.jpg" alt=""/>
<div class="caption">
Figure 1-6. Dynamic Seam Line Stitching.</div></div>
<hr  />
<h1><a class="anchor" id="stitch_design"></a>
2. Design</h1>
<p >This chapter provides information on the design of the stitching system.</p><ul>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_cap">2.1 Capture Device Structure</a></li>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_soft">2.2 Software Structure</a></li>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_sys">2.3 System Flow</a></li>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_calib">2.4 Calibration Process</a></li>
<li>Section <a class="el" href="../../dd/da8/page_lib_stitch_doc.html#stitch_pro">2.5 Stitching Process</a></li>
</ul>
<h2><a class="anchor" id="stitch_cap"></a>
2.1 Capture Device Structure</h2>
<div class="image">
<img src="../../expand.jpg" alt=""/>
<div class="caption">
Figure 2-1. Expanding Structure for Capture Device.</div></div>
<p> In order to enlarge the total FoV, an expanding structure is used for the image capture device: Because the capture device is composed of at least two cameras, similar to human eyesight, there are some parallaxes between the images captured by these cameras. If an object is too close to the camera, it is not possible to stitch the two images together without distortion. Therefore, a minimum distance between the cameras and the object is required (example: 6 meters). </p><div class="image">
<img src="../../close.jpg" alt=""/>
<div class="caption">
Figure 2-2. Blending Result for Close Object.</div></div>
<p> Users should note that objects closer to the eye appear larger. As a result, if the same horizontal offset is applied to different object distances, at least one of the objects will be positioned incorrectly. Therefore, if two object distances overlap, at least one of them will not be perfect. For a related demonstration, refer to the appendix.</p>
<h2><a class="anchor" id="stitch_soft"></a>
2.2 Software Structure</h2>
<p >The software structure contains three parts: the application, the driver, and the library.</p>
<p >Application</p>
<ul>
<li>User interface: obtains the input parameters from the command-line interface to set up the action of the application and the parameters for calibration and stitching.</li>
<li>Image capture: obtains the YUV of the current scene. Then, it sends an input / output (I/O) control message to the driver. The driver sends back the address of the image in DRAM.</li>
<li>Apply calibration: sends the left (or top) YUV address and the right (or bottom) YUV address to the library for calibration. Then, it sends the calibration parameters to the library and receives the shifting value from the library.</li>
<li>Apply stitching: sends the left (or top) YUV address and the right (or bottom) YUV address to the library for stitching. Then, it sends the stitching parameters to the library and retrieves the updated data from the alpha table.</li>
</ul>
<p >Driver</p>
<p >The driver is used to communicate with the digital signal processor (DSP). It acts as the bridge for the application and the DSP. The alpha table data is copied to a specific dynamic random access memory (DRAM) in the Linux kernel. Once this table is updated, it must wait for the DSP to consume it. The YUV data address for stitching analysis is retrieved by the interruption and fed back to the application.</p>
<p >Library</p>
<div class="image">
<img src="../../soft.jpg" alt=""/>
<div class="caption">
Figure 2-3. Software Structure.</div></div>
<ul>
<li>Calibration: the library receives the left (or top) image and the right (or bottom image) from the application. Afterwards, it receives the calibration parameters from the application and calculates the shifting value for the image pair. Then, it sends the shifting value back to the application.</li>
<li>Stitching: the library receives the left (or top) image and the right (or bottom) image from the application. Then, it gets the stitching parameters from the application. Finally, it calculates the seam line for this image pair to create the alpha table.</li>
</ul>
<h2><a class="anchor" id="stitch_sys"></a>
2.3  System Flow</h2>
<p >There are two steps in this process:</p><ul>
<li>Calibration</li>
<li>Stitching</li>
</ul>
<p >The steps are independent from one another. In the calibration step, the input images come from the camera. This means that the calibration will be based on the current scene. Image pre-processing includes automatic exposure (AE) and automatic white balance (AWB) adjustment, noise elimination, and more. The calibration model provides the image scale, rotation, and shift factors. In the stitching step, the input images come from the cameras. Then, it pre-processes the image using the calibration parameters obtained from the calibration process. Afterwards, it finds the best seam line for the current images and creates an alpha table.</p>
<h2><a class="anchor" id="stitch_calib"></a>
2.4 Calibration Process</h2>
<p >The calibration process consists of three stages: lens shading calibration (LSC), lens calibration, and pose calibration. <br  />
 LSC should be performed on the host PC. The user can use amba_calibration_v2.6.exe to perform the calibration; Contact the Ambarella support team for these tools. <br  />
 Lens calibration should be performed on the host PC because it is a long process. <br  />
 Pose calibration can be performed either on the host PC or on the chip. <br  />
</p>
<h3><a class="anchor" id="stitch_calib_lsc"></a>
2.4.1 Lens Shading Calibration (on Host Windows Side)</h3>
<div class="image">
<img src="../../shading.jpg" alt=""/>
<div class="caption">
Figure 2-4. Lens Shading.</div></div>
<p> The term shading describes the light fall-off or color variation from the sensor center to the corners that do not originate from the captured scene. Users must perform LSC to remove the lens shading. <br  />
 Ambarella suggests setting the color temperature to 5000K for the lamp box. The command should follow the rule amba_calibration_vX.X.exe MODE SOURCE PATH PREFIX WIDTH HEIGHT BLC PATTERN CENTERX CENTERY <br  />
</p>
<p >MODE: 2 <br  />
 SOURCE: 0 <br  />
 PATH: the path of the RAW data <br  />
 PREFIX: the prefix of the RAW data <br  />
 WIDTH: width of the RAW data <br  />
 HEIGHT: height of the RAW data <br  />
 BLC: black level of the RAW data <br  />
 </p><div class="image">
<img src="../../blc.jpg" alt=""/>
<div class="caption">
Figure 2-5. Black Level Correction Value.</div></div>
<p> PATTERN: Bayer RAW pattern <br  />
 </p><div class="image">
<img src="../../bayer_pattern.jpg" alt=""/>
<div class="caption">
Figure 2-6. Bayer Pattern Value.</div></div>
<p> CENTERX: center in the horizontal direction. If it is set to 0, the tool will caculate it automatically <br  />
 CENTERY: center in the vertical direction. If it is set to 0, the tool will caculate it automatically <br  />
</p>
<div class="fragment"><div class="line">The folder <span class="stringliteral">&quot;lsc_bin&quot;</span> should be created in the path E:\resolved_problem\stitching\3A\0\ first.</div>
<div class="line">amba_calibration_vx.x.exe 2 0 E:\resolved_problem\stitching\3A\0\ cap_raw_raw_3840x4320_0 3840 2160 1024 1 0 0</div>
<div class="line">the log is shown below ï¼š</div>
<div class="line">vig_result-&gt;model_center_R = [942, 561]</div>
<div class="line">vig_result-&gt;model_center_Gr = [942, 561]</div>
<div class="line">vig_result-&gt;model_center_Gb = [942, 561]</div>
<div class="line">vig_result-&gt;model_center_B = [942, 561]</div>
<div class="line">separate_raw.size.width = 1920</div>
<div class="line">separate_raw.size.height = 1080</div>
<div class="line">cal LSC calibration Done!</div>
<div class="line">-------------end------------</div>
</div><!-- fragment --><p >The calibration data is stored in the folder "lsc_bin". <br  />
 Rename the bin in "lsc_bin" to a name such as "vin0_3840x2160_cali_lens_shading.bin"; 0 is the video source (VSRC) name. <br  />
 Copy the "vin0_3840x2160_cali_lens_shading.bin" to the path <code>/usr/share/ambarella/idsp/calibration/</code> in the board, and modify the Lua file /usr/share/ambarella/idsp/aaa_iq_config.lua. <br  />
 </p><div class="image">
<img src="../../lsc_loadding.jpg" alt=""/>
<div class="caption">
Figure 2-7. Loading LSC Bin Configuration.</div></div>
<p> When users run "test_aaa_service -a", the calibration data will be loaded automatically.</p>
<h3><a class="anchor" id="stitch_calib_lens"></a>
2.4.2 Lens Calibration (on Host Windows Side)</h3>
<p >Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">2. Lens Calibration</a> for more details. <br  />
 Lens calibration is used to estimate the intrinsic parameters and distortion parameters. <br  />
 Intrinsic parameters: focal length / principal point <br  />
 Distortion parameters: radial distortion and tangential distortion <br  />
 Ambarella suggests using the following lens model: <br  />
 Horizontal mode: EVETAR N125b03518w <br  />
 Vertical mode: EVETAR M127B02820WM12 <br  />
</p>
<h3><a class="anchor" id="stitch_calib_chip"></a>
2.4.3 Stitch Pose Calibration (on Chip)</h3>
<p >Refer to <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_stitch">1. Stitching Pose Calibration</a> for more details. <br  />
</p><ul>
<li>There are four April tags in one pattern; it is assumed that each tag has its own corner ID (the angle of the April tag is different and the corner ID is from 0~3). As the pose calibration algorithm must use the same corner ID, the user should first query the common corner ID. "--debug 7" is the option to list all corner IDs. <br  />
</li>
<li>Storing many frames of YUV on the flash is a waste of memory; extracting the pattern information (include circle image position / object position) will be helpful. "--debug 6" is used to save target information. "--no-yuv" is specified to use previous stored target information. <br  />
</li>
<li>Users can specify stitching distance to create certain configuration information. "--sensor-dist" is used to specify the stitching distance. <br  />
 Performing pose calibration on the chip is suitable for environment-independent applications. As pose calibration must be performed for all equipment, using the calibraiton tool on board is much more efficient. <br  />
 Users can refer to <a class="el" href="../../d1/d1e/page_lib_sensor_calib_doc.html">Sensor Calibration Library API</a> for more pose calibration details.</li>
</ul>
<h3><a class="anchor" id="stitch_calib_example"></a>
2.4.4 Stitch Calibration Example</h3>
<p >The following is an example to perform the calibration for four-channel vertical stitching.</p><ul>
<li>Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_flow">2.2 Lens Calibration Flow</a> to learn the dataset capture method and the lens calibration process. <br  />
</li>
<li>Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_flow">5.3 Stitching Pose Calibration Flow</a> to learn the pose calibration process. <br  />
</li>
<li>Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#stitching_cmd_list">5.4 Multi-Channel Stitching Example</a> to learn the run stitching case commands. <br  />
</li>
</ul>
<h2><a class="anchor" id="stitch_pro"></a>
2.5 Stitching Process</h2>
<p >After the calibration process, the stitch library reports the calibration parameters to the application. Users must confirm if the result represents the optimal offset for each channel.</p>
<h3><a class="anchor" id="stitch_pro_parameters"></a>
2.5.1 Stitching Configration File Descriptions</h3>
<p >Some descriptions of the options are provided in test_stitch utility: <br  />
 </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Field   </th><th class="markdownTableHeadCenter">Value   </th><th class="markdownTableHeadCenter">Details    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">A / B / C / D / E   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Specify the overlap ID    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">i   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Channel ID    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">width   </td><td class="markdownTableBodyCenter">1920   </td><td class="markdownTableBodyCenter">Width    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">height   </td><td class="markdownTableBodyCenter">1080   </td><td class="markdownTableBodyCenter">Height    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">mode   </td><td class="markdownTableBodyCenter">3   </td><td class="markdownTableBodyCenter">0: map out to VIN; 1: merge data; 2: perform dewarp; 3: blending; 4: mapping point from VIN    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">map-point   </td><td class="markdownTableBodyCenter">960,540   </td><td class="markdownTableBodyCenter">Specify the point in the output image and map the point in the VIN domain    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">seam-method   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Seam-line type. 0: dynamic plan method, 1: graphcut method    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">seam-write   </td><td class="markdownTableBodyCenter">x   </td><td class="markdownTableBodyCenter">Save the seam line position in the overlap area    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">seam-read   </td><td class="markdownTableBodyCenter">x   </td><td class="markdownTableBodyCenter">Read the seam line position; create and apply the alpha table    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">top   </td><td class="markdownTableBodyCenter">0~shift_hor,0~3840   </td><td class="markdownTableBodyCenter">Indicate the position and number of top rows in order to prevent performance of seam-line searching    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">bottom   </td><td class="markdownTableBodyCenter">0~shift_hor,0~3840   </td><td class="markdownTableBodyCenter">Indicate the position and number of down rows in order to prevent performance of seam-line searching; default is 0,0    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">blend-r   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Blending radius; alpha changing steps are 255 / (2 * radius + 1) near the seam line position. The values vary from 255 to 0    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">vertical   </td><td class="markdownTableBodyCenter">x   </td><td class="markdownTableBodyCenter">Perform blending for vertical-direction stitching    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">clear   </td><td class="markdownTableBodyCenter">x   </td><td class="markdownTableBodyCenter">Clear the dewarp effect on the main buffer    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">warp-file   </td><td class="markdownTableBodyCenter">"file name"   </td><td class="markdownTableBodyCenter">Save the horizontal and vertical warp vector for debugging    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">verbose   </td><td class="markdownTableBodyCenter">x   </td><td class="markdownTableBodyCenter">Show the detailed input / output (offset / width / height / grid spacing / grid number information)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">adjust   </td><td class="markdownTableBodyCenter">20,2   </td><td class="markdownTableBodyCenter">Adjust the offset of specified channels in pixels    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">no-overlap   </td><td class="markdownTableBodyCenter">x   </td><td class="markdownTableBodyCenter">Specify the no overlap flag, used in the dewarp stage    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">fuse-channel   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Specify fuse channel for dewarp; 1: 1, 2: 2, 3: 1 and 2, 7: 1 and 2 and 3    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">use-map   </td><td class="markdownTableBodyCenter">x   </td><td class="markdownTableBodyCenter">Specify use of the map method. 0: no map; 1: pixel-level map; 2: calculate grid spacing automatically; 3: use a specific grid-spacing map. When this option is not specified, the default is to use the pixel-level map method    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">grid-w   </td><td class="markdownTableBodyCenter">1,2,4,8,16,...,128   </td><td class="markdownTableBodyCenter">Specify the specific grid spacing width to create a 2D warp table    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">grid-h   </td><td class="markdownTableBodyCenter">1,2,4,8,16,...,128   </td><td class="markdownTableBodyCenter">Specify the specific grid spacing height to create a 2D warp table    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">cw-rotate   </td><td class="markdownTableBodyCenter">0/1   </td><td class="markdownTableBodyCenter">Rotate channel in the clockwise direction    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">hflip   </td><td class="markdownTableBodyCenter">0/1   </td><td class="markdownTableBodyCenter">Flip channel in the horizontal direction    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">vflip   </td><td class="markdownTableBodyCenter">0/1   </td><td class="markdownTableBodyCenter">Flip channel in the vertical direction    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">dual-fisheye-ldc   </td><td class="markdownTableBodyCenter">0,1,2   </td><td class="markdownTableBodyCenter">0: stitching without LDC. 1: stitching with calibration. 2: stitching with parameter adjustment    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">update-overlap-content   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Perform dynamic stitching with updating overlap's content. 0: no; 1: sparse; 2: dense; 3: dense acc    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">skip-version-check   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Skip sensor calibration data version    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">diff-thresh   </td><td class="markdownTableBodyCenter">20   </td><td class="markdownTableBodyCenter">Specify difference threshold    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">diff-step-ratio   </td><td class="markdownTableBodyCenter">2   </td><td class="markdownTableBodyCenter">Specify difference step ratio    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">no-calib   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify to do stitching without calibration    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">max-fov   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify maximum FoV of lens    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">fish-radius   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify fisheye radius    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">in-center   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify input center    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">shift   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify output shift    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">extend-output   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify equirectangular output    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">skip-version-check   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Skip version check operation    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">smooth-width   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify smooth width for dynamic stitching    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">clear-blend-warp   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify to clear blend warp    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">max-disparity   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify maximum disparity to filter invalid data    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">stable-frame   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify stable frames for dyanmic stitching    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">motion-thresh   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify motion thresh for dyanmic stitching    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">speed-mode   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify dynamic stitcing mode. 0: fastest; 1: fast; 2: slow    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">stop-shift   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Specify to stop using globle shift   </td></tr>
</table>
<h3><a class="anchor" id="stitch_pro_pre"></a>
2.5.2 Run Multi-channel Stitching Cases</h3>
<p >For multi-channel stitching cases, users must modify the Lua script accordingly. The overlapped areas in the canvas must be configured properly. The following procedure describes the steps required for stitching:</p>
<p >Preview -&gt; dewarp (rough tuning) -&gt; offset change (refined tuning) -&gt; blending</p>
<p ><b>1. Configure the Lua script </b> <br  />
 There are some options that should be configured for stitching use cases. In the channel configuration, "blend_left_or_top" and "blend_right_or_bot" are configured to show which channel part will perform blending. <br  />
 There are two parts for each channel. <br  />
 For horizontal stitching: left or right <br  />
 For vertical stitching: top or bottom <br  />
 The first channel should be set as blend_left_or_top = 0, blend_right_or_bot = 1.<br  />
 The last channel should be set as blend_left_or_top = 1, blend_right_or_bot = 0.<br  />
 The middle channels should be set as blend_left_or_top = 1, blend_right_or_bot = 1. <br  />
 For CV5x, in the canvas configuration: <br  />
 "blend_copy_num_minus_1" is used to report each channel's blending YUV address. <br  />
 "blend_stitch_type" is used to specify blend stitch mode; the default is 0. 0: none; 1: horizontal; 2: vertical. <br  />
 </p><div class="fragment"><div class="line">canvas = {</div>
<div class="line">        {</div>
<div class="line">            type = <span class="stringliteral">&quot;encode&quot;</span>,</div>
<div class="line">            size = {4416, 1424},</div>
<div class="line">            <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> = {<span class="stringliteral">&quot;chan_0.main&quot;</span>, <span class="stringliteral">&quot;chan_1.main&quot;</span>},</div>
<div class="line">            extra_dram_buf = 0,</div>
<div class="line">            blend_stitch_type = 1,</div>
<div class="line">            blend_copy_num_minus_1 = 1,</div>
<div class="line">        },</div>
<div class="line">    }</div>
<div class="ttc" id="avin__init_8c_html_a07a87b2e6ed927503e2f95f119c9fc23"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a></div><div class="ttdeci">int source</div></div>
</div><!-- fragment --><p ><b>2. Dewarp</b> <br  />
 This step is used to remove lens distortion and reproject the image to the stitching view. As the Amareblla dewarp engine only supports 1D + 1D dewarp maps, the stitching library transfers 2D maps to 1D + 1D maps. </p><div class="fragment"><div class="line">Creating grid level 2D maps</div>
<div class="line">Board# test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 4 -f ./</div>
<div class="line"> </div>
<div class="line">Transfer to 1D + 1D maps and perform dewarp.</div>
<div class="line">Board# test_stitch --mode 2 -f . --no-overlap --fuse-<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> 15 --vertical (no overlap part)</div>
<div class="line">Board# test_stitch --mode 2 -f . --vertical (overlap)</div>
<div class="ttc" id="avin__init_8c_html_adf7dff2c57c0da9a4a2b70e3e815be31"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a></div><div class="ttdeci">int channel</div></div>
</div><!-- fragment --><p ><b>3. Refined tuning</b> <br  />
 This tool offers post adjustment for the horizontal and vertical offsets. </p><div class="fragment"><div class="line"><span class="stringliteral">&quot;-i&quot;</span> : Channel ID</div>
<div class="line"><span class="stringliteral">&quot;--adjust x,y&quot;</span> : (is used to adjust the offset of specified <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> with the</div>
<div class="line">unit of pixel, x &gt; 0: up, x &lt; 0 : down; y &gt; 0: right, y &lt; 0: left)</div>
<div class="line">Board # test_sensor_calib --mode 2 --channel-num 4 -f ./ -i 0 --adjust 3,-2</div>
<div class="line">Board # test_stitch --mode 2 -f . --no-overlap --fuse-channel 15 --vertical (no overlap part)</div>
<div class="line">Board # test_stitch --mode 2 -f . --vertical (overlap)</div>
</div><!-- fragment --><p ><b>4. Blending</b> <br  />
 1) The blend radius can be set using the "r" option; the default is "16". <br  />
 2) If the user wants to try the on the fly seam line, the algorithm uses motion to control the seam; "motion-r/motion-decide/motion-width/motion-height" options are used to control the motion. <br  />
 3) There are two types of dynamic seam methods: DP and GC. "seam-global / seam-shake / seam-bounce-w / seam-bounce-h" is used for the DP method in order to control the seam. <br  />
 4) If on the fly straight line is required rather than a seam line, "top / bottom" options can be used. "top" should be set as "x,0" and "bottom" should be set as "x,height", where x is the horizontal coordinate in the overlap area and the height is the overlap height.</p>
<h3><a class="anchor" id="stitch_pro_hor"></a>
2.5.3 Stitch in Horizontal Direction</h3>
<div class="image">
<img src="../../horizon_stitch.jpg" alt=""/>
<div class="caption">
Figure 2-8. Horizontal Stitching.</div></div>
<p> The command is as shown below: CV2x: <br  />
 </p><div class="fragment"><div class="line">board # init.sh --na;modprobe b5_imx290 <span class="keywordtype">id</span>=0x7 lane=3</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board # test_encode --resource-cfg ./cvxx_triple_4512x704_hor.lua  --enc-mode 5 --debug-stitch 1 -A --smaxsize 4512x704 --blend-stitch-type 1</div>
<div class="line">board # test_stitch --mode 2 -f /root</div>
<div class="line">board # test_stitch --mode 3 --overlap 0 --motion-w 70 -f /root</div>
</div><!-- fragment --><p >CV5x: <br  />
 </p><div class="fragment"><div class="line">board # modprobe ambrg</div>
<div class="line">board # modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8</div>
<div class="line">board # modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board # test_encode --resource-cfg ./cv5x_4_vin_4_chan_4k_encode_from_main_horizonal_stitch_in_row.lua</div>
<div class="line">board # test_stitch --mode 2 -f /root</div>
<div class="line">board # test_stitch --mode 3 --overlap 0 --motion-w 70 -f /root</div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_pro_ver"></a>
2.5.4 Stitch in Vertical Direction on CV2x</h3>
<div class="image">
<img src="../../vertical_stitch.jpg" alt=""/>
<div class="caption">
Figure 2-9. Vertical Stitching.</div></div>
<p> This is designed for the CV2x series of chips to perform stitching in the vertical direction. <br  />
 The flow of vertical stitching is shown in the image above; rotate the canvas to improve the view. The command to run the stitch is as shown below: </p><div class="fragment"><div class="line">board # init.sh --na &amp;&amp; modprobe imx335_mipi vinc_id=0xf1320 slave=1</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board # test_encode -i 0 --hdmi 480p --resource-cfg cvxx_quad_chan_5280x1856_ver_linear.lua --enc-mode 5 --blend-stitch-type 2</div>
<div class="line">board # test_encode -A -H 1856x5280 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 0 --rotate 1 -e -B -H 1856x5280 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 --rotate 1 -e</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 4 -f ./</div>
<div class="line">board # rtsp_server &amp;</div>
<div class="line">board # test_stitch --mode 2 -f . --no-overlap --fuse-<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> 15 --vertical (no overlap part)</div>
<div class="ttc" id="acJSON_8h_html_a1a175e87536301df98c805ac0636ad7c"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a></div><div class="ttdeci">const cJSON *const b</div><div class="ttdef"><b>Definition:</b> cJSON.h:255</div></div>
</div><!-- fragment --><p> <b>Linear line alpha blending</b> </p><div class="fragment"><div class="line">board # test_stitch --mode 3 --overlap 0 --top 120,0 --bottom 120,1856 -r 100 -B --top 160,0 --bottom 160,1856 -r 100 -C --top 112,1856 --bottom 112,1856 -r 100 --vertical</div>
</div><!-- fragment --><p> <b>Seam line alpha blending</b> </p><div class="fragment"><div class="line">board # test_stitch --mode 3 --overlap 0  --motion-width 10 --motion-height 10 --vertical</div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_pro_rotate"></a>
2.5.5 Stitch with Rotate Input on CV2x</h3>
<div class="image">
<img src="../../stitching_with_rotate_input_cv2x.jpg" alt=""/>
<div class="caption">
Figure 2-10. Stitching with Rotate Input.</div></div>
<p> This is designed for the CV2x series of chips to perform stitching in the vertical direction. <br  />
 In the example, the start of the frame is in the bottom left. A goal of this feature is to decrease the shutter time lag as much as possible between the two channels around the stitching line. Ambarella recommends installing sensors 1 and 3 with 180-degree rotation, so the stitching line between channel0 and channel1 are exposed at the first row, the stitching line between channel1 and channel2 are exposed at the last row, and the stitching line between channel2 and channel3 are exposed at the first row. The four sensors that run uniform auto exposure (AE) strategies for the same shutter / automatic gain control (AGC) configuration. The shutter time lag and the AGC of the first row (or the last row) from different sensors should be very close to each other, so the luma should also be very close. Configure the specific mirror type of the VSRC in the Lua script to orient images in the same direction.</p>
<p >The command to run the stitch is as shown below: </p><div class="fragment"><div class="line">(Do pose calibration on Host)</div>
<div class="line">host # save_target_info_4x_ver.bat</div>
<div class="line">host # specify_distance_4x_ver.bat</div>
<div class="line">board # init.sh --na; modprobe ambdd video_type=2 cap_cap_w=2688 cap_cap_h=3040 video_phase=3 video_yuv_mode=3 video_fps=17066667</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board(cv2x) # test_encode --resource-cfg cvxx_vin2_2688x1520_z116_m.lua --<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-capture 1 --enc-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-yuv 1</div>
<div class="line">--enc-mode 5 --blend-stitch-type 1</div>
<div class="line">board # test_efm -t 2 -i out16_m.yuv  -s 2688x3040 -T 1</div>
<div class="line">board # test_encode -A -h 5184x1456 -e</div>
<div class="line">board # rtsp_server&amp;</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 2 -f ./</div>
<div class="line">board # test_stitch --mode 2 -f /root --<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-encode-chan 2</div>
<div class="ttc" id="acJSON_8h_html_a788db922597cf2fb6389e278f822e59f"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div><div class="ttdeci">const char *const const char *const raw</div><div class="ttdef"><b>Definition:</b> cJSON.h:270</div></div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_channel_rotate"></a>
2.5.6 Stitch with Rotated Channels on CV5x</h3>
<p >This is designed for the CV5 series of chips to perform stitching in the vertical direction. <br  />
 </p><div class="image">
<img src="../../stitching_with_rotate_input_cv5x.jpg" alt=""/>
<div class="caption">
Figure 2-11. Stitching with Rotated Channels.</div></div>
<p> <br  />
 The image shows the design flow for Ambarella's reference demo. <br  />
 </p><div class="image">
<img src="../../stitch_rotate_hardware.jpg" alt=""/>
<div class="caption">
Figure 2-12. Stitching with Rotated Channels demo hardware.</div></div>
<p> <br  />
 The image shows the hardware design for Ambarella's reference board. <br  />
 Customers should configure it according to their hardware. <br  />
 In the stitching stage, the VSRC should be configured with the specific "mirror" type. <br  />
 The channels should be configured with the options "cw_rotate", "hflip", and "vflip" in the Lua. <br  />
 The example script is located in the path <code>ambarella\prebuild\library\multi_sensor_calib\dsp_v6\host_calib_tool\script\stitch\cv5x\ipc</code>. <br  />
 The command to run the stitch is as shown below: <br  />
 </p><div class="fragment"><div class="line">board # init.sh --na</div>
<div class="line">board # modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8</div>
<div class="line">board # modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">board # test_aaa_service -a &amp;</div>
<div class="line">(Capture images)</div>
<div class="line">board # test_encode --resource-cfg ./cv5x_4_vin_4_chan_1080p_encode_from_main_vertical_rotate.lua (1080p)</div>
<div class="line">board # test_encode --resource-cfg ./cv5x_4_4k_capture.lua (4k)</div>
<div class="line">board # test_encode -A -H 1080p -e -B -H 1080p -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e</div>
<div class="line">(Do pose calibration on Host)</div>
<div class="line">host # save_target_info_4x_ver_rotate.bat</div>
<div class="line">host # specify_distance_4x_ver_rotate.bat (<span class="stringliteral">&quot;cw_rotate&quot;</span> <span class="stringliteral">&quot;hflip&quot;</span> <span class="stringliteral">&quot;vflip&quot;</span> should be set as 1 in the ini file)</div>
<div class="line">(Do stitching)</div>
<div class="line">board # test_encode --resource-cfg ./cv5x_4_vin_4_chan_1080p_encode_from_main_horizonal_stitch_rotate_hvf.lua (1080p)</div>
<div class="line">board # test_encode --resource-cfg ./cv5x_4_4k_stitch_hvf.lua (4k)</div>
<div class="line">board # test_encode -A -H 1080p -e</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 4 -f ./</div>
<div class="line">board # test_stitch --mode 2 -f /root -i 0 --rotate-cw --hflip --vflip -i 1 --rotate-cw --hflip --vflip -i 2 --rotate-cw --hflip --vflip -i 3 --rotate-cw --hflip --vflip --vertical</div>
<div class="line">board # test_stitch --mode 3 --overlap 0 --top 30,0 --bottom 30,2880 --overlap 1 --top 30,0 --bottom 30,2880 --overlap 2 --top 30,0 --bottom 30,2880</div>
<div class="line">board # rtsp_server</div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_eight_channels_stitching"></a>
2.5.7 Stitch with Six / Eight Channels on CV5x</h3>
<p >This is designed for CV5 series of chips to perform stitching with six / eight channels. <br  />
 </p><div class="image">
<img src="../../8channel_stitching.jpg" alt=""/>
<div class="caption">
Figure 2-13. Stitching with Eight Channels.</div></div>
<p> <br  />
 Eight-channel stitching is used as an example. <br  />
 The image shows the canvas layout for Ambarella's reference board, including the calibration stage layout and stitching stage layout. <br  />
 Because there is a limitation of the coder / decoder (codec) stream width, the stitched buffers should be placed in two layers. <br  />
 After performing pose calibration, the message shown below appears: <br  />
 </p><div class="fragment"><div class="line">(Do pose calibration on Host)</div>
<div class="line">host # save_target_info_8x_hor.bat</div>
<div class="line">host # specify_distance_8x_hor.bat</div>
<div class="line"> </div>
<div class="line">Channel [0] Configuration :</div>
<div class="line">Buffer : output size [2176x960], zoom [1.378815, 1.378815]</div>
<div class="line">Canvas : Input : offset [0x0], size [2176x960], Output : offset [0x0], size [2176x960]</div>
<div class="line">Channel [1] Configuration :</div>
<div class="line">Buffer : output size [2176x960], zoom [1.378815, 1.378815]</div>
<div class="line">Canvas : Input : offset [0x0], size [2176x960], Output : offset [1280x0], size [2176x960]</div>
<div class="line">Channel [2] Configuration :</div>
<div class="line">Buffer : output size [2112x960], zoom [1.378815, 1.378815]</div>
<div class="line">Canvas : Input : offset [0x0], size [2112x960], Output : offset [2560x0], size [2112x960]</div>
<div class="line">Channel [3] Configuration :</div>
<div class="line">Buffer : output size [2176x960], zoom [1.378815, 1.378815]</div>
<div class="line">Canvas : Input : offset [0x0], size [2176x960], Output : offset [3904x0], size [2176x960]</div>
<div class="line">Channel [4] Configuration :</div>
<div class="line">Buffer : output size [2176x960], zoom [1.378815, 1.378815]</div>
<div class="line">Canvas : Input : offset [0x0], size [2176x960], Output : offset [5120x0], size [2176x960]</div>
<div class="line">Channel [5] Configuration :</div>
<div class="line">Buffer : output size [2304x960], zoom [1.378815, 1.378815]</div>
<div class="line">Canvas : Input : offset [0x0], size [2304x960], Output : offset [6336x0], size [2304x960]</div>
<div class="line">Channel [6] Configuration :</div>
<div class="line">Buffer : output size [2112x960], zoom [1.378815, 1.378815]</div>
<div class="line">Canvas : Input : offset [0x0], size [2112x960], Output : offset [7680x0], size [2112x960]</div>
<div class="line">Channel [7] Configuration :</div>
<div class="line">Buffer : output size [2112x960], zoom [1.378815, 1.378815]</div>
<div class="line">Canvas : Input : offset [0x0], size [2112x960], Output : offset [8896x0], size [2048x960]</div>
</div><!-- fragment --><p >When configuring the Lua, users must note the width change of channel3, Channel 3 width = channel_3_out_w - ((channel_3_out_x + channel_3_out_w) - (channel_7_out_x + channel_7_out_w - channel_4_out_x)) Channel 3 width = 2176 - ((3904 + 2176) - (8896 + 2048) - 5120). </p><div class="fragment"><div class="line">chan_3 = {</div>
<div class="line">    blend_left_or_top = 1,</div>
<div class="line">        blend_right_or_bot = 0,</div>
<div class="line">        <a class="code hl_function" href="../../dc/d60/test__smartfb_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a> = {</div>
<div class="line">            max_output = {2176, 960}, -- output width</div>
<div class="line">            input      = {0, 0, 0, 0}, -- full <a class="code hl_function" href="../../dc/d60/test__smartfb_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a></div>
<div class="line">            output     = {3904, 0, 1920, 960},</div>
<div class="line">        },</div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line">chan_4 = {</div>
<div class="line">        blend_left_or_top = 0,</div>
<div class="line">        blend_right_or_bot = 1,</div>
<div class="line">        <a class="code hl_function" href="../../dc/d60/test__smartfb_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a> = {</div>
<div class="line">            max_output = {2176, 960}, -- output width</div>
<div class="line">            input      = {0, 0, 0, 0}, -- full <a class="code hl_function" href="../../dc/d60/test__smartfb_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a></div>
<div class="line">            output     = {0, 960, 2176, 960},</div>
<div class="line">        },</div>
<div class="line">}</div>
<div class="ttc" id="atest__smartfb_8c_html_a3c04138a5bfe5d72780bb7e82a18e627"><div class="ttname"><a href="../../dc/d60/test__smartfb_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a></div><div class="ttdeci">int main(int argc, char **argv)</div><div class="ttdef"><b>Definition:</b> test_smartfb.c:1009</div></div>
</div><!-- fragment --><p> The example script is located in the path <code>ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/script/stitch</code>. <br  />
 The command to run the stitch is as shown below: <br  />
 </p><div class="fragment"><div class="line">(Do stitching)</div>
<div class="line">board # init.sh --na;modprobe max9296 <span class="keywordtype">id</span>=0x03030303 vinc_id=0x40b8</div>
<div class="line">board # modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">board # test_aaa_service -a &amp;</div>
<div class="line">board(cv5x) # test_encode --resource-cfg ./cv5x_8_vin_8_chan_1080p_encode_from_main_horizonal_stitch.lua</div>
<div class="line">board # test_encode -A -H 5824x1920 -e</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 8 -f ./</div>
<div class="line">board # test_stitch --mode 2 -f .</div>
<div class="line">board # test_stitch --mode 3 --overlap-<span class="keywordtype">id</span> 0 --top 100,0 --bot 100,960 --overlap-<span class="keywordtype">id</span> 1 --top 100,0 --bot 100,960</div>
<div class="line">    --overlap 2 --top 100,0 --bot 100,960 --overlap 3 --top 100,0  --bot 100,960 --overlap-<span class="keywordtype">id</span> 4 --top 100,0 --bot 100,960</div>
<div class="line">    --overlap-<span class="keywordtype">id</span> 5 --top 10,0 --bot 10,960 --overlap-<span class="keywordtype">id</span> 6 --top 100,960 --bot 100,960</div>
<div class="line">board # rtsp_server</div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_pro_dptz"></a>
2.5.8 Stitch Digital Pan / Tilt / Zoom on CV2x</h3>
<div class="image">
<img src="../../stitch_dptz.jpg" alt=""/>
<div class="caption">
Figure 2-14. Stitching DPTZ.</div></div>
<p> This is designed for the CV2x series chips. <br  />
 If the digital pan / tilt / zoom (DPTZ) is applied in one channel, users are required to only configure one channel. If the DPTZ is applied across more than one channel, users must configuration those channels accordingly. The features have been implemented in the test_multi_chan application. Another example of DPTZ within the stitched panorama view is shown in the image above. The bottom part is scaled from the stitched panorama view, and the top part is cropped and scaled from the stitched panorama view. The top part enables users to change the crop offset dynamically or on the fly. The command is as shown below: </p><div class="fragment"><div class="line">board # init.sh --na;modprobe b5_imx290 <span class="keywordtype">id</span>=0x7 lane=3</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board # test_encode --resource-cfg ./triple_chan_blend_4512x704_dptz.lua  --enc-mode 5 --debug-stitch 1 -A --smaxsize 4512x704 --blend-stitch-type 1</div>
<div class="line">board # test_encode -A -h 4512x704 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 -e</div>
<div class="line">board # rtsp_server&amp;</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 3 -f ./</div>
<div class="line">board # test_stitch --mode 2 -f /root</div>
<div class="line">board # test_stitch --mode 3 --overlap 0 --motion-w 70 -f /root</div>
<div class="line">board # test_multi_chan -L --cinoff 0x0 --cinsize 1920x700 --coutoffset 0x1328 --coutsize 1920x700</div>
<div class="line">board # test_stitch --mode 3 --overlap 0 --motion-w 10 --dptz-<span class="keyword">auto</span></div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_skip_blend"></a>
2.5.9 Stitch Skip Source Buffer Blend</h3>
<p >This is a flag to skip sub source buffer blend passes in stitching. The main buffer always has a blend pass; it cannot be skipped. It is only available when stitching is enabled. "srcbuf_to_skip_blend" is the configuration option in the Lua script. For example, the second source buffer is to set bit[1], the third source buffer is to set bit[2], and so on.</p>
<h3><a class="anchor" id="stitch_insert_pm"></a>
2.5.10 Stitch Privacy Mask</h3>
<p >The privacy mask (PM) is inserted in the VIN / main buffer domain. <br  />
 It can be added when LDC (lens-warp) is enabled. <br  />
 The application calculates the coordinates in the VIN domain according to the warp table. <br  />
 Users should refer to the Privacy Mask utility library (API: pm_fill_rect) to insert rectangular PMs: </p><div class="image">
<img src="../../rect_pm_w_jaggy.jpg" alt=""/>
<div class="caption">
Figure 2-15. Rectangle PM with Jaggy.</div></div>
<p> The image shows the rectangle performs normally in the LDC channel. </p><div class="image">
<img src="../../stitch_pm.jpg" alt=""/>
<div class="caption">
Figure 2-16. PM Layout.</div></div>
<p> If the PM is inserted in one channel, users are required to configure only one channel. If the PM is inserted across multiple channels, users configure those channels accordingly.</p>
<h3><a class="anchor" id="stitch_insert_blur"></a>
2.5.11 Stitch Blur on CV5x / CV72</h3>
<p >Blur is inserted in the canvas domain. It is allowed to insert one blur region across channel boundary onto the overlapped area. <br  />
 With the assumption that the left (or top) image and the right (or bottom) image have similar content in the overlapped area, DSP only takes one side's content as source image to calculate blur effect for the overlapped region. <br  />
 If the content in the overlapped region differs a lot, the blur result will mismatch with one side's content.</p>
<div class="image">
<img src="../../stitch_blur_mismatch.jpg" alt=""/>
<div class="caption">
Figure 2-17. Blur mismatch when overlap content differs.</div></div>
<h3><a class="anchor" id="stitch_pro_dual"></a>
2.5.12 Stitch Dual Fisheyes for 360-Degree Panorama</h3>
<div class="image">
<img src="../../dual_fisheye_panorama.jpg" alt=""/>
<div class="caption">
Figure 2-18. Stitching 360-Degree Panorama.</div></div>
<p> The flow of dual fisheye for 360-degree panorama stitching is shown in the image above. The output is a 360 x 180 degree panorama stitched view.</p>
<p >(1) Create panorama view with calibration. <br  />
 Lens calibration <br  />
 Ambarella suggests using the MEI fisheye calibration model to perform lens calibration. The command to run the lens calibration is as shown below: </p><div class="fragment"><div class="line">host # run_calib_chess_mei_yuv.bat</div>
</div><!-- fragment --><p >Pose calibration <br  />
 The following is an example to perform pose calibration for 2x 360-degree back-to-back fisheye stitching. <br  />
 Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_dual_fish">10. Dual-Fisheye Back-to-Back Pose Calibration</a> to learn the pose calibration process.</p>
<p >LDC / Dewarp <br  />
 1) Perform blending <br  />
 </p><div class="image">
<img src="../../fisheye_ldc.jpg" alt=""/>
<div class="caption">
Figure 2-19. Fisheye LDC.</div></div>
<p> Blending is only supported for mode 5, and between adjacent channels, users must use virtual channels for VINC0 to perform LDC. <br  />
 </p><div class="fragment"><div class="line">board # init.sh --na</div>
<div class="line">board # modprobe ambdd video_type=2 video_yuv_mode=3 video_fps=17066667 cap_cap_w=1600 cap_cap_h=2592</div>
<div class="line">board # test_aaa_service -a &amp;</div>
<div class="line">board # test_encode --resource-cfg cv2x_360_stitch_1600_1200_warp_3_chan_ldc_fisheye.lua --enc-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-yuv 1 --blend-stitch-type 1 --enc-mode 5</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 2 -f ./</div>
<div class="line">board # test_stitch --mode 2 -f ./ --dual-fisheye-ldc 1</div>
</div><!-- fragment --><p >2) No blending <br  />
 Mode 1 (dewarp) is used for this feature. There is no overlap region (blending) for two cameras at this stage. <br  />
 The command to run stitching is as shown below : <br  />
 </p><div class="fragment"><div class="line">board # init.sh --na</div>
<div class="line">board # modprobe b5_imx274 bus_addr=0x20000</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board # test_encode --resource cv2x_360_stitch_1920_1080_warp_b5_imx274.lua --enc-mode 1</div>
<div class="line">board # test_stitch --mode 2 -f /root --no-overlap</div>
</div><!-- fragment --><p >(2) Create panorama view without calibration (CV5x). <br  />
 Equirectangular projection is a representation of the sphere that maps longitude directly to the horizontal coordinate, and latitude to the vertical coordinate. <br  />
 It is commonly used as the projection type of the source images for spherical panorama viewers. <br  />
 The users can adjust the equirectangular projection paramters on the fly to stitch the images. <br  />
 The overlap area is specified by the user and they can do parameters adjustment to stitch the images. </p><div class="fragment"><div class="line">board # init.sh --na; modprobe ambds vin_virtual_flag=1 virtual_vsrc_num=2 custom_format_enable=1</div>
<div class="line">board # test_aaa_service -a &amp;</div>
<div class="line">board # test_encode --resource-cfg cv5x_dual_channel_encode_from_main_horizonal_stitch_without_calib.lua  --vout-cfg /usr/local/bin/scripts/vout_hdmi.lua --<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-capture 1 --enc-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-nv12 1</div>
<div class="line">board # test_efm -t 4 -i right.yuv  -s 1600x1296 -T 1 --vin-<span class="keywordtype">id</span> 15 (right.yuv <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a> is nv12)</div>
<div class="line">board # test_efm -t 4 -i left.yuv  -s 1600x1296 -T 1 --vin-<span class="keywordtype">id</span> 14 (left.yuv <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a> is nv12)</div>
<div class="line">board # test_encode -A -H 2944x1296 -e</div>
<div class="line">board # test_stitch --mode 2 --no-overlap --no-calib --dual-fisheye-ldc 2 --max-fov 200 --fish-radius 600 -i 0 --in-center 800,648</div>
<div class="line">--extend-output 1536,1296  --shift 768,0 -i 1 --in-center 800,648 --extend-output 1536,1296  --shift 0,0  --fuse 7 -i 2 --in-center 800,648</div>
<div class="line">--extend-output 1536,1296 --shift 0,0</div>
<div class="line">board # test_stitch --mode 3 --overlap-<span class="keywordtype">id</span> 0 --motion-width 10</div>
<div class="ttc" id="acJSON_8h_html_adb411a44855a4c49231d72a0fc9a3b3b"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a></div><div class="ttdeci">char const int const cJSON_bool format</div><div class="ttdef"><b>Definition:</b> cJSON.h:163</div></div>
</div><!-- fragment --><p >Options description : <br  />
 max-fov : FoV for lantitude-longitude frame. fish-radius : radius of fisheye, fixed by the parameter adjustment effect. in-center : coordinate in the input image, adjust the coordinates to shift the image. <br  />
 extend-output : resolution for latitude and longitude extend. <br  />
 fuse: dewarp channel id. 7 is for 3 channels. <br  />
 shift: shift the output image. <br  />
</p>
<h3><a class="anchor" id="stitch_backwarp_map"></a>
2.5.13 Stitch-Backward / Forward Mapping</h3>
<p >Stitch-backward mapping is used to map after LDC points to the VIN input domain. Stitch-forward mapping is used to map the points from the VIN input domain to the LDC domain. The command is as shown below: CV2xï¼š <br  />
 </p><div class="fragment"><div class="line">board # init.sh --na; modprobe b5_imx290 <span class="keywordtype">id</span>=0x7 lane=3</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board # test_encode --resource-cfg cvxx_triple_4512x704_hor.lua --enc-mode 5 --debug-stitch 1 --blend-stitch-type 1</div>
</div><!-- fragment --><p> Run mapping : <br  />
 </p><div class="fragment"><div class="line">board # test_stitch --mode 2 -f /root</div>
<div class="line">Stitch Backward Mapping:</div>
<div class="line">board # test_stitch --mode 0 -i 0 --map-point 441,210 -f /root -w 2560 -h 1440</div>
<div class="line"> </div>
<div class="line">Stitch Forward Mapping:</div>
<div class="line">board # test_stitch --mode 4 -i 0 --map-point 441,210 -f /root -w 2560 -h 1440</div>
<div class="line"> </div>
<div class="line">(441, 210 is the point of specific <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>, w / h is used to specify the VIN resolution.</div>
<div class="line">If the option <span class="stringliteral">&quot;fuse_method&quot;</span> is set to 2 in the pose calibration, changing width / height</div>
<div class="line">will not influence the result, becuase width / height will not be used in the formula.</div>
<div class="line">If the option <span class="stringliteral">&quot;fuse_method&quot;</span> is set to 0 in the pose calibration, changing width / height</div>
<div class="line">will influence the result, becuase width / height will be used in the formula.)</div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_simulation_efm"></a>
2.5.14 Stitch Simulation with EFM</h3>
<p >If LDC functions are applied to perform simulations, customers must run encode from RAW (EFR) processes. However, EFR only functions for single-VIN cases and takes RAW format. Customers must combine two RAW frames of data vertically into a single frame (n x 1080p -&gt; 1920 x (n x 1080). </p><div class="fragment"><div class="line">drv_modules  ---&gt;</div>
<div class="line">   <span class="keyword">private</span>  ---&gt;</div>
<div class="line">      -*- ambvideo-header (drv_modules/<span class="keyword">private</span>/video/dsp_v6)  ---&gt;</div>
<div class="line">                 (0x8200000)-&gt; IAV Usr Buffer Size</div>
</div><!-- fragment --><p> The command is as shown below: </p><div class="fragment"><div class="line">1. Prepare RAW data, and merge the data in the vertical direction. The input <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> of each RAW should be in the <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a> chan_x.raw.</div>
<div class="line">board # test_stitch --merge-num 2 --mode 1 -i 0 -w 2688 -h 1520 -i 1 -w 2688 -h 1520 --<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div>
<div class="line">2. Configure the Lua; each <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a><span class="stringliteral">&#39;s input offset should be changed accordingly.</span></div>
<div class="line"><span class="stringliteral">vsrc_0 = {</span></div>
<div class="line"><span class="stringliteral">    vsrc_id = 0,</span></div>
<div class="line"><span class="stringliteral">    mode = &quot;0&quot;,</span></div>
<div class="line"><span class="stringliteral">    hdr_mode = &quot;linear&quot;, -- options: &quot;linear&quot;, &quot;2x&quot; or &quot;3x&quot;</span></div>
<div class="line"><span class="stringliteral">    fps = 30,</span></div>
<div class="line"><span class="stringliteral">    bits= 0,</span></div>
<div class="line"><span class="stringliteral">}</span></div>
<div class="line"><span class="stringliteral"></span> </div>
<div class="line"><span class="stringliteral">....</span></div>
<div class="line"><span class="stringliteral">chan_0 = {</span></div>
<div class="line"><span class="stringliteral"> id = 0,</span></div>
<div class="line"><span class="stringliteral"> vsrc = vsrc_0,</span></div>
<div class="line"><span class="stringliteral"> main = {</span></div>
<div class="line"><span class="stringliteral">    max_output = {0, 0}, -- output width</span></div>
<div class="line"><span class="stringliteral">    input      = {0, 0, 2048, 1536},</span></div>
<div class="line"><span class="stringliteral">    output     = {0, 0, 2048, 1536},</span></div>
<div class="line"><span class="stringliteral"> },</span></div>
<div class="line"><span class="stringliteral">}</span></div>
<div class="line"><span class="stringliteral"></span> </div>
<div class="line"><span class="stringliteral">....</span></div>
<div class="line"><span class="stringliteral">chan_1 = {</span></div>
<div class="line"><span class="stringliteral"> id = 1,</span></div>
<div class="line"><span class="stringliteral"> vsrc = vsrc_0,</span></div>
<div class="line"><span class="stringliteral"> main = {</span></div>
<div class="line"><span class="stringliteral">    max_output = {0, 0}, -- output width</span></div>
<div class="line"><span class="stringliteral">    input      = {0, 1536, 2048, 1536},</span></div>
<div class="line"><span class="stringliteral">    output     = {0, 0, 1920, 1536},</span></div>
<div class="line"><span class="stringliteral"> },</span></div>
<div class="line"><span class="stringliteral">}</span></div>
<div class="line"><span class="stringliteral">.....</span></div>
<div class="line"><span class="stringliteral"></span> </div>
<div class="line"><span class="stringliteral">3. Perform RAW encode + stitching</span></div>
<div class="line"><span class="stringliteral">board # init.sh --na</span></div>
<div class="line"><span class="stringliteral">board # modprobe ambdd video_type=2 video_yuv_mode=3 video_fps=17066667 cap_cap_w=2048  cap_cap_h=3072</span></div>
<div class="line"><span class="stringliteral">board # test_aaa_service -a &amp;</span></div>
<div class="line"><span class="stringliteral">board(cv2x) # test_encode --resource-cfg cvxx.lua  --hdmi 720p --raw-capture 1 --enc-raw-rgb 1</span></div>
<div class="line"><span class="stringliteral">board # test_mempart -m 2 -s 0x8200000</span></div>
<div class="line"><span class="stringliteral">board # test_efm -t 3 -i out.raw  -s 2048x3072 -T 1</span></div>
<div class="line"><span class="stringliteral">board # test_sensor_calib --mode 2 --channel-num 2 -f ./</span></div>
<div class="line"><span class="stringliteral">board # test_stitch --mode 2 -f .</span></div>
<div class="ttc" id="acJSON_8h_html_a25d22ecc7e656d2c59332072684e8766"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a></div><div class="ttdeci">const char *const name</div><div class="ttdef"><b>Definition:</b> cJSON.h:264</div></div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_user_warp_alpha"></a>
2.5.15 Stitch with Users' Warp Table and Alpha Table</h3>
<ol type="1">
<li>If users want to use their own algorithms to perform calibrations and then apply them to the DSP, <br  />
 they must transform the OpenCV 2D warp table to a "1D + 1D" warp table. <br  />
 For 2D warp table details, refer to the Doxygen document (Dewarp Library API, 2.11 Transform 2D Vector to 1D+1D). <br  />
 <div class="fragment"><div class="line">board# test_ldc -c 0 -F 180 -R 910 -m 8 --twin-vec ./2D_vector.bin</div>
</div><!-- fragment --></li>
<li>If customers want to create their own alpha table and apply blending data, <br  />
 <code>test_stitch.c</code> is the reference application for this purpose. <br  />
 1) The function <code>do_vproc_ioctl()</code> is used to configure and perform blending. <br  />
 IAV_IOC_CFG_VIDEO_PROC is used to configure blend; the overlap information should be configured there. <br  />
 IAV_IOC_APPLY_VIDEO_PROC is used to apply blend. <br  />
 2) The formula is final_YUV = (chan_0 * alpha + chan_1 * (255 - alpha)) / 255. <br  />
 3) The alpha table format is shown as below: <br  />
 Channel 0, data is from 255 - 0 <br  />
 <div class="image">
<img src="../../channel_0_alpha_table.jpg" alt=""/>
<div class="caption">
Figure 2-20. Channel 0 Alpha Table Format.</div></div>
 Channel 1, data is from 0 - 255 <br  />
 <div class="image">
<img src="../../channel_1_alpha_table.jpg" alt=""/>
<div class="caption">
Figure 2-21. Channel 1 Alpha Table Format.</div></div>
</li>
</ol>
<h3><a class="anchor" id="stitch_update_warp_table"></a>
2.5.16 Stitch with Updating Warp Table on the Fly</h3>
<p >For video conference use cases, the distance between the users and the camera is very close and a large parallax issue will occur. This feature is designed to change the right channel's warp table and improve image alignment in the object's location. </p><div class="fragment"><div class="line">board# init.sh --na</div>
<div class="line">board# modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8</div>
<div class="line">board# modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">board# test_aaa_service -a &amp;</div>
<div class="line">board# test_encode --resource-cfg cvx_4k_stitch_4k_4hor_channel.lua</div>
<div class="line">board# test_stitch --mode 2 -f /root</div>
<div class="line">board# test_stitch --mode 3 --overlap-<span class="keywordtype">id</span> 0 -r 4 --top 160,0 --bot 160,1024  --update-overlap-content 2</div>
<div class="line">-f /root --overlap-<span class="keywordtype">id</span> 1 -r 4 --top 160,0 --bot 160,1024 --overlap-<span class="keywordtype">id</span> 2 -r 4 --top 160,0 --bot 160,1024</div>
<div class="line">--smooth-width 64 --skip-frame 2 --diff-thresh 2 --max-disparity 100 --stable-frame 2 --speed-mode 1</div>
</div><!-- fragment --><h3><a class="anchor" id="stitch_simulate_with_pose_results"></a>
2.5.17 Stitch Simulation with Pose Calibration Results</h3>
<p >The function <code>simulation_canvas_image_xx_xx.bat</code> demonstrates how to obtain the PC simulation results <br  />
 when users want to check the pose calibration results on the PC side, as well as the calibration quality. </p><div class="fragment"><div class="line">host# save_target_info_2x_hor.bat</div>
<div class="line">host# specify_distance_2x_hor.bat</div>
<div class="line">host# simulation_canvas_image_2x_hor.bat</div>
</div><!-- fragment --><p> The simulation results are stored in the path <code>example\2_hor\back_end</code>.</p>
<h3><a class="anchor" id="stitch_pro_tilt"></a>
2.5.18 Stitch in Horizontal Direction with Angles below the Horizon</h3>
<div class="image">
<img src="../../stitch_tilt.jpg" alt=""/>
<div class="caption">
Figure 2-22. Sensor Mounting with Angles below the Horizon.</div></div>
<p> <br  />
 The design of sensor mounting with angles below the horizon is shown in the image above. <br  />
 The four pinhole sensors should be placed with the same tilt angle. 25 degree is a commonly used value. <br  />
 Equirectangular projection across the horizon is used for this kind of product. <br  />
</p>
<p >Steps to perform stitching are as follows: <br  />
</p><ol type="1">
<li>Lens calibration <br  />
 Ambarella suggests using the pinhole calibration model to perform the lens calibration. The command to run the lens calibration is shown below: <div class="fragment"><div class="line">host # run_calib_chess_yuv.bat</div>
</div><!-- fragment --></li>
<li>Pose calibration <br  />
 The following is an example to perform pose calibration for 3x stitching with angles below the horizon. <br  />
 Ambarella suggests performing pose calibration with a chessboard. The option "no_dist_flag" should be set to 1, <br  />
 and "tilt_angle" should be set accordingly in the <code>.ini</code> configuration file. <br  />
 <div class="fragment"><div class="line">host # save_target_info_3x_hor_chess_tilt.bat</div>
<div class="line">host # specify_distance_3x_hor_chess_tilt.bat</div>
</div><!-- fragment --></li>
<li>LDC and blending <br  />
 <div class="fragment"><div class="line">board # init.sh --na</div>
<div class="line">board # modprobe ambrg</div>
<div class="line">board # modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8</div>
<div class="line">board # modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">board # test_aaa_service -a &amp;</div>
<div class="line">board # test_encode --resource-cfg cv5x_3_vin_3_chan_4k_encode_from_main_horizonal_stitch.lua --enc-mode 5</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 3 -f ./</div>
<div class="line">board # test_stitch --mode 2 -f ./</div>
<div class="line">board # test_stitch --mode 3 --overlap-<span class="keywordtype">id</span> 0 --motion-w 21</div>
</div><!-- fragment --></li>
</ol>
<h3><a class="anchor" id="stitch_pro_tilt_vhvh"></a>
2.5.19 Stitch in Vertical-Horizontal-Vertical-Horizontal Direction with Angles below the Horizon</h3>
<p >The vertical-horizontal-vertical-horizontal direction stitching is designed to combine 4 vertical-horizontal-vertical-horizontal direction channels into a 360-degree panorama view. <br  />
 </p><div class="image">
<img src="../../vhvh_tilt_stitching_input_output.jpg" alt=""/>
<div class="caption">
Figure 2-23. Input / Output in Vertical-Horizontal-Vertical-Horizontal Direction with Angles below the Horizon.</div></div>
<p> <br  />
 The input and output of vertical-horizontal-vertical-horizontal stitching is shown in the image above. <br  />
 </p><div class="image">
<img src="../../vhvh_tilt_stitching_design.jpg" alt=""/>
<div class="caption">
Figure 2-24. Sensor Mounting in Vertical-Horizontal-Vertical-Horizontal Direction with Angles below the Horizon.</div></div>
<p> <br  />
 The lens layout design of sensor mounting in vertical-horizontal-vertical-horizontal direction with angles below the horizon is shown in the image above. <br  />
 For the 4 channelsâ€™ sensor inputs, the ISP process order will be channel0-&gt;channel2-&gt;channel1-&gt;channel3. <br  />
 This is to ensure that the invalid area can be covered properly with the channels in higher Z-order. <br  />
 Step 1: for channel0, dewarp and rotate the output directly to main buffer canvas. <br  />
 Step 2: for channel2, dewarp and crop the output first (crop window is as below example), then rotate the output to main buffer canvas. <br  />
 Step 3: for channel1, dewarp and crop the output (crop window is as below example) to main buffer canvas. <br  />
 Step 4: for channel3, dewarp and crop the output (crop window is as below example) to main buffer canvas. <br  />
</p>
<p >Steps to perform stitching are as follows: <br  />
</p><ol type="1">
<li>Pose calibration <br  />
 <div class="image">
<img src="../../vhvh_tilt_stitching_config_ini.jpg" alt=""/>
<div class="caption">
Figure 2-25. Vertical-Horizontal-Vertical-Horizontal Stitching Pose Calibration File Configurations.</div></div>
 <br  />
 The following is an example to perform pose calibration for vertical-horizontal-vertical-horizontal stitching with angles below the horizon. <br  />
 The options <code>output_width/output_height/intrinsic/distortion/extrinsic/offset/resolution/top_fov/bot_fov</code> should be set accordingly in the <code>.ini</code> configuration file. <br  />
 The options descriptions are listed below : <br  />
 "output_width / output_height" is the width and height of the panorama view . <br  />
 "intrinsic" should be filled with lens calibration intrinsic parameters. <br  />
 "distortion" should be filled with lens calibration distortion parameters. <br  />
 "extrinsic" should be filled with pose calibration extrinsic parameters. <br  />
 "offset" should be filled with offset of the specific channel in the canvas (panaroma view). <br  />
 "resolution" should be filled with width / height of the specific channel in the canvas (panaroma view). <br  />
 "top_fov" is the FoV at the top of the panorama view. <br  />
 "bot_fov" is the FoV at the bottom of the panorama view. <br  />
 The methods to calculate some options are listed below : <br  />
 It is assumed "input_width" is 2304, "hfov" is 115, "top_fov" is 15, "bottom_fov" is -85. <div class="fragment"><div class="line">output_width = 360 * (input_width / hfov)</div>
<div class="line">output_height = (top_fov - bottom_fov) * (input_width / hfov))</div>
<div class="line">host # save_target_rotation_4m_85.bat</div>
<div class="line">host # create_map.bat</div>
</div><!-- fragment --></li>
<li>Multiple fisheye dewarp <br  />
 <div class="fragment"><div class="line">board # init.sh --na; modprobe ambds vin_virtual_flag=1 virtual_vsrc_num=8 custom_format_enable=1 yuv_mode=1</div>
<div class="line">board # test_aaa_service -a &amp;</div>
<div class="line">board # test_encode --resource-cfg motorola_stitching_efr_warp_al_new_bot_852_7212.lua   --enc-<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-nv12 1 --<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-capture 1 --chan-vcap-mode-enable 1</div>
<div class="line">board # sleep 0.5</div>
<div class="line">board # test_efm -t 4 -s 2592x1944 -i ./office-sensorImg0.yuv  -T 1 --vin-<span class="keywordtype">id</span> 14 &amp; test_efm -t 4 -s 2592x1944</div>
<div class="line">-i ./office-sensorImg1.yuv  -T 1 --vin-<span class="keywordtype">id</span> 15 &amp; test_efm -t 4 -s 2592x1944 -i ./office-sensorImg2.yuv</div>
<div class="line">-T 1 --vin-<span class="keywordtype">id</span> 16 &amp; test_efm -t 4 -s 2592x1944 -i ./office-sensorImg3.yuv  -T 1 --vin-<span class="keywordtype">id</span> 17&amp;</div>
<div class="line">board # test_encode -A -h 7168x1888 -<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 4 -e</div>
<div class="line">board # rtsp_server &amp;</div>
<div class="line">board # test_stitch --mode 2 -f /tmp/ --no-overlap --fuse 32 --skip-version --extra-height 16</div>
<div class="line">board # test_stitch --mode 2 -f /tmp/ --no-overlap --fuse 64 --skip-version   --extra-height 16</div>
<div class="line">board # test_stitch --mode 2 -f /tmp/ --no-overlap --fuse 16 -i4 -a 0 --rotate -H -V -a 1 -H -V</div>
<div class="line">-a 2 --expand-len 192 -a 3 --rotate -H -V --skip-version --extra-height 16</div>
<div class="line">board # test_stitch --mode 2 -f /tmp/ --no-overlap --fuse 128 -i7 -a 0 --rotate -H -V -a 1 --rotate -H -V --skip-version --extra-height 16</div>
</div><!-- fragment --></li>
</ol>
<hr  />
<h1><a class="anchor" id="sec_stitch_api"></a>
3. Stitch Application Programming Interface</h1>
<p >Visit the following link for details of the application programming interface (API) functions.</p><ul>
<li><a class="el" href="../../d2/dc5/group__lib-stitch-helper.html">STITCH Library API Helper</a> shows related macros and enumerations</li>
<li><a class="el" href="../../db/dd4/group__lib-stitch-api.html">STITCH Library API Detail</a> shows related APIs</li>
</ul>
<hr  />
<h1><a class="anchor" id="sec_stitch_faq"></a>
4. Stitch FAQ</h1>
<h2><a class="anchor" id="sec_stitch_faq_q1"></a>
Question 1: How can green artifacts in the overlap area be avoided?</h2>
<p ><b>Answer:</b> To ensure image quality in the overlap area, users must configure the Lua: <br  />
 enable_group = 1 <br  />
 If this issue still occurs, check the dmesg: <br  />
 dmesg -w | grep â€œraw data droppedâ€ <br  />
 </p><div class="image">
<img src="../../green_artifact.jpg" alt=""/>
<div class="caption">
Figure 4-1. Green Artifact.</div></div>
<h2><a class="anchor" id="sec_stitch_faq_q2"></a>
Question 2: When there are visible straight lines in sub-buffer stitching, but normal in main-buffer stitching, how can the lines be mitigated?</h2>
<p ><b>Answer:</b> To ensure image quality in the overlap area for sub-buffers, users must ensure that the zoom factor (width and height) is be the same for each buffer. It is necessary to use round_up to calculate the offset. </p><div class="image">
<img src="../../visible_straight_line.jpg" alt=""/>
<div class="caption">
Figure 4-2. Visible Straight Line for Sub Buffers Stitching.</div></div>
 <div class="fragment"><div class="line">Chan0</div>
<div class="line"><a class="code hl_function" href="../../dc/d60/test__smartfb_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a> <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a></div>
<div class="line"> input  = {0, 0, 2592, 1944},</div>
<div class="line"> output = {0, 0, 2624, 1632}</div>
<div class="line">sixth <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a></div>
<div class="line"> input  = {0, 0, 2624, 1632},</div>
<div class="line"> output = {0, 0, 672, 416},</div>
<div class="line"> </div>
<div class="line">Chan1</div>
<div class="line"><a class="code hl_function" href="../../dc/d60/test__smartfb_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a> <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a></div>
<div class="line"> input  = {0, 0, 2592, 1944},</div>
<div class="line"> output = {2432, 0, 2432, 1632},</div>
<div class="line">sixth <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a></div>
<div class="line"> input  = {0, 0, 2376, 1632},</div>
<div class="line"> output = {624, 0, 608, 416},</div>
<div class="line"> </div>
<div class="line">it is assumed ratio_x = 672 / 2624, ratio_y = 416 / 1632</div>
<div class="line">offset_x 624 = round_up(2432 * ratio_x, 4)</div>
<div class="line">input_width 2376 = round_up(608 / ratio_x, 4)</div>
<div class="ttc" id="acJSON_8h_html_aff2566f4c366b48d73479bef43ee4d2e"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a></div><div class="ttdeci">char * buffer</div><div class="ttdef"><b>Definition:</b> cJSON.h:163</div></div>
</div><!-- fragment --><h2><a class="anchor" id="sec_stitch_faq_q3"></a>
Question 3: How can artifacts in the horizontal and vertical directions after applying LDC be avoided?</h2>
<p ><b>Answer:</b> Users may encounter the banding problem as seen in</p><div class="image">
<img src="../../padding_artifact.jpg" alt=""/>
<div class="caption">
Figure 4-3. Padding-width Artifact.</div></div>
<p> To ensure image quality, users must increase the value of the option "max_padding_width" in the Lua: <br  />
 Users may encounter the artifact on the top lines of the channel as seen in</p><div class="image">
<img src="../../max_vwarp_wait_lines.jpg" alt=""/>
<div class="caption">
Figure 4-4. Vwarp Lines Artifact.</div></div>
<p> To ensure image quality, users must increase the value of the option "max_vwarp_wait_lines" in the Lua. There is no such problem in mode 5.</p>
<h2><a class="anchor" id="sec_stitch_faq_q4"></a>
Question 4: How is the warp table size reduced?</h2>
<p ><b>Answer:</b> The pose calibration configuration files are stored in the folder "back_end" and stored as "cali_warp_x". Users must create the 2D warp table using <br  />
 the application test_sensor_calib first. The full resolution 2D table will be downsampled with specific grid spacing in the horizontal and vertical directions. <br  />
 and stored as "undistort_x". Then users must create the 1D + 1D warp table by application "test_stitch". <br  />
 Users can increase values of the options â€œgrid-wâ€ and â€œgrid-hâ€ to reduce the size of "undistort_x".</p>
<h2><a class="anchor" id="sec_stitch_faq_q5"></a>
Question 5: How to capture images to avoid pose calibration fail?</h2>
<p ><b>Answer:</p><div class="image">
<img src="../../pose_error.jpg" alt=""/>
<div class="caption">
Figure 5-1. Detection Error.</div></div>
<p></b> Users may encounter the image detection failure problem in the pose calibration. The april tag ID is different for each tag. For pose calibration, the "share_id" in the .ini file is used to find the corresponding circle points of the specific channel image. <br  />
 To successfully detect the same ID tag and points, Ambarella suggests leaving at least three columns near the specified share ID inside the image, as shown in the green box. <br  />
 The first column should not exceed the image boundary.</p>
<h2><a class="anchor" id="sec_stitch_faq_q6"></a>
Question 6: How is the shared ID chosen?</h2>
<p >When running the bat of the calibration script, users can see the log below from the terminal. <br  />
 Users can then choose the ID that is common to the shared ID, and fill it in in the <code>.ini</code> file. </p><div class="fragment"><div class="line">read image 0</div>
<div class="line">Left tag <span class="keywordtype">id</span> 11, sid 1</div>
<div class="line">Left tag <span class="keywordtype">id</span> 11, sid 0</div>
<div class="line">vector 27.553820, 34.688438</div>
<div class="line">read image 1</div>
<div class="line">Left tag <span class="keywordtype">id</span> 11, sid 2</div>
<div class="line">Left tag <span class="keywordtype">id</span> 11, sid 3</div>
<div class="line">Left tag <span class="keywordtype">id</span> 11, sid 0</div>
<div class="line">Left tag <span class="keywordtype">id</span> 11, sid 1</div>
</div><!-- fragment --><p> share id is 0 / 1.</p>
<h2><a class="anchor" id="sec_stitch_faq_q7"></a>
Question 7: How is calibration data made compatible with the new SDK version?</h2>
<p >(1) Use "skip-version-check" in test_stitch to ignore the calibration file version difference, dynamic stitching is not supported for this method. <br  />
 </p><div class="fragment"><div class="line">board # test_stitch --mode 2 -f ./ --skip-version-check</div>
</div><!-- fragment --><p >(2) Redo calibration to create the new configuration file with old keypoints. <br  />
 When cameras have performed pose calibration in the old SDK version, and users want to upgrade to the latest-version calibration tool in the SDK, <br  />
 they are required to set the option "no_yuv" to 1 in the configuration file <code>sensor_calib_ini_pose_calibration_save_target_xx_xx.ini</code>, <br  />
 then run <code>save_target_info_xx_xx.bat</code> and <code>specify_distance_xx_xx.bat</code> again to create new configurations.</p>
<hr  />
<h1><a class="anchor" id="sec_stitch_lic"></a>
5. License</h1>
<p >Copyright (c) 2024 Ambarella International LP.</p>
<p >This file and its contents ( "Software" ) are protected by intellectual property rights including, without limitation, U.S. and/or foreign copyrights. This Software is also the confidential and proprietary information of Ambarella International LP and its licensors. You may not use, reproduce, disclose, distribute, modify, or otherwise prepare derivative works of this Software or any portion thereof except pursuant to a signed license agreement or nondisclosure agreement with Ambarella International LP or its authorized affiliates. In the absence of such an agreement, you agree to promptly notify and return this Software to Ambarella International LP.</p>
<p >THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL AMBARELLA INTERNATIONAL LP OR ITS AFFILIATES BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; COMPUTER FAILURE OR MALFUNCTION; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3 </li>
  </ul>
</div>
</body>
</html>
