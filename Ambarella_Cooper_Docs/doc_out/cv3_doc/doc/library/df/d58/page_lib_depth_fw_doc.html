<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Library: Depth Sensing Framework</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<link rel="search" href="../../search_opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Library"/>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  extensions: ["tex2jax.js"],
  jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="../../../library/mathjax/MathJax.js"></script>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-ambarella.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../Ambarella.png"/></td>
  <td id="projectalign">
   <div id="projectname">Library<span id="projectnumber">&#160;Cooper_1.6.0 (CV72 &amp; CV3) @ 2024.07.10 14:12:44</span>
   </div>
   <div id="projectbrief">placeholder</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,true,'search.html','Search');
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('df/d58/page_lib_depth_fw_doc.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">Depth Sensing Framework </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="depth_history"></a>
0. Revision History</h1>
<a class="anchor" id="lib_depth_framewrok_rev_history"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Updated Date </th><th align="left">Modification </th></tr>
<tr>
<td>20210312 </td><td>Initial Version </td></tr>
<tr>
<td rowspan="3">20210521 </td><td>1. Added support for dual frequency decode <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_dual_frequency_decoder">3.5.13 ToF Dual Frequency Decoding</a> </td></tr>
<tr>
<td>2. Added support for dtof mn34906 <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_input">3.5.1 ToF Process Input</a> </td></tr>
<tr>
<td>3. Added support for choosing points manually for ToF wiggling calibraiton <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_wiggle_calib">3.3.6 Wiggling Calibration</a> </td></tr>
<tr>
<td rowspan="3">20210603 </td><td>1. Added support for flying pixel removing <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_flying_pixel_removing">3.5.14 ToF Flying Pixel Removal</a> </td></tr>
<tr>
<td>2. Added support for converting depth image from 16 bit to three 8bit channels in JET mode <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_convert_depth">3.5.15 ToF Convert Depth Format</a> </td></tr>
<tr>
<td>3. Added support for ToF basic setting in menuconfig tof_pro_menu </td></tr>
<tr>
<td rowspan="3">20210628 </td><td>1. Added support for Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#sec_depth_disp_pc_on_ros">3. Display point cloud on ROS</a> </td></tr>
<tr>
<td>2. Added support for configuration files description <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_lc_explanation">1.7 Depth Sensing Framework Configuration Files Description</a> </td></tr>
<tr>
<td>3. Added support for supported sensor list <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_supported_sensor_list">3.2 Supported Sensor List</a> </td></tr>
<tr>
<td rowspan="2">20210906 </td><td>1. Added support for <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_rgb_registration_calib">3.3.7 ToF and RGB Sensors Registration Calibration</a> </td></tr>
<tr>
<td>2. Added support for <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_draw_osd">3.5.16 ToF Draw OSD</a> </td></tr>
<tr>
<td>20210927 </td><td>Update files for Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#sec_depth_disp_pc_on_ros">3. Display point cloud on ROS</a> </td></tr>
<tr>
<td rowspan="5">20211008 </td><td>1. Added DSF log system <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_log_system">1.5.1 Depth Sensing Framework Log System</a>, <br  />
performance profiling <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_performance_profiling">1.5.2 Depth Sensing Framework Performance Profiling</a>, <br  />
and diagnosis <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_diagnosis">1.5.3 Depth Sensing Framework Diagnosis</a> </td></tr>
<tr>
<td>2. Added DSF graph viewer <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_graph_viewer">1.6 Depth Sensing Framework Graph Viewer</a> </td></tr>
<tr>
<td>3. Added DSF run-time commands <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_runtime_commands">1.3.1 Depth Sensing Framework Run-time Commands</a>, <br  />
and add DSF example usage <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_example_usage">1.3.2 Depth Sensing Framework Example Usage</a> </td></tr>
<tr>
<td>4. Added DSF menuconfig description <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_required_menuconfig">1.1.5 Depth Sensing Framework Required Menuconfig</a>, <br  />
update DSF customization <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_customization">1.4 Depth Sensing Framework Customization</a> </td></tr>
<tr>
<td>5. Added DSF components <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_components">2. Components for Depth Sensing Framework</a> </td></tr>
<tr>
<td>20211102 </td><td>Added support for <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_temperature_calib">3.3.4 Temperature Offset Calibration</a> </td></tr>
<tr>
<td>20211119 </td><td>Added point cloud display tool on windows <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#sec_display_on_windows">5. Display Point Cloud on Windows</a> </td></tr>
<tr>
<td>20220112 </td><td>Added refinement for <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_calibration">3.3 ToF Calibration</a> </td></tr>
<tr>
<td>20220811 </td><td>Added cases for dual frequency mode calibration <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_calibration">3.3 ToF Calibration</a> </td></tr>
<tr>
<td>20230420 </td><td>Added Section of <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#sec_demo_app">6.Demo Application</a>, include <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#demo_visiond">6.1 CV22 Vision D EVK + IMX528</a> and <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#demo_cv25_adi3500">6.2 CV25_hazelnut + ADI3500 Sensor</a> </td></tr>
<tr>
<td>20230426 </td><td>Refine <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#demo_cv25_adi3500">6.2 CV25_hazelnut + ADI3500 Sensor</a> </td></tr>
<tr>
<td>20230605 </td><td>Added table <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#table_demo_adi3500_performance_cv5timn">The performance on CV5_timn</a> </td></tr>
<tr>
<td>20230619 </td><td>Added table <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#table_demo_adi3500_performance_cv2chestnut">The performance on CV2_chestnut</a>, update performance of enable cache. </td></tr>
<tr>
<td>20230817 </td><td>Added Section of <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#sec_depth_performance">7. Performance</a>, the performance of IMX528 and IRS2877C running on chip cv25/cv5/cv72 </td></tr>
<tr>
<td>20230913 </td><td>Updated supported sensor list <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_supported_sensor_list">3.2 Supported Sensor List</a> </td></tr>
<tr>
<td>20230918 </td><td>Added depth sensing framework software stack <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_software_stack">1.1.2 Depth Sensing Framework Software Stack</a> </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="depth_framework"></a>
1. Depth Sensing Framework</h1>
<ul>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_introduction">1.1 Depth Sensing Framework Introduction</a><ul>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_architecture">1.1.1 Depth Sensing Framework Architecture</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_typical_processing_flow">1.1.3 Depth Sensing Framework Typical Flow</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_code_hierarchy">1.1.4 Depth Sensing Framework Code Hierarchy</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_required_menuconfig">1.1.5 Depth Sensing Framework Required Menuconfig</a></li>
</ul>
</li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_programming_guide">1.2 Depth Sensing Framework Programming Guide</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_unit_test">1.3 Depth Sensing Framework Unit Test</a><ul>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_runtime_commands">1.3.1 Depth Sensing Framework Run-time Commands</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_example_usage">1.3.2 Depth Sensing Framework Example Usage</a></li>
</ul>
</li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_customization">1.4 Depth Sensing Framework Customization</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_profiling_and_debug">1.5 Depth Sensing Framework Profiling and Debug</a><ul>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_log_system">1.5.1 Depth Sensing Framework Log System</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_performance_profiling">1.5.2 Depth Sensing Framework Performance Profiling</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_diagnosis">1.5.3 Depth Sensing Framework Diagnosis</a></li>
</ul>
</li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_graph_viewer">1.6 Depth Sensing Framework Graph Viewer</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_lc_explanation">1.7 Depth Sensing Framework Configuration Files Description</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_api">1.8 Depth Sensing Framework API</a></li>
</ul>
<h2><a class="anchor" id="depth_framework_introduction"></a>
1.1 Depth Sensing Framework Introduction</h2>
<p >Ambarella depth sensing framework (DSF) is a framework for depth information processing, which is the basis of three-dimensional vision technology. The framework is designed to support various types of depth sensors, easy for extension and customization, lightweight and platform neutral, with highly optimized runtime performance. <br  />
</p>
<p >The framework does not bind to any specific depth technology, it can support 'time of flight (ToF)', 'stereo', and 'structured light'. <br  />
</p>
<h3><a class="anchor" id="depth_framework_architecture"></a>
1.1.1 Depth Sensing Framework Architecture</h3>
<p >In Ambarella depth sensing framework, the depth related processing are split into different stages. Upstream stage and downstream stage are connected by pins (input pin, output pin), and data are conveyed in pins. Each stage will employ a component to do the detailed processing. <br  />
</p>
<div class="image">
<img src="../../dsf_architecture.png" alt=""/>
<div class="caption">
Figure 1-1. Depth Sensing Framework Architecture.</div></div>
<p >The whole processing flow is described in a readable configuration string. The processing flow is a directed acyclic graph (DAG). Customers can easily modify the configurable string to set up a customized processing graph, according to their applications. <br  />
</p>
<p >During the processing, data is encapsulated in buffers. Buffers are managed by buffer pools, that means stage allocates a buffer from a buffer pool, uses it to convey data, and releases it to the buffer pool when the buffer is not needed. Considering there might be different data types in the whole processing graph, the framework introduces a domain concept, the stages in the same domain use the same type of data. Typically, there are three domains, the first one is for raw data, the second one is for depth / amplitude data, and the third one is for display. <br  />
</p>
<p >To achieve better run-time performance, the framework is able to enable "parallel computing", "chip acceleration", and "memory optimization". <br  />
</p>
<p >"Parallel computing" is automatically enabled when there are enough buffers between stages, different stages are running in data driven mode, different stages' processing can run simultaneously on different processors (digital signal processor (DSP), vector processor (VP), and Arm® cores). <br  />
</p>
<p >Ambarella SDK will provide acceleration libraries for the depth processing, such as lens distortion correction (LDC), iToF decoding, look-up table (LUT) based compensation, depth registration, and so on. <br  />
</p>
<p >About "memory optimization", the framework includes a small memory management module, which will try to allocate the memory buffer with physical continuous manner, so the GDMA engine can be used for some data copy. If multiple stages share the same input, they will also share the buffer without copy. <br  />
</p>
<h3><a class="anchor" id="depth_framework_software_stack"></a>
1.1.2 Depth Sensing Framework Software Stack</h3>
<p >The software stack diagram of the depth sensing framework is shown in <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#fig_dsf_software_stack">Figure 1-2</a>. The DSF can be running on AMBA SoC or other platforms, that rely on the dependencies of the component. For example, some filters in external component need OpenCV support; draw depth and amplitude in display component need VOUT support; and LDC in AMBA component depends on NNCtrl and VProc, NNCtrl and VProc need Cavalry device driver to enable the vector processor (VP); amba_phase_to_depth and amba_compensation depend on CV0 library. The send to ROS in the display component can send 3D point clouds and amplitudes to the PC, and these data can be displayed by amba_3dviewer or RViz. <a class="anchor" id="fig_dsf_software_stack"></a></p><div class="image">
<img src="../../fig_dsf_software_stack.jpg" alt=""/>
<div class="caption">
Figure 1-2. DSF Software Stack Diagram.</div></div>
<p> <br  />
</p>
<h3><a class="anchor" id="depth_framework_typical_processing_flow"></a>
1.1.3 Depth Sensing Framework Typical Flow</h3>
<p >Typically, there are three types of depth sensors, their processing flow are similar, with slight difference. Below will describe those three typical depth sensing scenarios. <br  />
</p>
<p ><b> iToF </b> <br  />
 iToF sensor outputs four phases raw data per frame for each modulation frequency, there are one or more decode stages, which convert phase into depth and amplitude (confidence), spatial and temporal filter stages can be applied on raw data. LDC and compensation stages are after the decode stage, then the depth / amplitude (confidence) are ready for application usage. In some scenarios, "flying pixel removal" and "hole filling" are also needed. Amplitude can be used for auto exposure (AE). Depth information can be displayed on TV (HDMI) or remote PC (ROS). On ROS, the depth information will be converted into point cloud information. <br  />
</p>
<div class="image">
<img src="../../typical_flow_itof.png" alt=""/>
<div class="caption">
Figure 1-3. Typical Flow of iToF.</div></div>
<p ><b> Structured Light </b> <br  />
 Structured light outputs a single frame, the block matching is applied on captured frame and a reference frame, then it outputs disparity. Disparity will be converted into depth information. Spatial and temporal filter stages can be applied on depth. Depth information can be displayed on TV (HDMI) or remote PC (ROS). On ROS, the depth information will be converted into point cloud information. <br  />
</p>
<div class="image">
<img src="../../typical_flow_of_structured_light.png" alt=""/>
<div class="caption">
Figure 1-4. Typical Flow of Structured Light.</div></div>
<p ><b> SW Stereo </b> <br  />
 There are two sensors in stereo, they will output two frames, the block matching is applied on those two captured frames, then it outputs disparity. Disparity will be converted into depth information. Spatial and temporal filter stages can be applied on depth. Depth information can be displayed on TV (HDMI) or remote PC (ROS). On ROS, the depth information will be converted into point cloud information. <br  />
</p>
<div class="image">
<img src="../../typical_flow_of_sw_stereo.png" alt=""/>
<div class="caption">
Figure 1-5. Typical Flow of SW Stereo.</div></div>
<p> <br  />
</p>
<h3><a class="anchor" id="depth_framework_code_hierarchy"></a>
1.1.4 Depth Sensing Framework Code Hierarchy</h3>
<p >The source code location is under <code>ambarella/packages/depth_sensing_framework</code>, subfolder content are listed below. <br  />
</p>
<ul>
<li><b> conf </b> Example of graph configuration string <br  />
</li>
<li><b> doc </b> Simple help file <br  />
</li>
<li><b> example_components </b> Example customized components <br  />
</li>
<li><b> include </b> Header file for interface <br  />
</li>
<li><b> internal_include </b> Header file for internal usage <br  />
</li>
<li><b> ros </b> ROS setup guide and ROS display app source code <br  />
</li>
<li><b> scripts </b> Example scripts to set up depth sensors <br  />
</li>
<li><b> source </b> Source files of the framework <br  />
<ul>
<li><b> source/components </b> Embedded components <br  />
</li>
<li><b> source/data_io </b> Data io <br  />
</li>
<li><b> source/graph </b> Framework code about the processing graph <br  />
</li>
<li><b> source/iav_al </b> IAV abstraction layer <br  />
</li>
<li><b> source/lc_config </b> Configuration string (.lc file) parsing <br  />
</li>
<li><b> source/platform_al </b> Platform abstraction layer <br  />
</li>
<li><b> source/text_io </b> Text io for string parsing <br  />
</li>
<li><b> source/utility </b> Utility functions <br  />
</li>
</ul>
</li>
<li><b> tools </b> Tools for the framework <br  />
</li>
<li><b> unit_test </b> Unit test of the framework <br  />
</li>
</ul>
<hr  />
<h3><a class="anchor" id="depth_framework_required_menuconfig"></a>
1.1.5 Depth Sensing Framework Required Menuconfig</h3>
<p >First of all, select the depth sensing framework under <code>ambarella/packages</code>. </p><div class="fragment"><div class="line">-&gt; Ambarella Package Configuration  ---&gt;</div>
<div class="line">   [*]Build Ambarella Depth Sensing Framework  ---&gt;</div>
</div><!-- fragment --><p >Then select needed components under each category, by default, most of them are selected. </p><div class="fragment"><div class="line">-&gt; Ambarella Package Configuration  ---&gt;</div>
<div class="line">   [*]Build Ambarella Depth Sensing Framework  ---&gt;</div>
<div class="line">       [*]   Build Ambarella accelerated components <span class="keywordflow">for</span> DSF  ---&gt;</div>
<div class="line">       [*]   Build c components <span class="keywordflow">for</span> DSF  ---&gt;</div>
<div class="line">       [*]   Build by <span class="keyword">extern</span> lib components <span class="keywordflow">for</span> DSF  ---&gt;</div>
<div class="line">       [*]   Build display components <span class="keywordflow">for</span> DSF  ---&gt;</div>
<div class="line">       [*]   Build example customized components <span class="keywordflow">for</span> DSF  ---&gt;</div>
</div><!-- fragment --><p >There are some other menuconfigs needed to be updated. One is that users should select correct time of fly (ToF) sensors and RGB sensors. </p><div class="fragment"><div class="line">-&gt; Ambarella Linux Configuration  ---&gt;</div>
<div class="line">   [*]   Ambarella Private Drivers Configuration  ---&gt;</div>
<div class="line">       [*]   Build Ambarella <span class="keyword">private</span> Vin modules  ---&gt;</div>
<div class="line">           [*]   Ambarella TOF Sensor Configuration  ---&gt;</div>
<div class="line">               [*] Sony IMX316 43.2K TOF sensor(MIPI)</div>
<div class="line">               [*] Sony IMX456 0.3M TOF sensor(MIPI)</div>
<div class="line">               [*] Sony IMX528 0.3M TOF sensor(MIPI)</div>
<div class="line">               [*] Panasonic MN34906 0.3M TOF sensor(MIPI)</div>
<div class="line">               [*] Infineon IRS2877C 0.3M TOF sensor(MIPI)</div>
</div><!-- fragment --><p >Select RGB sensors for example. </p><div class="fragment"><div class="line">-&gt; Ambarella Linux Configuration  ---&gt;</div>
<div class="line">   [*]   Ambarella Private Drivers Configuration  ---&gt;</div>
<div class="line">       [*]   Build Ambarella <span class="keyword">private</span> Vin modules  ---&gt;</div>
<div class="line">           [*]   Ambarella Sensor Configuration  ---&gt;</div>
<div class="line">               [*] Sony IMX327 2.13M CMOS sensor(Serial LVDS)</div>
<div class="line">               [*] Sony IMX327 2.13M CMOS sensor(MIPI)</div>
</div><!-- fragment --><p >Since some scenarios need three channels: ToF sensor, RGB sensor, and raw encode. So it is better to change the maximum channel to 4. </p><div class="fragment"><div class="line">-&gt; Ambarella Linux Configuration  ---&gt;</div>
<div class="line">   [*]   Ambarella Private Drivers Configuration  ---&gt;</div>
<div class="line">       [*]   Define Common Macros  ---&gt;</div>
<div class="line">           (4)   Max VIN Channel Number</div>
</div><!-- fragment --><p >Change image data distributed method to be ROBOT type. </p><div class="fragment"><div class="line">-&gt; Ambarella Prebuild  ---&gt;</div>
<div class="line">   [*]   Configure to include Ambarella Image Data  ---&gt;</div>
<div class="line">       [*]   Configure Ambarella Image Data Method  ---&gt;</div>
<div class="line">           [*]   Select to Ambarella Image Data in distributed method.  ---&gt;</div>
<div class="line">               [*]   Select to Ambarella Image Data ROBOT type</div>
</div><!-- fragment --><hr  />
<h2><a class="anchor" id="depth_framework_programming_guide"></a>
1.2 Depth Sensing Framework Programming Guide</h2>
<p >There are few application programming interface (APIs) of depth sensing framework listed below, refer to <code><a class="el" href="../../d3/dfc/amba__dsf__if_8h.html">ambarella/packages/depth_sensing_framework/include/amba_dsf_if.h</a></code> <br  />
</p>
<p >Setup processing graph, the graph description is readable string (graph_info) </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> <a class="code hl_function" href="../../de/dd6/group__dsf-api-flow.html#ga99114dbd89dea820555dd7a52d33f088">dsf_graph_setup</a>(<a class="code hl_struct" href="../../d3/d7c/structdsf__graph__t.html">dsf_graph_t</a> *p_graph,</div>
<div class="line">  <span class="keyword">const</span> <a class="code hl_struct" href="../../da/d46/structdsf__prerequisites__t.html">dsf_prerequisites_t</a> *p_prerequisites,</div>
<div class="line">  <span class="keyword">const</span> <span class="keywordtype">char</span> *graph_info, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> info_len,</div>
<div class="line">  <a class="code hl_struct" href="../../d0/dd9/structdsf__component__proto__t.html">dsf_component_proto_t</a> *customized_component_list,</div>
<div class="line">  <span class="keywordtype">unsigned</span> <span class="keywordtype">char</span> *p_ext_mem, <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> ext_mem_size);</div>
<div class="ttc" id="agroup__dsf-api-flow_html_ga99114dbd89dea820555dd7a52d33f088"><div class="ttname"><a href="../../de/dd6/group__dsf-api-flow.html#ga99114dbd89dea820555dd7a52d33f088">dsf_graph_setup</a></div><div class="ttdeci">EXPORT_DSF_API int dsf_graph_setup(dsf_graph_t *p_graph, const dsf_prerequisites_t *p_prerequisites, const char *graph_info, unsigned int info_len, dsf_component_proto_t *customized_component_list, unsigned char *p_ext_mem, unsigned int ext_mem_size)</div><div class="ttdoc">setup DSF graph conext</div></div>
<div class="ttc" id="astructdsf__component__proto__t_html"><div class="ttname"><a href="../../d0/dd9/structdsf__component__proto__t.html">dsf_component_proto_t</a></div><div class="ttdef"><b>Definition:</b> amba_dsf_if.h:352</div></div>
<div class="ttc" id="astructdsf__graph__t_html"><div class="ttname"><a href="../../d3/d7c/structdsf__graph__t.html">dsf_graph_t</a></div><div class="ttdef"><b>Definition:</b> amba_dsf_if.h:394</div></div>
<div class="ttc" id="astructdsf__prerequisites__t_html"><div class="ttname"><a href="../../da/d46/structdsf__prerequisites__t.html">dsf_prerequisites_t</a></div><div class="ttdoc">prequisites information, read only and volatile, typically those information are set at setup stage,...</div><div class="ttdef"><b>Definition:</b> amba_dsf_if.h:289</div></div>
</div><!-- fragment --><p >Clean processing graph </p><div class="fragment"><div class="line">void (*clean)(<span class="keyword">struct </span>dsf_graph_s *p_graph);</div>
</div><!-- fragment --><p >Start processing </p><div class="fragment"><div class="line">int (*start_loop)(<span class="keyword">struct </span>dsf_graph_s *p_graph,</div>
<div class="line">    <span class="keywordtype">unsigned</span> <span class="keywordtype">int</span> end_stage_index);</div>
</div><!-- fragment --><p >Stop processing </p><div class="fragment"><div class="line">int (*stop_loop)(<span class="keyword">struct </span>dsf_graph_s *p_graph);</div>
</div><!-- fragment --><p ><br  />
 The graph needs some prerequisites Setup prerequisites </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> <a class="code hl_function" href="../../de/dd6/group__dsf-api-flow.html#ga74c25597b5f150910908e81d460b902b">dsf_prerequisites</a>(<a class="code hl_struct" href="../../dd/da0/structdsf__option__t.html">dsf_option_t</a> *option,</div>
<div class="line">  <a class="code hl_struct" href="../../da/d46/structdsf__prerequisites__t.html">dsf_prerequisites_t</a> *p_prerequisites);</div>
<div class="ttc" id="agroup__dsf-api-flow_html_ga74c25597b5f150910908e81d460b902b"><div class="ttname"><a href="../../de/dd6/group__dsf-api-flow.html#ga74c25597b5f150910908e81d460b902b">dsf_prerequisites</a></div><div class="ttdeci">EXPORT_DSF_API int dsf_prerequisites(dsf_option_t *option, dsf_prerequisites_t *p_prerequisites)</div><div class="ttdoc">setup prerequisites</div></div>
<div class="ttc" id="astructdsf__option__t_html"><div class="ttname"><a href="../../dd/da0/structdsf__option__t.html">dsf_option_t</a></div><div class="ttdef"><b>Definition:</b> amba_dsf_if.h:374</div></div>
</div><!-- fragment --><p >Clean prerequisites </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> <a class="code hl_function" href="../../de/dd6/group__dsf-api-flow.html#ga6f843de808f14493ad1e8098df303a7d">dsf_clean_prerequisites</a>(</div>
<div class="line">  <a class="code hl_struct" href="../../da/d46/structdsf__prerequisites__t.html">dsf_prerequisites_t</a> *p_prerequisites);</div>
<div class="ttc" id="agroup__dsf-api-flow_html_ga6f843de808f14493ad1e8098df303a7d"><div class="ttname"><a href="../../de/dd6/group__dsf-api-flow.html#ga6f843de808f14493ad1e8098df303a7d">dsf_clean_prerequisites</a></div><div class="ttdeci">EXPORT_DSF_API void dsf_clean_prerequisites(dsf_prerequisites_t *p_prerequisites)</div><div class="ttdoc">clean prerequisites</div></div>
</div><!-- fragment --><p ><br  />
 Below are utility APIs <br  />
 Get a version </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> <a class="code hl_function" href="../../df/d42/group__dsf-api-utility.html#gae7f298ae73e0d401598f5666726bcb17">dsf_get_version</a>(<a class="code hl_struct" href="../../d5/dd9/structdsf__version__t.html">dsf_version_t</a> *version);</div>
<div class="ttc" id="agroup__dsf-api-utility_html_gae7f298ae73e0d401598f5666726bcb17"><div class="ttname"><a href="../../df/d42/group__dsf-api-utility.html#gae7f298ae73e0d401598f5666726bcb17">dsf_get_version</a></div><div class="ttdeci">EXPORT_DSF_API void dsf_get_version(dsf_version_t *version)</div><div class="ttdoc">get version of DSF</div></div>
<div class="ttc" id="astructdsf__version__t_html"><div class="ttname"><a href="../../d5/dd9/structdsf__version__t.html">dsf_version_t</a></div><div class="ttdef"><b>Definition:</b> amba_dsf_if.h:519</div></div>
</div><!-- fragment --><p> <br  />
 Set a log level </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> <a class="code hl_function" href="../../df/d42/group__dsf-api-utility.html#ga2754ceae218c31485921eead199b1017">dsf_set_log_level</a>(<span class="keywordtype">int</span> log_level);</div>
<div class="ttc" id="agroup__dsf-api-utility_html_ga2754ceae218c31485921eead199b1017"><div class="ttname"><a href="../../df/d42/group__dsf-api-utility.html#ga2754ceae218c31485921eead199b1017">dsf_set_log_level</a></div><div class="ttdeci">EXPORT_DSF_API void dsf_set_log_level(int log_level)</div><div class="ttdoc">set log level for DSF</div></div>
</div><!-- fragment --><p> <br  />
 Set a log file name </p><div class="fragment"><div class="line"><span class="keywordtype">int</span> <a class="code hl_function" href="../../df/d42/group__dsf-api-utility.html#gacec355b53d5f7c2ca359d16dafbee72e">dsf_set_log_file_name</a>(<span class="keyword">const</span> <span class="keywordtype">char</span> *log_file_name);</div>
<div class="ttc" id="agroup__dsf-api-utility_html_gacec355b53d5f7c2ca359d16dafbee72e"><div class="ttname"><a href="../../df/d42/group__dsf-api-utility.html#gacec355b53d5f7c2ca359d16dafbee72e">dsf_set_log_file_name</a></div><div class="ttdeci">EXPORT_DSF_API int dsf_set_log_file_name(const char *log_file_name)</div><div class="ttdoc">set log file name for DSF</div></div>
</div><!-- fragment --><p> <br  />
 Set a log file name </p><div class="fragment"><div class="line"><span class="keywordtype">void</span> <a class="code hl_function" href="../../df/d42/group__dsf-api-utility.html#gaa9595785fac89ec688a72d29d10f4da9">dsf_print_errcode</a>(<span class="keywordtype">int</span> code);</div>
<div class="ttc" id="agroup__dsf-api-utility_html_gaa9595785fac89ec688a72d29d10f4da9"><div class="ttname"><a href="../../df/d42/group__dsf-api-utility.html#gaa9595785fac89ec688a72d29d10f4da9">dsf_print_errcode</a></div><div class="ttdeci">EXPORT_DSF_API void dsf_print_errcode(int code)</div><div class="ttdoc">print detailed error code information</div></div>
</div><!-- fragment --><p> Get an error code string </p><div class="fragment"><div class="line"><span class="keyword">const</span> <span class="keywordtype">char</span> *<a class="code hl_function" href="../../df/d42/group__dsf-api-utility.html#gafaf0ba4398eb284cc1fd324bb1d33fac">dsf_get_errcode_string</a>(<span class="keywordtype">int</span> code);</div>
<div class="ttc" id="agroup__dsf-api-utility_html_gafaf0ba4398eb284cc1fd324bb1d33fac"><div class="ttname"><a href="../../df/d42/group__dsf-api-utility.html#gafaf0ba4398eb284cc1fd324bb1d33fac">dsf_get_errcode_string</a></div><div class="ttdeci">EXPORT_DSF_API const char * dsf_get_errcode_string(int code)</div><div class="ttdoc">get readable string about return code for DSF</div></div>
</div><!-- fragment --><hr  />
<h2><a class="anchor" id="depth_framework_unit_test"></a>
1.3 Depth Sensing Framework Unit Test</h2>
<p >Source code here: ambarella/packages/depth_sensing_framework/unit_test/test_amba_dsf.c test command line </p><div class="fragment"><div class="line">./test_amba_dsf ../conf/dsf_dummy_c.lc --loglevel 7</div>
</div><!-- fragment --><hr  />
<h3><a class="anchor" id="dsf_runtime_commands"></a>
1.3.1 Depth Sensing Framework Run-time Commands</h3>
<p >DSF can support run-time commands. There are three typical command handlers in DSF: the unit test (test_amba_dsf), the graph, and each component. Below is the current supported run-time command list:</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Command   </th><th class="markdownTableHeadCenter">Parameter Type   </th><th class="markdownTableHeadCenter">Description   </th><th class="markdownTableHeadCenter">Handler Type    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">h   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Help   </td><td class="markdownTableBodyCenter">test_amba_dsf    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">q   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Quit   </td><td class="markdownTableBodyCenter">test_amba_dsf    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">p   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Prints the performance profiling   </td><td class="markdownTableBodyCenter">test_amba_dsf    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">s   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Prints run-time status of stages   </td><td class="markdownTableBodyCenter">test_amba_dsf    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">log level   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Changes the log level   </td><td class="markdownTableBodyCenter">Graph    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">print memory   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Enables/Disables print data statistics in memory   </td><td class="markdownTableBodyCenter">Graph    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">print stages   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Print stages in graph   </td><td class="markdownTableBodyCenter">Graph    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">bypass   </td><td class="markdownTableBodyCenter">stage_name + integer   </td><td class="markdownTableBodyCenter">Bypass stage or not   </td><td class="markdownTableBodyCenter">Graph    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">idle   </td><td class="markdownTableBodyCenter">stage_name + integer   </td><td class="markdownTableBodyCenter">Idle stage or not   </td><td class="markdownTableBodyCenter">Graph    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">reset profiling   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Reset profiling   </td><td class="markdownTableBodyCenter">Graph    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">print depth   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Prints the depth or not   </td><td class="markdownTableBodyCenter">Component (phase_to_depth)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">print conf   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Prints the amplitude (confidence) or not   </td><td class="markdownTableBodyCenter">Component (phase_to_depth)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">gt depth   </td><td class="markdownTableBodyCenter">float   </td><td class="markdownTableBodyCenter">Specifies the depth's ground truth   </td><td class="markdownTableBodyCenter">Component (phase_to_depth)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">cap ply   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Capture the ply file   </td><td class="markdownTableBodyCenter">Component (phase_to_depth)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">dump depth_amp   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Dumps the depth and amplitude data   </td><td class="markdownTableBodyCenter">Component (phase_to_depth)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">iir order   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Specifies the IIR order   </td><td class="markdownTableBodyCenter">Component (temporal_filter)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">decay_a   </td><td class="markdownTableBodyCenter">float   </td><td class="markdownTableBodyCenter">Specifies the decay_a   </td><td class="markdownTableBodyCenter">Component (temporal_filter)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">decay_b   </td><td class="markdownTableBodyCenter">float   </td><td class="markdownTableBodyCenter">Specifies the decay_b   </td><td class="markdownTableBodyCenter">Component (temporal_filter)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">decay_ab   </td><td class="markdownTableBodyCenter">float   </td><td class="markdownTableBodyCenter">Specifies the decay_ab   </td><td class="markdownTableBodyCenter">Component (temporal_filter)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">decay_a   </td><td class="markdownTableBodyCenter">float   </td><td class="markdownTableBodyCenter">Specifies the decay_a   </td><td class="markdownTableBodyCenter">Component (temporal_filter)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">cap raw   </td><td class="markdownTableBodyCenter">none   </td><td class="markdownTableBodyCenter">Captures the raw   </td><td class="markdownTableBodyCenter">Component (itof_sensor_input)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">print temper   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Prints the temperature or not   </td><td class="markdownTableBodyCenter">Component (itof_sensor_input)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">check conf   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Checks the confidence or not   </td><td class="markdownTableBodyCenter">Component (compensation)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">conf threshold   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Specifies the confidence threshold   </td><td class="markdownTableBodyCenter">Component (compensation)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">crop depth   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Crops the depth or not   </td><td class="markdownTableBodyCenter">Component (compensation)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">enable ldc   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Enables the LDC or not   </td><td class="markdownTableBodyCenter">Component (ldc)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">dec method   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Specifies the decode method   </td><td class="markdownTableBodyCenter">Component (dual_freq_decoder)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">remove_thr   </td><td class="markdownTableBodyCenter">float   </td><td class="markdownTableBodyCenter">Specifies the flying pixel removal threshold   </td><td class="markdownTableBodyCenter">Component (flying_pixel_removal)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">rm invalid   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Specifies the removing invalid depth threshold   </td><td class="markdownTableBodyCenter">Component (flying_pixel_removal)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">conf th   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Specifies the confidence threshold   </td><td class="markdownTableBodyCenter">Component (flying_pixel_removal)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c   </td><td class="markdownTableBodyCenter">integer   </td><td class="markdownTableBodyCenter">Sets the folder number for calibration data   </td><td class="markdownTableBodyCenter">Component (idsp_phase_ir)   </td></tr>
</table>
<hr  />
<h3><a class="anchor" id="dsf_example_usage"></a>
1.3.2 Depth Sensing Framework Example Usage</h3>
<p >The needed .lc files can be found under <code>ambarella/packages/depth_sensing_framework/conf</code> The needed script, lua file, and compensation file can be found at <code>ambarella/packages/depth_sensing_framework/scripts</code> and <code>ambarella/prebuild/ambarella/library/amba_tof/board</code>. <br  />
</p>
<p >Below are some example usages.</p>
<p >Without a real sensor, the user can run with a dummy lc file </p><div class="fragment"><div class="line">./test_amba_dsf ../conf/dsf_dummy_c.lc --loglevel 7</div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<p >With a IMX528 sensor Prerequisites </p><div class="fragment"><div class="line">./run_tof_528.sh</div>
<div class="line">or</div>
<div class="line">./run_tof_528_efm.sh</div>
</div><!-- fragment --><p> <br  />
</p>
<p >Run with sunny optical IMX528 module </p><div class="fragment"><div class="line">test_amba_dsf dsf_imx528_amba_120m_sun.lc --loglevel 7</div>
</div><!-- fragment --><p >Run with sunny optical IMX528 module, with flying pixel removal </p><div class="fragment"><div class="line">test_amba_dsf dsf_imx528_amba_120m_sun_fpr.lc --loglevel 7</div>
</div><!-- fragment --><p >Run with sunny optical IMX528 module, with yolov5 and draw yolov5 detection result on Linux frame buffer </p><div class="fragment"><div class="line">test_amba_dsf dsf_imx528_amba_120m_sun_yolov5_fb.lc --loglevel 7</div>
</div><!-- fragment --><p >Run with sunny optical IMX528 module, with yolov5 and draw yolov5 detection result into EFM </p><div class="fragment"><div class="line">test_amba_dsf dsf_imx528_amba_120m_sun_yolov5_efm.lc --loglevel 7</div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<p >Run with polight IMX528 module </p><div class="fragment"><div class="line">test_amba_dsf dsf_imx528_amba_120m_polig.lc --loglevel 7</div>
</div><!-- fragment --><p >Run with polight IMX528 module, with flying pixel removal </p><div class="fragment"><div class="line">test_amba_dsf dsf_imx528_amba_120m_polig_fpr.lc --loglevel 7</div>
</div><!-- fragment --><p >Run with IMX528 module, do not involve any post-processing for calibration </p><div class="fragment"><div class="line">test_amba_dsf dsf_imx528_amba_120m_dec_for_calib.lc --loglevel 7</div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<p >With a IRS2877c sensor Prerequisites </p><div class="fragment"><div class="line">./run_tof_irs2877c.sh</div>
</div><!-- fragment --><p> <br  />
</p>
<p >Run with IRS2877c module, dual frequency </p><div class="fragment"><div class="line">test_amba_dsf dsf_irs2877c_amba_dual.lc --loglevel 7</div>
</div><!-- fragment --><p >Run with IRS2877c module, dual frequency, with flying pixel removal </p><div class="fragment"><div class="line">test_amba_dsf dsf_irs2877c_amba_dual_fpr.lc --loglevel 7</div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<p >Get run-time performance</p>
<div class="fragment"><div class="line">test_amba_dsf dsf_irs2877c_amba_dual_fpr.lc</div>
</div><!-- fragment --><p> Users enter 'p' + ENTER, then may see performance information of each stages, as shown below. First line, there is an "average fps", which means average fps of the graph (from this stage's observation). Second line, there is a "average proc time" of this stage, and a theoretical maximum fps "maximum stage fps" for this stage. Third line, there is a "total frame num", which records how many frames was processed by this stage in the past. </p><div class="fragment"><div class="line">stage[itof_sensor_input, amba_itof_sensor_input] profiling: average FPS 30.318455</div>
<div class="line">        stage average proc time 32975711 ns, 32.975712 ms, maximum stage FPS 30.325350</div>
<div class="line">        total frame num 80, total msg num 79</div>
<div class="line">        processing time 2638056906 ns, percentage 0.999775</div>
<div class="line">        wait data time 0 ns, percentage 0.000000</div>
<div class="line">        wait out <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> time 594873 ns, percentage 0.000225</div>
<div class="line">stage[cal_depth_amp, amba_itof_decoder] profiling: average FPS 29.937582</div>
<div class="line">        stage average proc time 25541148 ns, 25.541149 ms, maximum stage FPS 39.152508</div>
<div class="line">        total frame num 79, total msg num 158</div>
<div class="line">        processing time 2017750762 ns, percentage 0.766316</div>
<div class="line">        wait data time 615058617 ns, percentage 0.233592</div>
<div class="line">        wait out <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> time 242305 ns, percentage 0.000092</div>
<div class="ttc" id="acJSON_8h_html_aff2566f4c366b48d73479bef43ee4d2e"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a></div><div class="ttdeci">char * buffer</div><div class="ttdef"><b>Definition:</b> cJSON.h:163</div></div>
</div><!-- fragment --><p> <br  />
</p>
<p >To get the theoretical maximum speed without VIN sensor fps limitation, users can type 'idle itof_sensor_input 1' + ENTER, and type 'reset profiling' + ENTER. Then users will see the maximum process speed without VIN sensor fps limitation. <br  />
</p>
<hr  />
<p >Get depth statistics (depth precision and accuracy)</p>
<div class="fragment"><div class="line">test_amba_dsf dsf_irs2877c_amba_dual_fpr.lc</div>
</div><!-- fragment --><p> Users enter 'gt depth 0.53' + ENTER, then may see depth statistics information, as shown below. It will print AVG depth for each frame, and will print statistics for every 100 frames. Users can find the depth precision and accuracy after entering the ground truth depth. To disable depth statistics print, users can enter 'print depth 0' + ENTER. </p><div class="fragment"><div class="line">depth: AVG 0.533714</div>
<div class="line">depth: AVG 0.533302</div>
<div class="line">depth: AVG 0.533500</div>
<div class="line">depth: AVG 0.533515</div>
<div class="line">depth: AVG 0.533654, STD_DERV 0.000247, precision 0.000464, GT 0.530000, MAE 0.003654, RMSE 0.003662, accuracy 0.006910</div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<p >Get help on run-time command</p>
<div class="fragment"><div class="line">test_amba_dsf dsf_irs2877c_amba_dual_fpr.lc</div>
</div><!-- fragment --><p> Users enter 'h' + ENTER, then may see help information for run-time commands, as shown below. </p><div class="fragment"><div class="line">test_amba_dsf runtime commands</div>
<div class="line">    <span class="charliteral">&#39;q&#39;</span> or <span class="stringliteral">&#39;quit&#39;</span> + ENTER: quit</div>
<div class="line">    <span class="charliteral">&#39;s&#39;</span> or <span class="stringliteral">&#39;status&#39;</span> + ENTER: print Status</div>
<div class="line">    <span class="charliteral">&#39;p&#39;</span> or <span class="stringliteral">&#39;profiling&#39;</span> + ENTER: print performance Profiling</div>
<div class="line">    <span class="stringliteral">&#39;log level %%d&#39;</span> + ENTER: set log level</div>
<div class="line">    <span class="stringliteral">&#39;print memory %%d&#39;</span> + ENTER: print memory 0 or 1</div>
<div class="line">    <span class="stringliteral">&#39;print stages&#39;</span> + ENTER: print stages</div>
<div class="line">    <span class="stringliteral">&#39;print depth %%d&#39;</span> + ENTER: print depth 0 or 1</div>
<div class="line">    <span class="stringliteral">&#39;print conf %%d&#39;</span> + ENTER: print confidence (amplitude) 0 or 1</div>
<div class="line">    <span class="stringliteral">&#39;gt depth %%f&#39;</span> + ENTER: enter ground truth depth, to print depth_error information</div>
<div class="line">    <span class="stringliteral">&#39;cap ply&#39;</span> + ENTER: capture a ply file</div>
<div class="line">    <span class="stringliteral">&#39;dump depth_amp&#39;</span> + ENTER: dump depth and amplitude</div>
<div class="line">    <span class="stringliteral">&#39;bypass %%s %%d&#39;</span> + ENTER: bypass stage, 0 means no, 1 means yes</div>
<div class="line">    <span class="stringliteral">&#39;idle %%s %%d&#39;</span> + ENTER: idle stage, 0 means no, 1 means yes</div>
<div class="line">    <span class="stringliteral">&#39;reset profiling&#39;</span> + ENTER: reset profiling</div>
<div class="line">    <span class="stringliteral">&#39;iir order %%d&#39;</span> + ENTER: set IIR order</div>
<div class="line">    <span class="stringliteral">&#39;decay_a %%f&#39;</span> + ENTER: set decay a</div>
<div class="line">    <span class="stringliteral">&#39;decay_b %%f&#39;</span> + ENTER: set decay <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a></div>
<div class="line">    <span class="stringliteral">&#39;decay_ab %%f&#39;</span> + ENTER: set decay ab</div>
<div class="line">    <span class="stringliteral">&#39;cap raw&#39;</span> + ENTER: capture <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div>
<div class="line">    <span class="stringliteral">&#39;print temper %%d&#39;</span> + ENTER: print temperature or not</div>
<div class="line">    <span class="stringliteral">&#39;check conf %%d&#39;</span> + ENTER: check confidence or not</div>
<div class="line">    <span class="stringliteral">&#39;conf threshold %%f&#39;</span> + ENTER: confidence threshold</div>
<div class="line">    <span class="stringliteral">&#39;crop depth %%d&#39;</span> + ENTER: crop depth or not</div>
<div class="line">    <span class="stringliteral">&#39;enable ldc %%d&#39;</span> + ENTER: enable ldc or not</div>
<div class="line">    <span class="stringliteral">&#39;dec method %%d&#39;</span> + ENTER: set dec method</div>
<div class="line">    <span class="stringliteral">&#39;remove_thr %%f&#39;</span> + ENTER: set flying pixel removal threshold</div>
<div class="line">    <span class="stringliteral">&#39;rm invalid %%d&#39;</span> + ENTER: enable/disable remove invalid depth</div>
<div class="line">    <span class="stringliteral">&#39;conf th %%d&#39;</span> + ENTER: set confidence threshold</div>
<div class="line">    <span class="stringliteral">&#39;c %%d&#39;</span> + ENTER: set folder <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a01b4671c6b7cc8f831c951c000a37735">number</a> <span class="keywordflow">for</span> calibrition data</div>
<div class="line">    <span class="stringliteral">&#39;sub bg %%d&#39;</span> + ENTER: enable/disable substract background <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a></div>
<div class="line">    <span class="charliteral">&#39;h&#39;</span> or <span class="stringliteral">&#39;help&#39;</span> + ENTER: print Help</div>
<div class="line">    ENTER: execute last command</div>
<div class="ttc" id="acJSON_8h_html_a01b4671c6b7cc8f831c951c000a37735"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a01b4671c6b7cc8f831c951c000a37735">number</a></div><div class="ttdeci">const char *const const double number</div><div class="ttdef"><b>Definition:</b> cJSON.h:268</div></div>
<div class="ttc" id="acJSON_8h_html_a1a175e87536301df98c805ac0636ad7c"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a></div><div class="ttdeci">const cJSON *const b</div><div class="ttdef"><b>Definition:</b> cJSON.h:255</div></div>
<div class="ttc" id="acJSON_8h_html_a788db922597cf2fb6389e278f822e59f"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div><div class="ttdeci">const char *const const char *const raw</div><div class="ttdef"><b>Definition:</b> cJSON.h:270</div></div>
<div class="ttc" id="avin__init_8c_html_adf7dff2c57c0da9a4a2b70e3e815be31"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a></div><div class="ttdeci">int channel</div></div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<p >Bypass a stage</p>
<div class="fragment"><div class="line">test_amba_dsf dsf_irs2877c_amba_dual_fpr.lc</div>
</div><!-- fragment --><p> Users enter 'bypass flying_pixel_removal 1' + ENTER, then may bypass stage (flying_pixel_removal). Users can check whether there is difference between bypass and not bypass stage (flying_pixel_removal). If users want to re-enable this bypassed stage, they can enter 'bypass flying_pixel_removal 0' + ENTER. <br  />
</p>
<hr  />
<p >Print stages in graph</p>
<div class="fragment"><div class="line">test_amba_dsf dsf_irs2877c_amba_dual_fpr.lc</div>
</div><!-- fragment --><p> Users enter 'print stages' + ENTER, then test_amba_dsf will print stage connections, as shown below. For each stage, those information are printed: its domain, upstream stage, and bypass or not, and so on. </p><div class="fragment"><div class="line">print stages</div>
<div class="line">stage [itof_sensor_input, amba_itof_sensor_input, 0], its domain [<a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>]:</div>
<div class="line">        bypass 0</div>
<div class="line">stage [cal_depth_amp, amba_itof_decoder, 1], its domain [depth_amplitude]:</div>
<div class="line">        upstream[0]: [itof_sensor_input]</div>
<div class="line">        bypass 0</div>
<div class="line">stage [compensation, amba_compensation, 2], its domain [depth_amplitude]:</div>
<div class="line">        upstream[0]: [cal_depth_amp]</div>
<div class="line">        bypass 0</div>
<div class="line">stage [ae, amba_ae, 3], its domain [depth_amplitude]:</div>
<div class="line">        upstream[0]: [cal_depth_amp]</div>
<div class="line">        bypass 0</div>
<div class="line">stage [ldc, amba_ldc, 4], its domain [depth_amplitude]:</div>
<div class="line">        upstream[0]: [compensation]</div>
<div class="line">        bypass 0</div>
<div class="line">stage [flying_pixel_removal, amba_flying_pixel_removal, 5], its domain [depth_amplitude]:</div>
<div class="line">        upstream[0]: [ldc]</div>
<div class="line">        bypass 0</div>
<div class="line">stage [phase_to_depth, amba_phase_to_depth, 6], its domain [depth_amplitude]:</div>
<div class="line">        upstream[0]: [flying_pixel_removal]</div>
<div class="line">        bypass 0</div>
<div class="line">stage [draw, draw_depth, 7], its domain [depth_amplitude]:</div>
<div class="line">        upstream[0]: [phase_to_depth]</div>
<div class="line">        bypass 0</div>
<div class="line">stage [ros, send_to_ros, 8], its domain [depth_amplitude]:</div>
<div class="line">        upstream[0]: [phase_to_depth]</div>
<div class="line">        bypass 0</div>
<div class="line">handle cmd (print stages) done</div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<p >Print stage's run-time status</p>
<div class="fragment"><div class="line">test_amba_dsf dsf_irs2877c_amba_dual_fpr.lc</div>
</div><!-- fragment --><p> Users enter 's' + ENTER, then test_amba_dsf will print each stage's run-time status, as shown below. For each stage, those information are printed: its state, number of buffers on input pin, number of buffers on output pin, and number of free buffers in the buffer pool, etc. </p><div class="fragment"><div class="line">stage[itof_sensor_input, amba_itof_sensor_input] status: 4, Wait Outbuf</div>
<div class="line">stage[itof_sensor_input, amba_itof_sensor_input] <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> status:</div>
<div class="line">        num in output pin: 0</div>
<div class="line">        num in <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> pool: 2</div>
<div class="line"> </div>
<div class="line">stage[cal_depth_amp, amba_itof_decoder] status: 3, Wait Data</div>
<div class="line">stage[cal_depth_amp, amba_itof_decoder] <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> status:</div>
<div class="line">        num in input pin[0]: 0</div>
<div class="line">        num in output pin: 0</div>
<div class="line">        num in <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> pool: 2</div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<h2><a class="anchor" id="depth_framework_customization"></a>
1.4 Depth Sensing Framework Customization</h2>
<p >The framework is designed to be flexible, that means the customer is able to add their own component as they wish. There are two approaches to add a new component. The first one adds a new component in <code>ambarella/packages/depth_sensing_framework/source/components</code>, and adds its prototype into component_factory.c, the other one is a write component externally, and imports the customized component list when the appication invokes <a class="el" href="../../de/dd6/group__dsf-api-flow.html#ga99114dbd89dea820555dd7a52d33f088" title="setup DSF graph conext">dsf_graph_setup()</a>. <br  />
</p>
<p >In addition, the framework also supports customized "configurable string" in .lc file, for the new component, this is convenient for people who do not want to touch DSF library. <br  />
</p>
<p >There are some example customized components, under the folder example_components. Take Yolov5 as an example, implement the create_func, proc_func, and destroy_func in yolov5.c.</p>
<div class="fragment"><div class="line"><a class="code hl_struct" href="../../d0/dd9/structdsf__component__proto__t.html">dsf_component_proto_t</a> proto_test_yolov5 = {</div>
<div class="line">    .<a class="code hl_variable" href="../../d0/dd9/structdsf__component__proto__t.html#ae858b286673aebe6387585f9832fb201">stage_name</a> = <span class="stringliteral">&quot;vca&quot;</span>,</div>
<div class="line">    .component_name = <span class="stringliteral">&quot;od_yolov5&quot;</span>,</div>
<div class="line"> </div>
<div class="line">    .create_func = yolov5_create,</div>
<div class="line">    .proc_func = yolov5_proc,</div>
<div class="line">    .destroy_func = yolov5_destroy,</div>
<div class="line">};</div>
<div class="ttc" id="astructdsf__component__proto__t_html_ae858b286673aebe6387585f9832fb201"><div class="ttname"><a href="../../d0/dd9/structdsf__component__proto__t.html#ae858b286673aebe6387585f9832fb201">dsf_component_proto_t::stage_name</a></div><div class="ttdeci">const char * stage_name</div><div class="ttdef"><b>Definition:</b> amba_dsf_if.h:353</div></div>
</div><!-- fragment --><p> <br  />
</p>
<p >Add od_yolov5 into customized component list, in customized_component_factory.c.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#ifdef BUILD_DSF_COMPONENT_OD_YOLOV5</span></div>
<div class="line"><span class="keyword">extern</span> <a class="code hl_struct" href="../../d0/dd9/structdsf__component__proto__t.html">dsf_component_proto_t</a> proto_test_yolov5;</div>
<div class="line"><span class="preprocessor">#endif</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#ifdef BUILD_DSF_COMPONENT_OD_YOLOV5</span></div>
<div class="line">        __add_component_proto_into_emd_list(&amp;proto_test_yolov5);</div>
<div class="line"><span class="preprocessor">#endif</span></div>
</div><!-- fragment --><p> <br  />
</p>
<p >Handle customized property in .lc file for this customized component.</p>
<div class="fragment"><div class="line"><span class="keywordflow">if</span> (!strcmp(p_cur_pty-&gt;name, <span class="stringliteral">&quot;i&quot;</span>)) {</div>
<div class="line">    snprintf(thiz-&gt;input_dir, <span class="keyword">sizeof</span>(thiz-&gt;input_dir), <span class="stringliteral">&quot;%s&quot;</span>, p_cur_pty-&gt;value);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!strcmp(p_cur_pty-&gt;name, <span class="stringliteral">&quot;o&quot;</span>)) {</div>
<div class="line">    snprintf(thiz-&gt;output_dir, <span class="keyword">sizeof</span>(thiz-&gt;output_dir), <span class="stringliteral">&quot;%s&quot;</span>, p_cur_pty-&gt;value);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!strcmp(p_cur_pty-&gt;name, <span class="stringliteral">&quot;model&quot;</span>)) {</div>
<div class="line">    snprintf(thiz-&gt;model_path, <span class="keyword">sizeof</span>(thiz-&gt;model_path), <span class="stringliteral">&quot;%s&quot;</span>, p_cur_pty-&gt;value);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!strcmp(p_cur_pty-&gt;name, <span class="stringliteral">&quot;type&quot;</span>)) {</div>
<div class="line">    thiz-&gt;model_type = p_cur_pty-&gt;value[0];</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!strcmp(p_cur_pty-&gt;name, <span class="stringliteral">&quot;f&quot;</span>)) {</div>
<div class="line">    thiz-&gt;conf_threshold = atof(p_cur_pty-&gt;value);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!strcmp(p_cur_pty-&gt;name, <span class="stringliteral">&quot;nms&quot;</span>)) {</div>
<div class="line">    thiz-&gt;nms_threshold = atof(p_cur_pty-&gt;value);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!strcmp(p_cur_pty-&gt;name, <span class="stringliteral">&quot;top_k&quot;</span>)) {</div>
<div class="line">    thiz-&gt;top_k = atoi(p_cur_pty-&gt;value);</div>
<div class="line">} <span class="keywordflow">else</span> <span class="keywordflow">if</span> (!strcmp(p_cur_pty-&gt;name, <span class="stringliteral">&quot;u&quot;</span>)) {</div>
<div class="line">    thiz-&gt;use_multi_cls = atoi(p_cur_pty-&gt;value);</div>
<div class="line">}</div>
</div><!-- fragment --><p> <br  />
</p>
<p >Edit the .lc file to add the customized stage / component into gragh.</p>
<div class="fragment"><div class="line">Stage</div>
<div class="line"> <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> = vca</div>
<div class="line"> component = od_yolov5</div>
<div class="line"> domain = rgb</div>
<div class="line"> <a class="code hl_variableRef" target="_blank" href="../../../video/d9/dd6/overlay__cfg_8c.html#afd064c95beb16fddfd1fbf3754b12739">buffer_num</a> = 3</div>
<div class="line"> upstream_stage = normalization_jet</div>
<div class="line"> bypass = 0</div>
<div class="line"> i = ./nn/in/</div>
<div class="line"> o = ./nn/out/</div>
<div class="line"> model = ./nn/model/</div>
<div class="line"> type = s</div>
<div class="line"> f = 0.2</div>
<div class="line"> <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.3</div>
<div class="line"> top_k = 100</div>
<div class="line"> u = 0</div>
<div class="ttc" id="acJSON_8h_html_a25d22ecc7e656d2c59332072684e8766"><div class="ttname"><a href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a></div><div class="ttdeci">const char *const name</div><div class="ttdef"><b>Definition:</b> cJSON.h:264</div></div>
<div class="ttc" id="agroup__cavalry__opt__layers-api-details_html_gaaebc4f5976b0ca899e54fa28ee499eb2"><div class="ttname"><a href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a></div><div class="ttdeci">AMBA_API int nms(OUT half *out, IN half *in, IN int in_count, IN float iou_thresh, IN int out_lim)</div></div>
<div class="ttc" id="aoverlay__cfg_8c_html_afd064c95beb16fddfd1fbf3754b12739"><div class="ttname"><a href="../../../video/d9/dd6/overlay__cfg_8c.html#afd064c95beb16fddfd1fbf3754b12739">buffer_num</a></div><div class="ttdeci">int buffer_num</div></div>
</div><!-- fragment --><p> <br  />
</p>
<p >Also add a new domain if the customized stage / component needs.</p>
<div class="fragment"><div class="line">Domain</div>
<div class="line"> <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> = rgb</div>
<div class="line"> <a class="code hl_variableRef" target="_blank" href="../../../video/d9/dd6/overlay__cfg_8c.html#afd064c95beb16fddfd1fbf3754b12739">buffer_num</a> = 4</div>
<div class="line"> alignment = 64</div>
<div class="line"> image_num = 1</div>
<div class="line"> Image</div>
<div class="line">  channel_num = 3</div>
<div class="line">  channel_interleave = 0</div>
<div class="line">  pixel_fmt = <a class="code hl_typedef" href="../../d2/d47/asf__structure_8h.html#a92c50087ca0e64fa93fc59402c55f8ca">u8</a></div>
<div class="ttc" id="aasf__structure_8h_html_a92c50087ca0e64fa93fc59402c55f8ca"><div class="ttname"><a href="../../d2/d47/asf__structure_8h.html#a92c50087ca0e64fa93fc59402c55f8ca">u8</a></div><div class="ttdeci">uint8_t u8</div><div class="ttdef"><b>Definition:</b> asf_structure.h:44</div></div>
</div><!-- fragment --><p> <br  />
</p>
<p >Finally, pass the customized components list to <a class="el" href="../../de/dd6/group__dsf-api-flow.html#ga99114dbd89dea820555dd7a52d33f088" title="setup DSF graph conext">dsf_graph_setup()</a>, then the customized stage / component is enabled in DSF.</p>
<div class="fragment"><div class="line">ret = <a class="code hl_function" href="../../de/dd6/group__dsf-api-flow.html#ga99114dbd89dea820555dd7a52d33f088">dsf_graph_setup</a>(&amp;graph,</div>
<div class="line">    &amp;prerequisites,</div>
<div class="line">    (<span class="keyword">const</span> <span class="keywordtype">char</span> *) graph_info, info_len,</div>
<div class="line">    setup_module_proto_customized_list(),</div>
<div class="line">    prerequisites.mem_info.p_virt_mem_base,</div>
<div class="line">    prerequisites.mem_info.tot_mem_size);</div>
</div><!-- fragment --><p> <br  />
</p>
<hr  />
<h2><a class="anchor" id="depth_framework_profiling_and_debug"></a>
1.5 Depth Sensing Framework Profiling and Debug</h2>
<h3><a class="anchor" id="dsf_log_system"></a>
1.5.1 Depth Sensing Framework Log System</h3>
<p >There is a log system, users can set the log level and output log to a file or a console. Users can use "--loglevel" to specify the log level, by default, the log level is ILOG_LEVEL_NOTICE (0x04). For log level definition, the user can refer to internal_include/internal_log.h</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Log Level Name   </th><th class="markdownTableHeadCenter">Log Level Value    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">ILOG_LEVEL_NONE   </td><td class="markdownTableBodyCenter">0x00    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">ILOG_LEVEL_FATAL   </td><td class="markdownTableBodyCenter">0x01    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">ILOG_LEVEL_ERROR   </td><td class="markdownTableBodyCenter">0x02    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">ILOG_LEVEL_WARN   </td><td class="markdownTableBodyCenter">0x03    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">ILOG_LEVEL_NOTICE   </td><td class="markdownTableBodyCenter">0x04    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">ILOG_LEVEL_INFO   </td><td class="markdownTableBodyCenter">0x05    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">ILOG_LEVEL_DEBUG   </td><td class="markdownTableBodyCenter">0x06    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">ILOG_LEVEL_VERB   </td><td class="markdownTableBodyCenter">0x07   </td></tr>
</table>
<p><br  />
</p>
<hr  />
<h3><a class="anchor" id="dsf_performance_profiling"></a>
1.5.2 Depth Sensing Framework Performance Profiling</h3>
<p >There is a performance profiling feature in DSF. Users can press 'p' + ENTER for test_amba_dsf, it will print each stage cost time (ns) and corresponding fps. The real fps of the graph will also be printed. It is expected to reach maximum fps (30) for VGA (640x480) iToF, on CV2x platform. If users want to get theoretical maximum fps, regardless of the sensor fps limitation, they can idle the sensor input stage, and reset profiling. Here are run-time commands examples: 'idle itof_sensor_input' + ENTER; 'reset profiling' + ENRER; 'p' + ENTER. Then test_amba_dsf will print the maximum fps regardless of the sensor fps limitation. <br  />
</p>
<hr  />
<h3><a class="anchor" id="dsf_diagnosis"></a>
1.5.3 Depth Sensing Framework Diagnosis</h3>
<p >There are three typical ways to diagnose DSF, first one is increasing the log level; the second one is using GDB; the third one is checking run-time status of each stages: 's' + ENTER. The run-time status of stages include the stage state, the buffer number on input pins, the buffer number on output pins and the free buffer number in the buffer pool. <br  />
</p>
<hr  />
<h2><a class="anchor" id="depth_framework_graph_viewer"></a>
1.6 Depth Sensing Framework Graph Viewer</h2>
<p >This is python tool to view the data processing graph, it will generate a picture from a <code>.lc</code> file. The tool is under <code>ambarella/packages/depth_sensing_framework/tools/graph_viewer</code>. <br  />
</p>
<p >Prerequisites: install graphviz if it is not installed </p><div class="fragment"><div class="line">pip install graphviz</div>
</div><!-- fragment --><p> <br  />
</p>
<p >Usage: </p><div class="fragment"><div class="line">python ./DSF_graph_viewer.py -i xxxxx.lc -o xxxx.jpg</div>
</div><!-- fragment --><p> Parameter '-i' is used to specify the path of input .lc file. Parameter '-o' is used to specify the path of output flowchart. The format of output file can be selected in ".jpg, .png or .pdf". <br  />
</p>
<hr  />
<h2><a class="anchor" id="depth_framework_lc_explanation"></a>
1.7 Depth Sensing Framework Configuration Files Description</h2>
<p >Configuration files are in the path <code>ambarella/packages/depth_sensing_framework/conf</code>. <br  />
 <a href="../../scripts/dsf_imx528_amba_120m.lc" target="_blank"><b>dsf_imx528_amba_120m.lc</b></a> <br  />
 Some details of the lc files are described here: </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Field   </th><th class="markdownTableHeadCenter">Value   </th><th class="markdownTableHeadCenter">Details    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">domain_num   </td><td class="markdownTableBodyCenter">2   </td><td class="markdownTableBodyCenter">Memory domain numbers    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">dump_path   </td><td class="markdownTableBodyCenter">./   </td><td class="markdownTableBodyCenter">Path of dumping    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">thread_num_hint   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Thread numbers for components    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">name   </td><td class="markdownTableBodyCenter">IMX528   </td><td class="markdownTableBodyCenter">Sensor name    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">category   </td><td class="markdownTableBodyCenter">iTOF   </td><td class="markdownTableBodyCenter">Sensor category    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">width   </td><td class="markdownTableBodyCenter">640   </td><td class="markdownTableBodyCenter">Resolution width    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">height   </td><td class="markdownTableBodyCenter">480   </td><td class="markdownTableBodyCenter">Resolution height    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">vin_id   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Vinc ID for raw capture    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">enable_confidence   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Enable decoding amplitude    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">fx   </td><td class="markdownTableBodyCenter">513.6133634100554   </td><td class="markdownTableBodyCenter">Intrinsic paramter: focal length in horizontal directrion    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">fy   </td><td class="markdownTableBodyCenter">513.6133634100554   </td><td class="markdownTableBodyCenter">Intrinsic paramter: focal length in vertical directrion    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">cx   </td><td class="markdownTableBodyCenter">342.8242453686895   </td><td class="markdownTableBodyCenter">Intrinsic paramter: image center in horizontal directrion    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">cy   </td><td class="markdownTableBodyCenter">246.0759997902838   </td><td class="markdownTableBodyCenter">Intrinsic paramter: image center in vertical directrion    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">k1   </td><td class="markdownTableBodyCenter">-0.04544260539644419   </td><td class="markdownTableBodyCenter">Radial distortion    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">k2   </td><td class="markdownTableBodyCenter">0.3089769280456539   </td><td class="markdownTableBodyCenter">Radial distortion    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">k3   </td><td class="markdownTableBodyCenter">-0.7618227789466491   </td><td class="markdownTableBodyCenter">Radial distortion    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">p1   </td><td class="markdownTableBodyCenter">0.001979789423728918   </td><td class="markdownTableBodyCenter">Tangential distortion    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">p2   </td><td class="markdownTableBodyCenter">0.004543491564486492   </td><td class="markdownTableBodyCenter">Tangential distortion    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">cw_freq_0   </td><td class="markdownTableBodyCenter">120000000   </td><td class="markdownTableBodyCenter">First frequency    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">cw_freq_1   </td><td class="markdownTableBodyCenter">120000000   </td><td class="markdownTableBodyCenter">Second frequency used in dual freqency mode    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">raw_channel_num   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Channel numbers in on raw frame    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">raw_sub_interleave   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Raw data interleave subtraction mode    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">raw_rightshift_bits   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Right shift bits for raw data    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amp_cut_higher_bits   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Cut higher bits of amplitude    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">buffer_num   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Buffer numbers    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">alignment   </td><td class="markdownTableBodyCenter">64   </td><td class="markdownTableBodyCenter">Buffer address's alignment (bytes)    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">image_num   </td><td class="markdownTableBodyCenter">1   </td><td class="markdownTableBodyCenter">Image number    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">channel_num   </td><td class="markdownTableBodyCenter">4   </td><td class="markdownTableBodyCenter">Channel numbers of one frame    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">channel_interleave   </td><td class="markdownTableBodyCenter">0   </td><td class="markdownTableBodyCenter">Channel interleave flag    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">pixel_fmt   </td><td class="markdownTableBodyCenter">f32   </td><td class="markdownTableBodyCenter">Pixel format   </td></tr>
</table>
<h2><a class="anchor" id="depth_framework_api"></a>
1.8 Depth Sensing Framework API</h2>
<p >Visit the following link to see details of the API function</p><ul>
<li><a class="el" href="../../de/dd6/group__dsf-api-flow.html">Depth Sensing Framework work flow API</a> shows depth sensing framework work flow API</li>
<li><a class="el" href="../../df/d42/group__dsf-api-utility.html">Depth Sensing Framework utility API</a> shows depth sensing framework utility API</li>
</ul>
<hr  />
<h1><a class="anchor" id="dsf_components"></a>
2. Components for Depth Sensing Framework</h1>
<ul>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_components_overview">2.1 Overview of DSF Components</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_c_components">2.2 DSF C Components</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_amba_components">2.3 DSF AMBA Components</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_display_components">2.4 DSF Display Components</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_by_extern_lib_components">2.5 DSF by External Library Components</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#dsf_customized_components">2.6 DSF Customized Components</a></li>
</ul>
<h2><a class="anchor" id="dsf_components_overview"></a>
2.1 Overview of DSF Components</h2>
<p >Component is a basic process unit in Amba DSF, it is used by a stage. A component can be an embedded one, which is already provided by DSF, or a customized one, which is written by the customer. All components use the same interface to framework for data message processing. Components are classified into several categories for easy maintainence: C components, Amba components, display components, by external library components and example customized components. <br  />
</p>
<hr  />
<h2><a class="anchor" id="dsf_c_components"></a>
2.2 DSF C Components</h2>
<p >C component is with a pure c implementation, it does not depends on any libraries and does not involve optimization. Typically, c component is used for development and debug purpose. Currently, the c component list is as follows.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">C Components    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_itof_decoder    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">c_dual_freq_decoder    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_compensation    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">c_spatial_median_filter    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_spatial_gaussian_filter    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">c_normalization_jet    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_temporal_filter    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">c_temporal_iir_filter    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_flying_pixel_removal   </td></tr>
</table>
<p><br  />
</p>
<h3><a class="anchor" id="c_itof_decoder"></a>
2.2.1 C iToF Decoder</h3>
<p >This component decodes raw frame for iToF sensor, in single frequency's case, its output is distance (phase) and amplitude (confidence). The corresponding accelerated component is amba_itof_decoder. <br  />
</p>
<h3><a class="anchor" id="c_dual_freq_decoder"></a>
2.2.2 C iToF Dual Frequency Decoder</h3>
<p >This component decodes raw frame for iToF sensor, in dual frequency's case, its output is distance (phase) and amplitude (confidence). The corresponding accelerated component is amba_dual_freq_decoder. <br  />
</p>
<h3><a class="anchor" id="c_compensation"></a>
2.2.3 C Compensation</h3>
<p >This component does wiggling compensation for distance (phase). The corresponding accelerated component is amba_compensation. <br  />
</p>
<h3><a class="anchor" id="c_spatial_median_filter"></a>
2.2.4 C Spatial Median Filter</h3>
<p >This component operates spatial median filter. The corresponding accelerated component is amba_spatial_median_filter. <br  />
</p>
<h3><a class="anchor" id="c_spatial_gaussian_filter"></a>
2.2.5 C Spatial Gaussian Filter</h3>
<p >This component operates spatial gaussian filter. <br  />
</p>
<h3><a class="anchor" id="c_normalization_jet"></a>
2.2.6 C Normalization JET</h3>
<p >This component operates normalization first, then converts data into pseudo-color with JET scheme. <br  />
</p>
<h3><a class="anchor" id="c_temporal_filter"></a>
2.2.7 C Temporal Filter</h3>
<p >This component operates simple temporal filter. <br  />
</p>
<h3><a class="anchor" id="c_temporal_iir_filter"></a>
2.2.8 C Temporal IIR Filter</h3>
<p >This component operates temporal IIR filter. <br  />
</p>
<h3><a class="anchor" id="c_flying_pixel_removal"></a>
2.2.9 C Flying Pixel Removal</h3>
<p >This component operates flying pixel removal. The corresponding accelerated component is amba_flying_pixel_removal. <br  />
</p>
<hr  />
<h2><a class="anchor" id="dsf_amba_components"></a>
2.3 DSF AMBA Components</h2>
<p >AMBA component is implementation with Ambarella acceleration, it may depends on Ambarella libraries and kernel modules such as sensor / VIN driver, IAV driver, NNCtrl, Cavalry, CV0 library, cvlib, lib_amba_tof, and more. Typically, AMBA component has a good running performance. Currently, the AMBA component list is as follows.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">AMBA Components    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_itof_sensor_input    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_dtof_sensor_input    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_itof_decoder    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_dual_freq_decoder    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_itof_dec_for_calib    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_compensation    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_ae_control    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_depth_registration    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_idsp_phase_ir    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_phase_to_depth    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_ldc    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_spatial_median_filter    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_flying_pixel_removal   </td></tr>
</table>
<p><br  />
</p>
<h3><a class="anchor" id="amba_itof_sensor_input"></a>
2.3.1 AMBA iToF Sensor Input</h3>
<p >This component reads raw frame from iToF sensor, its output is sensor raw data. <br  />
</p>
<h3><a class="anchor" id="amba_dtof_sensor_input"></a>
2.3.2 AMBA dToF Sensor Input</h3>
<p >This component reads raw frame for dToF sensor, its output is distance and amplitude. <br  />
</p>
<h3><a class="anchor" id="amba_itof_decoder"></a>
2.3.3 AMBA iToF Decoder</h3>
<p >This component decodes raw frame for iToF sensor, in single frequency's case, its output is distance (phase) and amplitude (confidence). <br  />
</p>
<h3><a class="anchor" id="amba_dual_freq_decoder"></a>
2.3.4 AMBA iToF Dual Frequency Decoder</h3>
<p >This component decodes raw frame for iToF sensor, in dual frequency's case, its output is distance (phase) and amplitude (confidence). <br  />
</p>
<h3><a class="anchor" id="amba_itof_dec_for_calib"></a>
2.3.5 AMBA iToF Decoder for Calibration</h3>
<p >This component decodes raw frame for iToF sensor, it is for calibration purpose, so it does not apply any post-processing like global offset compensation, wiggling compensation, spatial and temporal filtering, removing invalid depth and flying pixel removal. <br  />
</p>
<h3><a class="anchor" id="amba_compensation"></a>
2.3.6 AMBA Compensation</h3>
<p >This component does wiggling compensation for distance (phase). <br  />
</p>
<h3><a class="anchor" id="amba_ae_control"></a>
2.3.7 AMBA AE Control</h3>
<p >This component controls AE according to the current average amplitude (confidence) and AE target. <br  />
</p>
<h3><a class="anchor" id="amba_depth_registration"></a>
2.3.8 AMBA Depth Registration</h3>
<p >This component is used to map the depth image to RGB sensor's coordinate. align_mat option is the transform matrix. <br  />
</p>
<h3><a class="anchor" id="amba_idsp_phase_ir"></a>
2.3.9 AMBA IDSP Phase IR</h3>
<p >This component is used to process phase (distance) / amplitude (confidence) by image digital signal processing (IDSP). Encode from raw (EFR) is used to send 16 bits phase / amplitude to IDSP. In order to obtain good quality images for lens calibration, 3A parameters in <code>ambarella/prebuild/ambarella/ibrary/amba_tof/3a</code> should be loaded by Amage tool. <br  />
</p>
<h3><a class="anchor" id="amba_phase_to_depth"></a>
2.3.10 AMBA Phase to Depth</h3>
<p >This component convert phase (distance) to depth, with intrinsic matrix. <br  />
</p>
<h3><a class="anchor" id="amba_ldc"></a>
2.3.11 AMBA LDC</h3>
<p >This component operates LDC. <br  />
</p>
<h3><a class="anchor" id="amba_spatial_median_filter"></a>
2.3.12 AMBA Spatial Median Filter</h3>
<p >This component operates spatial median filter. <br  />
</p>
<h3><a class="anchor" id="amba_flying_pixel_removal"></a>
2.3.13 AMBA Flying Pixel Removal</h3>
<p >This component operates flying pixel removal. <br  />
</p>
<hr  />
<h2><a class="anchor" id="dsf_display_components"></a>
2.4 DSF Display Components</h2>
<p >Display component is for displaying, it does not include post-processing. Currently, the display component list is as follows.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Display Components    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">send_to_ros    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">draw_depth    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">draw_osd   </td></tr>
</table>
<p><br  />
</p>
<h3><a class="anchor" id="send_to_ros"></a>
2.4.1 Send to ROS</h3>
<p >This component sends the depth data to ROS for display. <br  />
</p>
<h3><a class="anchor" id="draw_depth"></a>
2.4.2 Draw Depth on Linux Frame Buffer</h3>
<p >This component draws the depth on Linux frame buffer. <br  />
</p>
<h3><a class="anchor" id="draw_osd"></a>
2.4.3 Draw Overlay for Video Stream Encoding</h3>
<p >This component draws the depth on overlay for video stream encoding. <br  />
</p>
<hr  />
<h2><a class="anchor" id="dsf_by_extern_lib_components"></a>
2.5 DSF by External Library Components</h2>
<p >Display component depends on external libraries like OpenCV. Currently, the by external library component list is as follows.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">By External Library Components    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">opencv_flying_pixel_removal    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">opencv_normalization_jet   </td></tr>
</table>
<p><br  />
</p>
<h3><a class="anchor" id="opencv_flying_pixel_removal"></a>
2.5.1 OpenCV Flying Pixel Removal</h3>
<p >This component operates flying pixel removal, with OpenCV library. <br  />
</p>
<h3><a class="anchor" id="opencv_normalization_jet"></a>
2.5.2 OpenCV Normalization JET</h3>
<p >This component operates normalization first, and then converts data into pseudo-color with JET scheme. This component depends on OpenCV library. <br  />
</p>
<hr  />
<h2><a class="anchor" id="dsf_customized_components"></a>
2.6 DSF Customized Components</h2>
<p >Typically, customized component is written by customers, DSF also includes example codes for some customized components. Currently, the customized component list is as follows.</p>
<table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Customized Components    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">yolov5    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">feed_to_efm    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">combine_depth_nv12_bbox    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">draw_det_fb   </td></tr>
</table>
<p><br  />
</p>
<h3><a class="anchor" id="yolov5"></a>
2.6.1 Yolov5</h3>
<p >This component loads and executes Yolov5 on depth data. <br  />
</p>
<h3><a class="anchor" id="feed_to_efm"></a>
2.6.2 Feed to EFM</h3>
<p >This component feeds the data to EFM. <br  />
</p>
<h3><a class="anchor" id="combine_depth_nv12_bbox"></a>
2.6.3 Combine Depth and BBox</h3>
<p >This component combines the depth and bounding boxes. <br  />
</p>
<h3><a class="anchor" id="draw_det_fb"></a>
2.6.4 Draw detection result on Linux Frame Buffer</h3>
<p >This component draws the detection result on Linux frame buffer. <br  />
</p>
<hr  />
<h1><a class="anchor" id="depth_tof"></a>
3. ToF Sensor</h1>
<ul>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_introduction">3.1 ToF Introduction</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_supported_sensor_list">3.2 Supported Sensor List</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_calibration">3.3 ToF Calibration</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_process">3.4 ToF Process Modules</a></li>
<li>Section <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#tof_pro_stages">3.5 ToF Components</a></li>
</ul>
<h2><a class="anchor" id="tof_introduction"></a>
3.1 ToF Introduction</h2>
<p >ToF is used for extraction of three-dimensional information from scene by using modulated light at specific wavelength. The phase difference between the emitted light and the light reflecting off the scene is measured, per pixel, and converted to depth. By using camera intrinsic parameters, each pixel can be transformed into three-dimensional coordinates. <br  />
 The cw-iToF (continues wave) method consists of illuminating the scene with a light source, which amplitude is sinusoidally modulated at a certain high frequency. Once the light is emitted towards the scene, it changes its phase delay in relation to the time delay interleaving the emission and the detection (after the reflection). This time delay (or more correctly time of flight) is related to the distance of objects within the scene; thus starting from the phase delay it is possible to compute the distance of the acquired scene, pixel by pixel. In order to measure the phase delay it is possible to sample the back-reflected light four times per period and using the Fourier Transform algorithm it is possible to compute the phase of the reflected light in respect to the reference signal. </p><div class="image">
<img src="../../tof_principle.png" alt=""/>
<div class="caption">
Figure 3-1. Depth Principle.</div></div>
<p> Sinusoidal reflected light compared to the reference signal. The amplitude of the reflected light is less than those of the emitted light because of the reflection of objects in the scene. Moreover the ambient background light changes the offset of the acquired light. The algorithm deals with the four samples (c0, c1, c2, and c3) of the reflected light allowing the calculation of the phase delay between the two signals using the Fourier Transform equations. The figure above shows the distance generated using the emitted and reflecting light.</p>
<h2><a class="anchor" id="tof_supported_sensor_list"></a>
3.2 Supported Sensor List</h2>
<p >There are several sensors already supported for ToF function.</p>
<p >Here is the supported sensor list for ToF: </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Sensors   </th><th class="markdownTableHeadCenter">Resolution   </th><th class="markdownTableHeadCenter">Status   </th><th class="markdownTableHeadCenter">Modules    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">IMX316   </td><td class="markdownTableBodyCenter">240x180   </td><td class="markdownTableBodyCenter">supported   </td><td class="markdownTableBodyCenter">Liteon    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">IMX456   </td><td class="markdownTableBodyCenter">640x480   </td><td class="markdownTableBodyCenter">supported   </td><td class="markdownTableBodyCenter">Liteon    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">IMX528   </td><td class="markdownTableBodyCenter">640x480   </td><td class="markdownTableBodyCenter">supported   </td><td class="markdownTableBodyCenter">Polight &amp; SunnyOptical    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">IRS2877c   </td><td class="markdownTableBodyCenter">640x480   </td><td class="markdownTableBodyCenter">supported   </td><td class="markdownTableBodyCenter">Oflim    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">OZT167C   </td><td class="markdownTableBodyCenter">640x480   </td><td class="markdownTableBodyCenter">supported   </td><td class="markdownTableBodyCenter">Infineon    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">ADSD3500   </td><td class="markdownTableBodyCenter">512x512 &amp; 1024x1024   </td><td class="markdownTableBodyCenter">supported   </td><td class="markdownTableBodyCenter">ADI   </td></tr>
</table>
<hr  />
<h2><a class="anchor" id="tof_calibration"></a>
3.3 ToF Calibration</h2>
<p >Users should perform the calibration as shown in the steps below: <br  />
 1) Temperature calibration: remove sensor's temperature drift <br  />
 2) Lens calibration: remove lens' distortion <br  />
 3) Global calibration: common offset between the measured distance and the real distance <br  />
 4) Wiggling calibration: nonlinear offset between the measured distance and the real distance <br  />
</p>
<p >The flow of calibration is as shown in the steps below: <br  />
 1) Capture the temperature calibration data and perform the temperature calibration. <br  />
 2) Capture the lens calibration dataset, and peform the lens calibration. <br  />
 3) Modify lc file according to the lens calibration's result (fx, fy, cx, cy, k1, k2, p1, p2, k3). <br  />
 4) Capture the global / wiggling calibration dataset. <br  />
 5) Perform the global calibration. <br  />
 6) According to the global calibration results, peform the wiggling calibration. <br  />
</p>
<h3><a class="anchor" id="tof_calib_build_step"></a>
3.3.1 ToF Build Steps</h3>
<p >First, set the basic ToF information in menuconfig. Configure the depth sensing framework and choose required modules. </p><div class="fragment"><div class="line">-&gt; Ambarella Package Configuration</div>
<div class="line">   [*]Build Ambarella Depth Sensing Framework</div>
</div><!-- fragment --><p >Configure amb_tof library. </p><div class="fragment"><div class="line">-&gt; Ambarella Prebuild</div>
<div class="line">   [*] Configure Ambarella amba_tof library</div>
</div><!-- fragment --><p >Configure ToF sensors. </p><div class="fragment"><div class="line">-&gt; Ambarella Linux Configuration</div>
<div class="line">   -&gt; Ambarella Private Drivers Configuration</div>
<div class="line">     -&gt; Build Ambarella <span class="keyword">private</span> Vin modules</div>
<div class="line">        -&gt; Ambarella ToF Sensor Configuration</div>
<div class="line">          [*] Sony IMX316 43.2K ToF sensor(MIPI)</div>
<div class="line">          [*] Sony IMX456 0.3M ToF sensor(MIPI)</div>
<div class="line">          [*] Sony IMX528 0.3M ToF sensor(MIPI)</div>
<div class="line">          [*] Panasonic MN34906 0.3M ToF sensor(MIPI)</div>
</div><!-- fragment --><p >Configure pre-build modules. </p><div class="fragment"><div class="line">-&gt; Ambarella Prebuild</div>
<div class="line">  -&gt; CONFIG Ambarella Aicam prebuild</div>
<div class="line">     -&gt; [*] Configure Ambarella Optimized Aicam Algos Library</div>
<div class="line">     -&gt; [*] Configure Traditional Aicam Algos Library</div>
<div class="line">     -&gt; [*] Configure Ambarella Software CV Library</div>
</div><!-- fragment --><h3><a class="anchor" id="tof_calib_capture"></a>
3.3.2 Calibration Dataset Capturing</h3>
<p >3A and lc files are located in the path <code>ambarella/packages/depth_sensing_framework/data_files</code>. <br  />
 Calibration related configuration files are located in the path <code>ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/script</code> <br  />
 The amplitude images are gray scale images. The detection of the chessboard in amplitude images could be used <br  />
 to do lens / global / wiggling calibration. <br  />
 Amage tool is used to adjust the brightness of the amplitude images. <br  />
 </p><div class="image">
<img src="../../amage_tool.png" alt=""/>
<div class="caption">
Figure 3-2. Amage Tool.</div></div>
<p> The image shows the steps to apply the 3A parameters on amplitude images by raw encode. <br  />
 Step 1: Connect the tool with the board by telnet. <br  />
 Step 2: Open the 3A configuration files. <br  />
 Files are stored in <code>ambarella/packages/depth_sensing_framework/data_files/3a</code>. calib_3D.bin / calib_reg.bin should be modified in ir_calibration.txt accordingly. <br  />
 Step 3: Choose the specific channel. <br  />
 Step 4: Apply the 3A parameters. <br  />
 Step 5: Choose the before_ce_wb_gain stage. <br  />
 Step 6: Change the gain value （set r_gain / g_gain / b_gain the same）to adjust the brightness, <br  />
 and click apply button. <br  />
</p>
<p >Commands to enter the preview state and mount the share folder: <br  />
 </p><div class="fragment"><div class="line">board # ./run_tof_xx.sh</div>
<div class="line">board # mount -t cifs -o domain=ambarella,sec=ntlmssp,username=xx,password=xx,uid=0,</div>
<div class="line">gid=0,file_mode=0755,dir_mode=0755 <span class="comment">//10.0.0.5/share /mnt</span></div>
</div><!-- fragment --><p >Run depth framework and capture the camera calibration dataset: </p><div class="fragment"><div class="line">(A) Single frequency mode <span class="keywordflow">case</span> :</div>
<div class="line">board # test_amba_dsf dsf_imxxxx_amba_dump_calib.lc</div>
<div class="line">(B) Dual frequency mode case :</div>
<div class="line">board # test_amba_dsf dsf_irs2877a_amba_dump_calib_dual_lens_calib_ambadualdec.lc (<span class="keywordflow">if</span> the sensor is irs2877a)</div>
<div class="line">host  $ use Amage tool to read configurations and adjust 3A <span class="keywordflow">for</span> amplitude images.</div>
<div class="line">tof_conf_capture.sh is in ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/script/tof</div>
<div class="line">board # ./tof_conf_capture.sh 0 30</div>
</div><!-- fragment --><p >Run depth framework and capture the temperature calibration dataset: </p><div class="fragment"><div class="line">board # mkdir calibration</div>
<div class="line">(A) Single frequency mode case :</div>
<div class="line">board # test_amba_dsf dsf_xxx_amba_xxx_dec_for_calib.lc</div>
<div class="line">The data will be stored in accuracy.csv of the calibration folder.</div>
<div class="line">Like ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/calib_data/tof/accuracy.csv.</div>
<div class="line">(B) Dual frequency mode <span class="keywordflow">case</span> :</div>
<div class="line">board # test_amba_dsf dsf_irs2877a_amba_dump_calib_dual_laser_calib_ambadualdec.lc (<span class="keywordflow">if</span> the sensor is irs2877a)</div>
<div class="line">The distance values of the crosshair will be reported like below :</div>
<div class="line">- frequency 0 center average value 1.146080</div>
<div class="line">- frequency 1 center average value 1.877759</div>
<div class="line">when put the camera to the other postion, enter <span class="stringliteral">&quot;c 2&quot;</span>, the terminal will report the other location<span class="stringliteral">&#39;s distance.</span></div>
</div><!-- fragment --><p >Run depth framework and capture the global / wiggling dataset: <br  />
 If the temperature calibration has been done, <br  />
 fill the temperature fitting parameters to the stage cal_depth_amp / itof_dec_for_calib <br  />
 to do the temperature compensation first, options are "line_slopy" and "base". Global and wiggling calibration use the same dataset. </p><div class="image">
<img src="../../global_wiggiling.png" alt=""/>
<div class="caption">
Figure 3-3. Capture Global / Wiggling Dataset.</div></div>
<p> The image shows how to capture the global / wiggling dataset from close to the far distance. <br  />
</p>
<p >1) For the single frequency short range (0 - 1.25 meters) calibration, <br  />
 it is suggested to use the chessboard to perform the calibration. <br  />
 The chessboard should be rigid and flat. If the chessboard's accuracy is not good enough, <br  />
 it is suggested to use the laser method to do calibration. <br  />
 The chessboard corners could be detected automatically to get the points' ToF distance <br  />
 and caculate out the points' actual distance. Set "dump_calib = 1" in dsf_imxxxx_amba_dump_calib.lc, <br  />
 and modify the lc file's option (fx, fy, cx, cy, k1, k2, p1, p2, k3) according to the lens calibration's result. <br  />
 "dump_path" is the path to store the calibration data. <br  />
</p>
<div class="fragment"><div class="line">board # test_amba_dsf dsf_imxxxx_amba_dump_calib.lc</div>
</div><!-- fragment --><p> Run-time command "c" is used to create the folder and save the calibration data. Record the distance information and YUV with a step of 10 cm from near to far. <br  />
 ToF distance information is stored in tof_distance.csv. <br  />
 tof_canvas_xx.yuv is used to detect the chessboard's coner coordinates. <br  />
</p>
<p >2) For the long range (greater than 1.25 meters), it is suggested to use the laser to perform the calibration. <br  />
 </p><div class="image">
<img src="../../crosshair.png" alt=""/>
<div class="caption">
Figure 3-4. Crosshair.</div></div>
<p> Paste one crosshair image on the wall, and focus the principle center on the crosshair when recording distances. <br  />
 "draw_crosshair = 1" in dsf_xxx_amba_xxx_dec_for_calib_laser.lc is used to show the center crosshair on the amplitude image. Record the distance information (ToF and laser measurement) <br  />
 with a step of 10 cm from near to far. <br  />
 </p><div class="fragment"><div class="line">board # test_amba_dsf dsf_imxxxx_amba_xxxm_dec_for_calib_laser.lc</div>
<div class="line">Key information (ToF distance) report :</div>
<div class="line">distance(meter): AVG xx, STD_DERV xx, precision xx</div>
</div><!-- fragment --><p> Fill the ToF distance and the measuring distance (by laser) in the nl_laser.csv, for example <code>ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/calib_data/tof/nl_laser.csv</code>.</p>
<h3><a class="anchor" id="tof_lens_calib"></a>
3.3.3 Lens Calibration</h3>
<p >This calibration is used to remove lens' distortion, every pixel will be converted into the ideal coordinate in the pin-hole model by removing the distortion. Ambarella suggests using the Zhang Zhengyou calibration method for pinhole lens. Lens calibration is very important, because the intrinsic and distortion parameters will influence the calculation accuracy of extrinsic parameters. It is better to capture more than fifty images to reduce the fitting error. To avoid the chessboard to be detected with failure, ensure that every chessboard in the picture is big enough.</p>
<p >Use PC calibration tool to do lens calibration. Tools are located in the path <code>ambarella/prebuild/ambarella/library/multi_sensor_calib/calib_tool</code> Refer to the document Sensor Calibration Library API of Lens Calibration section. Modify run_cali.sh, and add the option like "yuv_w=4096 -yuv_h=2160 -yuv_name=fuse_canvas3_4096x2160_NV12 -k4=1 -k5=1 -k6=1" in funciton "run_lens_calib()". Calibration results containing intrinsic matrix and distortion parameters will be reported as below : <br  />
 Intrinsic[1063.124773676325, 0, 973.8136518801646;0, 1063.124773676325, 541.1757522380176;0, 0, 1] <br  />
 dist_coeffs[-0.08726931759522329;0.06903056691830357;6.280400379716693e-05;-0.0006512637770184914;-0.01574894685520492;]</p>
<p >Parameters meanings are: Intrinsic[fx, 0, cx; 0, fy, cy; 0, 0, 1] dist_coeffs[k1; k2; p1; p2; k3] Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens"><ol type="1">
<li>Lens Calibration</li>
</ol>
</a> for more details.</p>
<h3><a class="anchor" id="tof_temperature_calib"></a>
3.3.4 Temperature Offset Calibration</h3>
<p >There is a phase drift introduced by the temperature. It is a linear drift in distance. Users can perform the temperature calibration to add the compensation for distance. Tools are located in the path <code>ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/script/tof</code>. Refer to the document Sensor Calibration Library API of ToF Calibration section. Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_tof"><ol type="1">
<li>ToF Calibration</li>
</ol>
</a> for more details.</p>
<h3><a class="anchor" id="tof_global_calib"></a>
3.3.5 Global Offset Calibration</h3>
<p >There is a global offset between the measured distance and the real distance. Users just need chessboard or some other calibration targets to do extrinsic calibration and get ground truth distance. Tools are located in the path <code>ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool</code>. Users perform the calibration and choose one value as a global offset value from the report. Refer to the document Sensor Calibration Library API of ToF Calibration section. Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_tof"><ol type="1">
<li>ToF Calibration</li>
</ol>
</a> for more details.</p>
<h3><a class="anchor" id="tof_wiggle_calib"></a>
3.3.6 Wiggling Calibration</h3>
<p >Modulation wave shape is not perfect as the sinusoidal shape, so the phase delay will not be calculated correctly, and the imperfect phase will introduce the wiggling errors for different distances. Refer to the document Sensor Calibration Library API of ToF Calibration section. After ToF calibration, calibration data can be used for ToF process on chips. Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_tof"><ol type="1">
<li>ToF Calibration</li>
</ol>
</a> for more details.</p>
<h3><a class="anchor" id="tof_rgb_registration_calib"></a>
3.3.7 ToF and RGB Sensors Registration Calibration</h3>
<p >The proposed calibration solution provides a mechanism to calibrate RGB and Depth cameras's intrinsic /extrinsic paramters. The depth image could be converted to the RGB's view with the calibration data. Refer to dsf_imx528_amba_120m_register_sun.lc for how to configure the depth registration feature. Refer to <a class="elRef" target="_blank" href="../../../system/d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_tof_rgbd"><ol type="1">
<li>RGBD Registration Calibration</li>
</ol>
</a> for more details of calibration. </p><hr  />
<h2><a class="anchor" id="tof_process"></a>
3.4 ToF Process Modules</h2>
<div class="image">
<img src="../../tof_flow.png" alt=""/>
<div class="caption">
Figure 3-5. ToF Process Flow.</div></div>
<p> This image shows the process flow of Amba ToF. It shows the pipeline from raw phase data to final point cloud.</p>
<h2><a class="anchor" id="tof_pro_stages"></a>
3.5 ToF Components</h2>
<p >Here is the supported components lists for ToF function : </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Components    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_dtof_sensor_input    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_itof_sensor_input    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_itof_decoder    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_ae_control    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_compensation    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_depth_register    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">amba_idsp_phase_ir    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">amba_ldc    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_compensation    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">c_dual_frequency_decoder    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_file_feeder    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">c_flying_pixel    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_itof_decoder    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">c_normalization_jet    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_spatial_gaussian_filter    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">c_spatial_median_filter    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">c_transfer_depth    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">draw_depth    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">send_to_ros    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">draw_osd   </td></tr>
</table>
<h3><a class="anchor" id="tof_input"></a>
3.5.1 ToF Process Input</h3>
<p >This stage is to query raw / raw sequence and copy to user space. IMX528 supports four phases in one raw frame. MN34906 ouput depth and IR data in one raw frame without decoding. c_file_feeder.c / amba_itof_sensor_input.c / amba_dtof_sensor_input.c are versions for reference. dsf_mn34906_c.lc is a configuration file for reference.</p>
<h3><a class="anchor" id="tof_temporal_filter"></a>
3.5.2 ToF Temporal Filter</h3>
<p >The median filter is used as one example to remove noise. c_spatial_gaussian_filter.c is a component for reference.</p>
<h3><a class="anchor" id="tof_spatial_filter"></a>
3.5.3 ToF Spatial Filter</h3>
<p >The gaussian filter is used as one example to remove noise. c_spatial_gaussian_filter.c is a component for reference.</p>
<h3><a class="anchor" id="tof_pro_decode"></a>
3.5.4 ToF Process Decode</h3>
<p >CW-iToF 4-phase raw pictures can be decoded as two images of distance and amplitude. Amplitude image is used to extract key points and control 3A. </p><div class="image">
<img src="../../tof_formula.png" alt=""/>
<div class="caption">
Figure 3-6. ToF Decode Phase / Amplitude.</div></div>
<p> c_itof_decoder.c/amba_itof_decoder.c in components are common / acceleration versions for reference.</p>
<h3><a class="anchor" id="tof_idsp_phase_ir"></a>
3.5.5 ToF Phase / Amplitude Raw Encode</h3>
<p >This stage is used to process phase / amplitude by IDSP. Encode from raw (EFR) is used to send 16 bits phase / amplitude to IDSP. In order to have good quality images for lens calibration, 3A parameters in <code>ambarella/prebuild/ambarella/ibrary/amba_tof/3a</code> should be loaded by Amage tool. amba_idsp_phase_ir.c is a component for reference. Option: <br  />
 "show": shows amplitude through encode from memory. <br  />
 "dump_calib": enables dump calibration data for wiggling calibration. <br  />
 "frame_mean": uses mean value from depth sequence. <br  />
 "total_num": numbers of frames to capture. <br  />
 "min_conf / max_conf": threshold of amplitude. <br  />
</p>
<h3><a class="anchor" id="tof_ldc"></a>
3.5.6 ToF LDC</h3>
<p >LDC is used to remove distortion. Distortion parameters fx,fy,cx,cy,k1,k2,k3,p1,p2 should be filled correctly in lc configuration files. amba_ldc.c is a component for reference.</p>
<h3><a class="anchor" id="tof_compensation"></a>
3.5.7 ToF Compensation</h3>
<p >There are a few features for this stage: <br  />
 1) Wiggling compensation <br  />
 "gen_com" option should be configured as the first time to generate recognizable format, fit_num is the value from wiggling calibration message. <br  />
 2) Remove outlier by checking confidence <br  />
 This is used to remove invalid noise in far distance. <br  />
 3) Crop depth in specific range amba_compensation.c is a component for reference.</p>
<h3><a class="anchor" id="tof_phase_to_depth"></a>
3.5.8 ToF Phase Transformed To Depth</h3>
<p >This stage is to transform phase to depth, calibration intrinsic and distortion parameters should be filled. "depth_mm" option is used to get depth in millimeter unit. amba_phase_to_depth.c is a component for reference.</p>
<h3><a class="anchor" id="tof_ae_control"></a>
3.5.9 ToF Auto Exposure Control</h3>
<p >Shutter should be adjusted to avoid overexposure for specific area. Overexposure will cause depth inaccuracy. Ambarella supports two kinds of methods, one is using center area's average amplitude as the target to control shutter, the other one is to use full amplitude image' histogram to control shutter. amba_ae_control.c is a component for reference.</p>
<h3><a class="anchor" id="tof_rgbd_alignment"></a>
3.5.10 ToF RGBD Alignment</h3>
<p >If customers want to do alignment between RGB sensor and ToF sensor, amba_depth_register.c is used to map depth image to RGB sensor's coordinate. align_mat option is the transform matrix. depth_mm option should be set for phase_to_depth stage. amba_depth_register.c is a component for reference.</p>
<h3><a class="anchor" id="tof_draw_depth"></a>
3.5.11 ToF Draw Depth</h3>
<p >This stage shows the depth through the frame buffer. Depth should do normalization to 8 bits. Option "depth_mm" should be filled, if the unit is millimeter. draw_depth.c is a component for reference.</p>
<h3><a class="anchor" id="tof_live_show_ros"></a>
3.5.12 ToF Live Point Cloud Shown On Ros</h3>
<p >This stage is used to send depth information to PC side by socket, remote_port/remote_url options are used to set socket port and address. The depth information will be received in the server side and transformed to cloud point. send_to_ros.c is a component for reference. Refer to ros_on_ubuntu18.04.txt for details on how to set up.</p>
<h3><a class="anchor" id="tof_dual_frequency_decoder"></a>
3.5.13 ToF Dual Frequency Decoding</h3>
<p >The real distance can not be detected correctly with one kind of frequency. </p><div class="image">
<img src="../../dual_decode.png" alt=""/>
<div class="caption">
Figure 3-7. Real Distance Calculation Formula.</div></div>
<p> Image shows the formula to calculate the real distance, k is a positive number, representing of cycle number. If the distance is bigger than one cycle's distance, it will cause unambiguous range. </p><div class="image">
<img src="../../uncertain.png" alt=""/>
<div class="caption">
Figure 3-8. Unambiguous Range.</div></div>
<p> The image shows the unambiguous range phenomenon. By using dual frequency decoding method, the unambiguous range problem can be resolved. <br  />
 dual_frequency_decoder.c is a component for reference. dsf_imx316_c_dual_freq.lc is a configuration file for reference.</p>
<h3><a class="anchor" id="tof_flying_pixel_removing"></a>
3.5.14 ToF Flying Pixel Removal</h3>
<p >Even if the distance between the two targets is far, when the two targets are partially overlapped, the contour of the overlapped part of the former target is not clear, and the edge contour cannot be accurately determined due to multiple reflections. </p><div class="image">
<img src="../../fly.png" alt=""/>
<div class="caption">
Figure 3-9. Removing Flying Pixel Image vs Original Image.</div></div>
<p> Ihe image shows the effect of removing flying pixels. dsf_imx528_c_compensation_20m_fly.lc is a configuration file for reference.</p>
<h3><a class="anchor" id="tof_convert_depth"></a>
3.5.15 ToF Convert Depth Format</h3>
<p >dsf_imx528_c_compensation_20m_jet.lc is a configuration file for reference to convert depth format from 16bit to three 8bit channels in JET mode.</p>
<h3><a class="anchor" id="tof_draw_osd"></a>
3.5.16 ToF Draw OSD</h3>
<p >This stage is used to show the depth through overlay. Depth will be normalized to 8 bits in the stage. Configure the region of interest (ROI) and alpha value to the specific stream as shown in below .lc file. </p><div class="fragment"><div class="line">stream_id = 2</div>
<div class="line">  roi_x = 0</div>
<div class="line">  roi_y = 0</div>
<div class="line">  roi_w = 320</div>
<div class="line">  roi_h = 240</div>
<div class="line">  alpha = 255</div>
<div class="line">stream_id = 1</div>
<div class="line">  roi_x = 0</div>
<div class="line">  roi_y = 0</div>
<div class="line">  roi_w = 640</div>
<div class="line">  roi_h = 480</div>
<div class="line">  alpha = 128</div>
</div><!-- fragment --><hr  />
<h1><a class="anchor" id="sec_depth_disp_pc_on_ros"></a>
4. Display Point Cloud on ROS</h1>
<p >This document provides the guidelines for the visual point cloud data with robot operating system (ROS) in Ubuntu and Ambarella CV25 platforms. </p>
<h2><a class="anchor" id="host_prepare"></a>
4.1 Host PC Preparation</h2>
<p >The point cloud rendering needs to be done on a PC (host) with a separate graphics card. Do not use a virtual machine to run ROS, it is recommended to use a laptop with good rendering performance directly. </p>
<h3><a class="anchor" id="hardware_prepare"></a>
4.1.1 Hardware Preparation</h3>
<p >The verified host configuration is as below table. </p><a class="anchor" id="lib_depth_framewrok_rev_history"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Host </th><th align="left">Dell Precision 3531 </th></tr>
<tr>
<td>CPU </td><td>Intel i7-10850H </td></tr>
<tr>
<td>Memory </td><td>16GB, DDR4-2666MHz SDRAM </td></tr>
<tr>
<td>GPU </td><td>Nvidia Quadro P620 4GB GDDR5 </td></tr>
<tr>
<td>SSD </td><td>M.2 2230 512 GB, Gen 3 PCIe x4 NVMe </td></tr>
</table>
<h3><a class="anchor" id="software_prepare"></a>
4.1.2 Software Preparation</h3>
<p >The following table shows the software configuration for the host.</p>
<a class="anchor" id="lib_depth_framewrok_rev_history"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Host </th><th align="left">Dell Precision 3531 </th></tr>
<tr>
<td>OS </td><td>Ubuntu 18.04 (Recommend, compatibility issues may occur on other versions) </td></tr>
<tr>
<td>GPU driver version </td><td>460.80 </td></tr>
<tr>
<td>CUDA version </td><td>11.2 </td></tr>
</table>
<p >Nvidia GPU Driver download：https://www.nvidia.cn/Download/index.aspx?lang=en </p><div class="image">
<img src="../../nvidia_driver_download0.png" alt=""/>
</div>
 <div class="image">
<img src="../../nvidia_driver_download1.png" alt=""/>
<div class="caption">
Figure 4-1. Step of Nvidia Driver Download.</div></div>
<p >Type the following command on host to see if the installed version of the GPU driver matches the latest version on NVIDIA release.</p>
<div class="fragment"><div class="line">host $ nvidia-smi</div>
</div><!-- fragment --><p >Since the older version of the GPU driver may affect the rendering of the point cloud, it is necessary to uninstall the older version of the GPU driver first:</p>
<div class="fragment"><div class="line">host $ sudo apt-get remove --purge nvidia*</div>
</div><!-- fragment --><p >Then install the downloaded driver:</p>
<div class="fragment"><div class="line">host $ cd to path of NVIDIA diver</div>
<div class="line">host $ sudo sh NVIDIA-Linux-x86_64-460.84.run # install the driver, file <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> as yours</div>
</div><!-- fragment --><p >Finally, type the following command to confirm that the driver is installed to the latest version:</p>
<div class="fragment"><div class="line">host $ nvidia-smi</div>
</div><!-- fragment --><h2><a class="anchor" id="ros_prepare"></a>
4.2 ROS Preparation</h2>
<p >The robot operating system (ROS) is a set of software libraries and tools that help you build robot applications. From drivers to state-of-the-art algorithms, and with powerful developer tools, ROS has what you need for your next robotics project. The ROS can render point cloud data from CV25 platform real-time and adjustable.</p>
<h3><a class="anchor" id="install_ros"></a>
4.2.1 Install ROS</h3>
<p >Install ROS:</p>
<div class="fragment"><div class="line">host $ sudo sh -c <span class="stringliteral">&#39;echo &quot;deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main&quot; &gt; /etc/apt/sources.list.d/ros-latest.list&#39;</span></div>
<div class="line">host $ sudo apt-key adv --keyserver <span class="stringliteral">&#39;hkp://keyserver.ubuntu.com:80&#39;</span> --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654</div>
<div class="line">host $ sudo apt update</div>
<div class="line">host $ sudo apt install ros-melodic-desktop-full</div>
</div><!-- fragment --><p >Run ROS core: </p><div class="fragment"><div class="line">host $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> /opt/ros/melodic/setup.bash</div>
<div class="line">host $ roscore &amp;</div>
<div class="ttc" id="avin__init_8c_html_a07a87b2e6ed927503e2f95f119c9fc23"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a></div><div class="ttdeci">int source</div></div>
</div><!-- fragment --><p >Install PCL and RViz:</p>
<div class="fragment"><div class="line">host $ sudo apt-get install ros-melodic-pcl-ros</div>
<div class="line">host $ sudo apt-get install RViz</div>
</div><!-- fragment --><p >Compile host program:</p>
<div class="fragment"><div class="line">host $ mkdir -p ~/catkin_ws/src</div>
<div class="line">host $ cd ~/catkin_ws/src</div>
<div class="line">host $ catkin_init_workspace</div>
<div class="line">host $ cd ~/catkin_ws/</div>
<div class="line">host $ catkin_make</div>
<div class="line">host $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> devel/setup.bash</div>
<div class="line">host $ cd ~/catkin_ws/src</div>
<div class="line">host $ catkin_create_pkg amba_tof pcl_conversions pcl_ros pcl_msgs sensor_msgs</div>
<div class="line">host $ rospack profile</div>
<div class="line">host $ roscd amba_tof</div>
</div><!-- fragment --><p >copy amba_ros source code (ambarella/packages/depth_sensing_framework/ros/display_app) to ~/catkin_ws/src/amba_tof/</p>
<div class="fragment"><div class="line">host $ cd ~/catkin_ws/src/amba_tof/</div>
<div class="line">host $ vim CMakeLists.txt  (modify INCLUDE_DIR as your dir)</div>
<div class="line">host $ cd ~/catkin_ws</div>
<div class="line">host $ catkin_make --pkg amba_tof</div>
</div><!-- fragment --><h3><a class="anchor" id="run_ros_core"></a>
4.2.2 Run ROS Core</h3>
<div class="fragment"><div class="line">(<span class="keyword">new</span> terminal)</div>
<div class="line">host $ cd ~/catkin_ws</div>
<div class="line">host $ source devel/setup.bash</div>
<div class="line">host $ roscore</div>
</div><!-- fragment --><h3><a class="anchor" id="run_ros_app"></a>
4.2.3 Run ROS Application</h3>
<div class="fragment"><div class="line">(<span class="keyword">new</span> terminal)</div>
<div class="line">host $ source devel/setup.bash</div>
<div class="line">host $ rosrun amba_tof amba_ros_tof_socket 1555 --filterz 0.3-2</div>
</div><!-- fragment --><p> "--filterz 0.3,2" means that points within a specified range (0.3 to 2) will be retained, select proper size according to user scenario.</p>
<h3><a class="anchor" id="run_app_evk"></a>
4.2.4 Run Application in EVK</h3>
<p >Take IMX528 sensor as an example, copy the file below to “board/root”, “XXX” means the specific module or frequency:</p>
<div class="fragment"><div class="line">board $ ambarella/packages/depth_sensing_framework/conf/dsf_imx528_amba_XXX.lc</div>
<div class="line">board $ ambarella/prebuild/ambarella/library/amba_tof/board/imx528/amba_wiggle_offset.bin</div>
<div class="line">board $ ambarella/prebuild/ambarella/library/amba_tof/board/imx528/run_tof_528.sh</div>
<div class="line">board $ ambarella/prebuild/ambarella/library/amba_tof/board/imx528/cv2x_vin2_640x480_linear_raw_encode_327.lua</div>
</div><!-- fragment --><p >Then run amba_tof in board. </p><div class="fragment"><div class="line">board $ sh ./run_tof_528.sh</div>
<div class="line">board $ ./test_amba_dsf ./dsf_imx528_amba_XXX.lc</div>
</div><!-- fragment --><p> "test_amba_dsf dsf_imx528_amba_XXX.lc" will draw the depth with HDMI and send point cloud to ROS simultaneously. If encountering the error of socket connection, ensure that the IP in "dsf_imx528_amba_XXX.lc" is the same as host. Then open RViz to render point cloud data.</p>
<h3><a class="anchor" id="show_pt_ros"></a>
4.2.5 Show Point Cloud in ROS</h3>
<div class="fragment"><div class="line">(<span class="keyword">new</span> terminal)</div>
<div class="line">host $ rviz</div>
</div><!-- fragment --><p> The topic needs to be assigned in RViz. First, the "Fixed Frame" in "Displays" must be "amtf", and add "PointCloud2" display type as shown in the figure below.</p>
<div class="image">
<img src="../../rviz_set0.png" alt=""/>
<div class="caption">
Figure 4-2. Add Display Data.</div></div>
<p >Then set "Topic" in "PointCloud2" is "/tof_output", although the point cloud data can display in RViz now, there are some parameters to do adjustments to find best display performance as shown in the figure below.</p>
<div class="image">
<img src="../../rviz_set1.png" alt=""/>
<div class="caption">
Figure 4-3. Point Cloud Parameters.</div></div>
<p >The table below lists some important parameters for point cloud to display performance and recommended values, just for your information, select proper size according to user scenario.</p>
<a class="anchor" id="lib_depth_framewrok_rev_history"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Class </th><th align="left">Parameters </th><th align="left">Value </th><th align="left">Comment </th></tr>
<tr>
<td>Global options </td><td>Background color </td><td>48;48;48 </td><td>Dark colors are helpful for point cloud performance </td></tr>
<tr>
<td>Global options </td><td>Frame rate </td><td>30 </td><td>The frame rate of point cloud render in RViz, final frame rate is limited by ToF </td></tr>
<tr>
<td>Grid </td><td>Cell size </td><td>1 </td><td>The cell size of grid </td></tr>
<tr>
<td>Grid </td><td>Color </td><td>32;74;135 </td><td>Color of grid, dark colors are helpful for point cloud </td></tr>
<tr>
<td>Grid </td><td>Offset </td><td>0;0;-10 </td><td>Grid offset 10 in Z axis, prevent blocking point clouds </td></tr>
<tr>
<td>PointCloud2 </td><td>Topic </td><td>/tof_output </td><td>Monitor the point cloud data </td></tr>
<tr>
<td>PointCloud2 </td><td>Style </td><td>Points </td><td>Recommend </td></tr>
<tr>
<td>PointCloud2 </td><td>Size (pixels) </td><td>1.5 </td><td>Select proper size according to user scenario </td></tr>
<tr>
<td>PointCloud2 </td><td>Alpha </td><td>1 </td><td>The transparency of the point cloud, select proper size according to user scenario </td></tr>
<tr>
<td>PointCloud2 </td><td>Color transform </td><td>AxisColor </td><td>Colour according to the coordinates </td></tr>
<tr>
<td>PointCloud2 </td><td>Axis </td><td>Z </td><td>Colour according to the Z coordinates </td></tr>
<tr>
<td>PointCloud2 </td><td>Autocompute value </td><td>False </td><td>Manually set colour range in coordinates value </td></tr>
<tr>
<td>PointCloud2 </td><td>Min Value </td><td>0 </td><td>Select proper value according to user scenario </td></tr>
<tr>
<td>PointCloud2 </td><td>Max Value </td><td>3 </td><td>Select proper value according to user scenario </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="sec_display_on_windows"></a>
5. Display Point Cloud on Windows</h1>
<p >There is a tool to view point cloud on Windows: amba_3dviewer. The tool location is under <code>ambarella/packages/depth_sensing_framework/tools/amba_3dviewer/windows</code>. It works similarly to the ROS application and the following are examples of its use.</p>
<div class="fragment"><div class="line">widnows $ amba_3dviewer.exe</div>
</div><!-- fragment --><div class="fragment"><div class="line">widnows $ amba_3dviewer.exe &lt;port&gt;</div>
</div><!-- fragment --><div class="fragment"><div class="line">widnows $ amba_3dviewer.exe &lt;port&gt; --loglevel 4</div>
</div><!-- fragment --><hr  />
<h1><a class="anchor" id="sec_demo_app"></a>
6. Demo Application</h1>
<p >This chapter provides details on setting up the building environment and running the DSF demo. There are many examples that can guide users in running demos for different EVK and sensor boards.</p>
<h2><a class="anchor" id="demo_visiond"></a>
6.1 CV22 Vision D EVK + IMX528</h2>
<p >The Vision D EVK is a reference design platform based on the Ambarella CV22 Computer Vision (CV) SoC. Designed for three-dimensional sensing with a time-of-flight (ToF) sensor, Vision D is capable of generating point cloud / depth images for biometric identification, as well as gray-scale images for face detection and face recognition (FDFR). Additionally, the Vision D EVK serves as a reference development platform on which Ambarella users can build their own products / hardware designs, using the Vision D EVK as a software development / prototype platform. The final products have unique requirements, ranging from (but not limited to) the field of view (FoV) of the lens used, the baseline and ToF module design (thus, the operating range), the video image / anti-spoofing algorithms based on point cloud / depth information, and more. For an overview of the Vision D board and setting up the CV22 Vision D EVK hardware, refer to Setting Up the CV22 Vision D Hardware.</p>
<h3><a class="anchor" id="cv22_vision_d_build_img"></a>
6.1.1 Build Image on the Vision D EVK</h3>
<p >Refer to the <em>CV2x Linux SDK Release Notes</em> document for information relating to the toolchain and other software.<br  />
 To build an image on the Vision D EVK:</p><ul>
<li>Extract the latest SDK patch</li>
<li>Refer to the <code>readme.txt</code> file for the complete build process For further details, such as USB boot options, USB download, or force download, refer to Overview of the CV25M Aquaman Board.</li>
</ul>
<h3><a class="anchor" id="cv22_vision_d_compile_opts"></a>
6.1.2 Compile Options</h3>
<p >There is a default configuration file in the folder <code>$SDK/ambarella/boards/cv22_vision_d/config</code>, and the demo options are selected by default. Users can check them in <code>menuconfig</code>. </p><div class="fragment"><div class="line">build $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> ../../build/env/aarch64-linux5.4-gcc.env</div>
<div class="line">build $ make sync_build_mkcfg</div>
<div class="line">build $ make cv22s88_ipcam_config</div>
<div class="line">build $ make menuconfig</div>
</div><!-- fragment --><p> Options for DSF: </p><div class="fragment"><div class="line">[*] Ambarella Package Configuration  ---&gt;</div>
<div class="line">  [*]   Build Ambarella Depth Sensing Framework  ---&gt;</div>
<div class="line">    ... ...</div>
<div class="line">    [*]   Build example customized components <span class="keywordflow">for</span> DSF  ---&gt;</div>
<div class="line">      [*]   Build DSF component: Ambarella Od Yolov5</div>
<div class="line">      [*]   Build DSF component: Draw detection on fb</div>
<div class="line">      [*]   Build DSF component: Feed to efm</div>
<div class="line">    -*-   Build DSF Ambarella TOF Library support</div>
<div class="line">      [*]   Build Ambarella DSF Unit Test</div>
<div class="line">      [*]   Copy files <span class="keywordflow">for</span> DSF</div>
</div><!-- fragment --> <dl class="section note"><dt>Note</dt><dd>For SDK versions prior to 3.0.11, users must modify "SDK_VER_LESS_THAN_030011" in the makefiles shown below: <div class="fragment"><div class="line"><span class="comment">//SDK/ambarella/packages/depth_sensing_framework/unit_test/make.inc</span></div>
<div class="line">  SDK_VER_LESS_THAN_030011 := y</div>
<div class="line"><span class="comment">//SDK/ambarella/packages/depth_sensing_framework/source/make.inc</span></div>
<div class="line">  SDK_VER_LESS_THAN_030011 := y</div>
</div><!-- fragment --></dd></dl>
<h3><a class="anchor" id="cv22_vision_d_run_demo_app"></a>
6.1.3 Running Demo Applications</h3>
<p >Users can check the demo sample files in the Vision D board, and assume the firmware is correct. The file list is as follows: </p><div class="fragment"><div class="line">board # cd /root/data_files/sensor/demo_set_up/vision_d_pl528/20m</div>
<div class="line">board # ls</div>
<div class="line">calibration</div>
<div class="line">cv2x_vin2_640x480_linear_raw_encode.lua</div>
<div class="line">cv2x_vin2_640x480_linear_raw_encode_efm.lua</div>
<div class="line">dsf_imx528_amba_20m_dec_for_calib_laser.lc</div>
<div class="line">dsf_visiond_imx528_amba_20m_dec_for_calib.lc</div>
<div class="line">dsf_visiond_imx528_amba_20m_polig_fpr.lc</div>
<div class="line">dsf_visiond_imx528_amba_20m_polig_fpr_ros_yolo_efm.lc</div>
<div class="line">dsf_visiond_imx528_amba_20m_polig_fpr_yolo_efm.lc</div>
<div class="line">dsf_visiond_no_comp.lc</div>
<div class="line">run_tof_528_20m.sh</div>
<div class="line">run_tof_528_20m_visiond_efm.sh</div>
<div class="line">wiggle_offset.bin</div>
</div><!-- fragment --><h3><a class="anchor" id="cv22_vision_d_display_point_cloud"></a>
6.1.4 Display Point Cloud on Windows (Amba 3D Viewer)</h3>
<ol type="1">
<li>Run <code>amba_3dviewer.exe</code> on the PC. Users can find this application package in the folder <code>$SDK/ambarella/packages/depth_sensing_framework/tools/amba_3dviewer/windows/</code>.</li>
<li>Run the following script file on the Vision D board. <div class="fragment"><div class="line">board # cd /root/data_files/sensor/demo_set_up/vision_d_pl528/20m</div>
<div class="line">board # ./run_tof_528_20m.sh</div>
</div><!-- fragment --></li>
<li>Modify the DSF configuration file. For this demo, modify the file <code>dsf_visiond_imx528_amba_20m_polig_fpr.lc</code> and change the option setting for "remote_url" to match the internet protocol (IP) used by the PC that is running the <code>amba_3dviewer.exe</code> software. Users can refer to the Doxygen documents for more details regarding the parameters in the LC files.</li>
<li>Run the unit test application <code>test_amba_dsf</code>. <div class="fragment"><div class="line">board # test_amba_dsf dsf_visiond_imx528_amba_20m_polig_fpr.lc</div>
</div><!-- fragment --></li>
<li>View the image in Amba 3D Viewer (refer to <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#fig_cv22_vision_d_amba_3d_viewer">Figure 6-1</a>). <a class="anchor" id="fig_cv22_vision_d_amba_3d_viewer"></a><div class="image">
<img src="../../cv22_vision_d_amba_3d_viewer.jpg" alt=""/>
<div class="caption">
Figure 6-1. Image of the Amba 3D Viewer.</div></div>
 <br  />
</li>
</ol>
<h3><a class="anchor" id="cv22_vision_d_display_depth_yolov5_vlc"></a>
6.1.5 Display Depth with Yolov5 on VLC (Streaming)</h3>
<p >This sample teaches users how to demo depth via livestreaming. Users must prepare CV models and font files by themselves.</p><ol type="1">
<li>Run the following script file on the Vision D board. <div class="fragment"><div class="line">board # cd /root/data_files/sensor/demo_set_up/vision_d_pl528/20m</div>
<div class="line">board # ./run_tof_528_20m_visiond_efm.sh</div>
</div><!-- fragment --></li>
<li>Run the real-time streaming protocol (RTSP) server. <div class="fragment"><div class="line">board # rtsp_server &amp;</div>
</div><!-- fragment --></li>
<li>Modify the DSF configuration file.<br  />
 For this demo, <code>dsf_visiond_imx528_amba_20m_polig_fpr_yolo_efm.lc</code> must be modified to specify the yolov5 model path (i = ..., o = ..., model = ...) and font file path (font_file = ...), as shown below. Users can refer to the Doxygen documents for more details regarding the parameters in lc files. <div class="fragment"><div class="line">Stage</div>
<div class="line">  <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> = vca</div>
<div class="line">  component = od_yolov5</div>
<div class="line">  domain = jet</div>
<div class="line">  <a class="code hl_variableRef" target="_blank" href="../../../video/d9/dd6/overlay__cfg_8c.html#afd064c95beb16fddfd1fbf3754b12739">buffer_num</a> = 3</div>
<div class="line">  upstream_stage = normalization_jet</div>
<div class="line">  bypass = 0</div>
<div class="line">  i = /root/yolov5/nn/in/coco_class_names.txt</div>
<div class="line">  o = /root/yolov5/nn/out/result.txt</div>
<div class="line">  model = /root/yolov5/nn/model/onnx_yolov5s_cavalry.bin</div>
<div class="line">  type = s</div>
<div class="line">  f = 0.5</div>
<div class="line">  <a class="code hl_function" href="../../da/dae/group__cavalry__opt__layers-api-details.html#gaaebc4f5976b0ca899e54fa28ee499eb2">nms</a> = 0.3</div>
<div class="line">  top_k = 100</div>
<div class="line">  u = 0</div>
<div class="line">  tiny_enable = 0</div>
<div class="line">Stage</div>
<div class="line">  <a class="code hl_variable" href="../../d1/d82/cJSON_8h.html#a25d22ecc7e656d2c59332072684e8766">name</a> = combine_bbox</div>
<div class="line">  component = combine_depth_nv12_bbox</div>
<div class="line">  domain = jet</div>
<div class="line">  <a class="code hl_variableRef" target="_blank" href="../../../video/d9/dd6/overlay__cfg_8c.html#afd064c95beb16fddfd1fbf3754b12739">buffer_num</a> = 3</div>
<div class="line">  upstream_stage = normalization_jet</div>
<div class="line">  upstream_stage = vca</div>
<div class="line">  bypass = 0</div>
<div class="line">  font_file = /root/arial.ttf</div>
<div class="line">  enable_diagnosis = 0</div>
</div><!-- fragment --></li>
<li>Run unit test application: <code>test_amba_dsf</code>. <div class="fragment"><div class="line">board # test_amba_dsf dsf_visiond_imx528_amba_20m_polig_fpr_yolo_efm.lc</div>
</div><!-- fragment --></li>
<li>View the image in VLC (refer to <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#fig_cv22_vision_d_img_vlc">Figure 6-2</a>). <a class="anchor" id="fig_cv22_vision_d_img_vlc"></a><div class="image">
<img src="../../cv22_vision_d_img_vlc.jpg" alt=""/>
<div class="caption">
Figure 6-2. Image in VLC.</div></div>
 <br  />
</li>
</ol>
<h2><a class="anchor" id="demo_cv25_adi3500"></a>
6.2 CV25_hazelnut + ADI3500 Sensor</h2>
<h3><a class="anchor" id="demo_adi3500_build"></a>
6.2.1 Build Image on CV25_hazelnut</h3>
<p >Refer to the <em>CV2x Linux SDK Release Notes</em> document for information relating to the toolchain and other software.<br  />
 There is a default configuration file in the <code>$cv25_ipcam_depth_framework_tof_config</code>, and for detailed infomation, users can refer to <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#depth_framework_required_menuconfig">1.1.5 Depth Sensing Framework Required Menuconfig</a>.</p>
<div class="fragment"><div class="line">build $ <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> ../../build/env/aarch64-linux5.4-gcc.env</div>
<div class="line">build $ make sync_build_mkcfg</div>
<div class="line">build $ make cv25_ipcam_depth_framework_tof_config</div>
<div class="line">build $ make defconfig_public_linux</div>
<div class="line">build $ make menuconfig</div>
</div><!-- fragment --><div class="fragment"><div class="line">below option need select by hand in menuconfig.</div>
<div class="line">-&gt; Ambarella Linux Configuration (BUILD_AMBARELLA_LINUX_KERNEL [=y]) p(MIPI)</div>
<div class="line">    -&gt; Ambarella Private Drivers Configuration (BUILD_AMBARELLA_PRIVATE_MODULES [=y])</div>
<div class="line">        -&gt; Build Ambarella <span class="keyword">private</span> Vin modules (BUILD_AMBARELLA_VIN [=y])</div>
<div class="line">            -&gt; Ambarella TOF Sensor Configuration</div>
<div class="line">                [*] ADI ADSD3500+ADSD3100 1M TOF sensor/isp.</div>
<div class="line"> -&gt; Ambarella Package Configuration (BUILD_AMBARELLA_PACKAGE [=y]</div>
<div class="line">    -&gt; Build Ambarella Depth Sensing Framework</div>
<div class="line">        [*] Select Copy files <span class="keywordflow">for</span> DSF.</div>
<div class="line">        -&gt; Build vendors components <span class="keywordflow">for</span> DSF (BUILD_VENDORS_COMPONENTS [=y])</div>
<div class="line">            [*] Build DSF component: ADI depth compute engine.</div>
</div><!-- fragment --><p >Then, burn the image to cv25_hazelunt via amba_usb.</p>
<h3><a class="anchor" id="demo_adi3500_prepare"></a>
6.2.2 Prepare Related Files</h3>
<p >If the folder<code>$data_files</code> is not in <code>$board /root/</code>, users should copy <code>$ambarella/packages/depth_sensing_framework/data_files/sensor/demo_set_up/adsd3500</code> to <code>$board /root/</code>.</p>
<h3><a class="anchor" id="demo_adi3500_run"></a>
6.2.3 Running Demo Applications</h3>
<div class="fragment"><div class="line">QMP <span class="keywordflow">case</span> (InputFormat: raw8, Data Info: Depth16b+Conf8b+AB16b)</div>
<div class="line">board $ cd /root/data_files/sensor/demo_set_up/adsd3500/qmp_raw8_Depth16b+Conf8b+AB16b</div>
<div class="line">board $ sh ./run_adsd3500_qmp_raw8.sh</div>
<div class="line">board $ test_amba_dsf ./dsf_adsd3500_qmp8b_draw_ros.lc</div>
<div class="line"> </div>
<div class="line">MP <span class="keywordflow">case</span> (InputFormat: raw16_bits12_shift4, Data Info: Phase12b+AB12b)</div>
<div class="line">board $ cd /root/data_files/sensor/demo_set_up/adsd3500/mp_12t16bit_Phase12b+AB12b</div>
<div class="line">board $ sh ./run_adsd3500_mp.sh</div>
<div class="line">board $ test_amba_dsf ./dsf_adsd3500_mp12t16b_draw_ros.lc</div>
</div><!-- fragment --><p> Users will see the depth image via HDMI preview; refer to <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#fig_adsd3500_hdmi_depth">Figure 6-3</a>. <a class="anchor" id="fig_adsd3500_hdmi_depth"></a></p><div class="image">
<img src="../../fig_adsd3500_hdmi_depth.jpg" alt=""/>
<div class="caption">
Figure 6-3. Depth in HDMI Preview.</div></div>
<p> <br  />
 The point cloud data is display via amba_3dviewer; refer to <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#fig_adsd3500_3dpc">Figure 6-4</a>. Check the <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#sec_depth_disp_pc_on_ros">Display Point Cloud on ROS</a> for details on the robot operating system (ROS), or <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#sec_display_on_windows">Display Point Cloud On Windows</a> for amba_3dviewer. <a class="anchor" id="fig_adsd3500_3dpc"></a></p><div class="image">
<img src="../../fig_adsd3500_3dpc.jpg" alt=""/>
<div class="caption">
Figure 6-4. Point Cloud Data in amba_3dviewer.</div></div>
<p> <br  />
</p>
<h3><a class="anchor" id="demo_adi3500_performance"></a>
6.2.4 Performance on Boards</h3>
<p >The performance on CV25_hazelnut. </p><a class="anchor" id="table_demo_adi3500_performance_cv25hazelnut"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Sensor Resolution </th><th align="left">Data Information </th><th align="left">Input Format </th><th align="left">Data Size (byte) </th><th align="left">CPU (CV25) </th><th align="left">Time (stage) </th><th align="left">FPS </th></tr>
<tr>
<td>QMP (mode 7) </td><td>Depth16bit+Conf8bit+AB16bit </td><td>Raw8 (VIN treats the RAW8 as RAW16) </td><td>1,310,720 </td><td>9.5 % </td><td>8.46 ms </td><td>118.16 </td></tr>
<tr>
<td>Mp (mode 5) </td><td>Phase12bit+AB16bit </td><td>mipiRaw12_8 </td><td>6,815,744 </td><td>46.7 % </td><td>39.39 ms </td><td>25.38 </td></tr>
</table>
<p >The performance on CV2_chestnut. </p><a class="anchor" id="table_demo_adi3500_performance_cv2chestnut"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Sensor Resolution </th><th align="left">Data Information </th><th align="left">Input Format </th><th align="left">Data Size (byte) </th><th align="left">CPU (CV2) </th><th align="left">Time (stage) </th><th align="left">FPS </th></tr>
<tr>
<td>QMP (mode 7) </td><td>Depth16bit+Conf8bit+AB16bit </td><td>Raw8 (VIN treats the RAW8 as RAW16) </td><td>1,310,720 </td><td>45.8 % </td><td>7.48 ms </td><td>133.65 </td></tr>
<tr>
<td>Mp (mode 5) </td><td>Phase12bit+AB16bit </td><td>mipiRaw12_8 </td><td>6,815,744 </td><td>43.9 % </td><td>36.44 ms </td><td>27.44 </td></tr>
</table>
<p >The performance on CV5_timn. </p><a class="anchor" id="table_demo_adi3500_performance_cv5timn"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Sensor Resolution </th><th align="left">Data Information </th><th align="left">Input Format </th><th align="left">Data Size (byte) </th><th align="left">CPU (CV5) </th><th align="left">Time (stage) </th><th align="left">FPS </th></tr>
<tr>
<td>QMP (mode 7) </td><td>Depth16bit+Conf8bit+AB16bit </td><td>Raw8 (VIN treats the RAW8 as RAW16) </td><td>1,310,720 </td><td>4.0 % </td><td>5.10 ms </td><td>196.06 </td></tr>
<tr>
<td>Mp (mode 5) </td><td>Phase12bit+AB16bit </td><td>mipiRaw12_8 </td><td>6,815,744 </td><td>20.1 % </td><td>23.23 ms </td><td>43.04 </td></tr>
</table>
<h3><a class="anchor" id="demo_adi3500_TOFEngine"></a>
6.2.5 Time of Flight (ToF) Depth Compute Engine NXP</h3>
<p >"ToF depth compute engine" is a depth compute library which processes the raw frames captured by ADI ToF sensor module and generate confidence/depth/active-brightness and XYZ frames. More details about the ADI ToF depth compute engine, contact ADI support team or consult Ambarella support team.</p>
<hr  />
<h1><a class="anchor" id="sec_depth_performance"></a>
7. Performance</h1>
<p >In order to compare the performance intuitively, Ambarella sets a typically DSF pipline as shown in <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#fig_typically_pipline">Figure 7-1</a>. <a class="anchor" id="fig_typically_pipline"></a></p><div class="image">
<img src="../../fig_typically_pipline.jpg" alt=""/>
<div class="caption">
Figure 7-1. Typically DSF Pipline.</div></div>
<p >The performance of some ToF sensors on our chip.<br  />
 *cpu usage<br  />
 **Downsample to enhance the frame rate of "ros" stage</p>
<a class="anchor" id="table_ToFSensors_performance"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th colspan="3">Sensors </th><th colspan="3">Boards </th></tr>
<tr>
<th>Name </th><th>Resolution </th><th>Sensor FPS </th><th>CV25_hazelnut </th><th>CV5_timn </th><th>CV72_gage </th></tr>
<tr>
<td>IMX528 </td><td>640x480 </td><td>30 fps </td><td>14.86 fps, 45.3%* </td><td>17.64 fps, 24.2% </td><td>18.93 fps, 22.2% </td></tr>
<tr>
<td colspan="3" align="right">**Downsample to 320x240 </td><td>19.87 fps, 65.8% </td><td>20.11 fps, 31.0% </td><td>20.32 fps, 35.6% </td></tr>
<tr>
<td>IRS2877C </td><td>640x480 </td><td>15 fps </td><td>15.29 fps, 41.2% </td><td>14.34 fps, 17.2% </td><td>14.85 fps, 15.0% </td></tr>
</table>
<p >The visualization of video output (VOUT) and point cloud are as shown in <a class="el" href="../../df/d58/page_lib_depth_fw_doc.html#fig_vout_pointcloud">Figure 7-2</a>.<br  />
 *The quality of point cloud is related to the filters in DSF pipline. The point cloud in figure 7-2 adds some spatial filters and uses different filters to get a balance between frame rate and point cloud quality. <a class="anchor" id="fig_vout_pointcloud"></a></p><div class="image">
<img src="../../fig_vout_pointcloud.jpg" alt=""/>
<div class="caption">
Figure 7-2. HDMI VOUT and Point Cloud Data.</div></div>
 <hr  />
<h1><a class="anchor" id="sec_depth_api"></a>
8. ToF API</h1>
<p >Visit the following link to refer to details of the application programming interface (API) functions.</p>
<hr  />
<h1><a class="anchor" id="sec_depth_lic"></a>
9. License</h1>
<p >Copyright (c) 2024 Ambarella International LP.</p>
<p >This file and its contents ( "Software" ) are protected by intellectual property rights including, without limitation, U.S. and/or foreign copyrights. This Software is also the confidential and proprietary information of Ambarella International LP and its licensors. You may not use, reproduce, disclose, distribute, modify, or otherwise prepare derivative works of this Software or any portion thereof except pursuant to a signed license agreement or nondisclosure agreement with Ambarella International LP or its authorized affiliates. In the absence of such an agreement, you agree to promptly notify and return this Software to Ambarella International LP.</p>
<p >THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL AMBARELLA INTERNATIONAL LP OR ITS AFFILIATES BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; COMPUTER FAILURE OR MALFUNCTION; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3 </li>
  </ul>
</div>
</body>
</html>
