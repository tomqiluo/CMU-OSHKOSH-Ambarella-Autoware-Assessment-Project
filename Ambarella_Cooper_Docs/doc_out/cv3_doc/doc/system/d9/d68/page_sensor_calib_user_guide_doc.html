<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>System: DESIGN - Multiple Sensors Calibration</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<link rel="search" href="../../search_opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="System"/>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-ambarella.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../Ambarella.png"/></td>
  <td id="projectalign">
   <div id="projectname">System<span id="projectnumber">&#160;Cooper_1.6.0 (CV72 &amp; CV3) @ 2024.07.10 14:12:44</span>
   </div>
   <div id="projectbrief">placeholder</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,true,'search.html','Search');
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d9/d68/page_sensor_calib_user_guide_doc.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">DESIGN - Multiple Sensors Calibration </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="guide_sensor_calib_history"></a>
0. Revision History</h1>
<a class="anchor" id="Sensor calibration user guide"></a>
<table class="doxtable">
<caption></caption>
<tr>
<th>Tool Name </th><th>Tool Version </th><th align="left">Updated Date</th><th align="left">Tool Platform</th><th align="left">Modification </th></tr>
<tr>
<td>Lens_calib </td><td>0.0.1 </td><td>20210902 </td><td>armv8-a / x86 </td><td>Initial Version </td></tr>
<tr>
<td>Lens_calib </td><td>0.1.2 </td><td>20210921 </td><td>armv8-a </td><td>Refine lens calibration flow </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.1 </td><td>20210924 </td><td>x86 </td><td>Added Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_structure_light">Structured-light Parameters Pose Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.2 </td><td>20211102 </td><td>x86 </td><td>Add support for <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calibtof_temp_calib">Temperature Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.2 </td><td>20211124 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.2 </td><td>20211207 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_flow">Lens Calibration Flow</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.3 </td><td>20211210 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_flow">Lens Calibration Flow</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.3 </td><td>20211210 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_tool">Multi-Sensor Stitching Pose Calibration Tool</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.3 </td><td>20211216 </td><td>armv8-a / x86 </td><td>Updated Section <a class="elRef" target="_blank" href="../../../library/d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_introduction">Introduction</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.4 </td><td>20211216 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_flow">Lens Calibration Flow</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.4 </td><td>20211216 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_preparation">Calibration Preparation Work</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.4 </td><td>20220119 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.4 </td><td>20220119 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_stitch">Stitching Pose Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.4 </td><td>20220124 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_faq">Sensor Calibration FAQ</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.4 </td><td>20220126 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_faq">Sensor Calibration FAQ</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.5 </td><td>20220127 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.5 </td><td>20220211 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.5 </td><td>20220217 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> </td></tr>
<tr>
<td>Pose_calib </td><td>1.0.0 </td><td>20221130 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_dual_fish">Dual-fisheye back to back Pose Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.6 </td><td>20221201 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.7 </td><td>20230206 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> </td></tr>
<tr>
<td>Lens_calib </td><td>2.0.8 </td><td>20230208 </td><td>armv8-a / x86 </td><td>Updated Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> </td></tr>
</table>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_introduction"></a>
1. Introduction</h1>
<p >This chapter introduces the basic information on different sensor calibrations.</p><ul>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_preparation">2. Calibration Preparation Work</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">3. Lens Calibration</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_tof">4. ToF Calibration</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_tof_rgbd">5. RGBD Registration Calibration</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_stitch">6. Multi-sensor Stitching Pose Calibration</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_thermal_rgb">7. Thermal-RGB Fusion FoV-Alignment Calibration</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_mono_rgb">8. Mono-RGB Fusion FoV-Alignment Calibration</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_structure_light">9. Structured-light Parameters Pose Calibration</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_faq">11. Sensor Calibration FAQ</a></li>
<li>Section <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lic">12. License</a></li>
</ul>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_preparation"></a>
2. Calibration Preparation Work</h1>
<h2><a class="anchor" id="sensor_calib_prepare"></a>
2.1 Preparing Work</h2>
<ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calib_prepare_host">2.1.1 Host Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calib_prepare_board">2.1.2 Board Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calib_prepare_pat">2.1.3 Pattern Preparing Work</a></li>
</ul>
<h3><a class="anchor" id="sensor_calib_prepare_host"></a>
2.1.1 Host Calibration Tool</h3>
<p >Host calibration tool supports the following features : <br  />
</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">3. Lens Calibration</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_tof">4. ToF Calibration</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_tof_rgbd">5. RGBD Registration Calibration</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_structure_light">9. Structured-light Parameters Pose Calibration</a></li>
</ul>
<p >The host calibration tool is used to manage time-consuming problems. <br  />
 Ambarella supports performing both lens and pose calibration on the PC Linux side and on the Windows side. <br  />
 Ambarella recommends performing lens / pose calibration on the PC Windows side to save environment installation time. <b>(1) PC Windows side lens calibration tool:</b> <br  />
 Windows environment: Win10, x64 <br  />
 Lens calibration tools: cv2x_cv5x_lens_calibration_tool_for_windows_vx.x.x_x.tar.bz2 <br  />
 Pose calibration tools: cv2x_cv5x_pose_calibration_tool_for_windows_vx.x.x_x.tar.bz2 <br  />
 If users want to perform calibration on the PC Windows side, they must ask the Ambarella support team for the required tools.</p>
<p ><b>(2) PC Linux side lens calibration tool:</b> <br  />
 The lens calibration tool is in the path below: <br  />
 ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool <br  />
 Some descriptions of the key libraries of the calibration are as follows : <br  />
 </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Name   </th><th class="markdownTableHeadCenter">Version   </th><th class="markdownTableHeadCenter">Calibration type    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">OpenCV   </td><td class="markdownTableBodyCenter">3.2.0   </td><td class="markdownTableBodyCenter">ALL    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Apriltag   </td><td class="markdownTableBodyCenter">2018-11-29   </td><td class="markdownTableBodyCenter">Lens / multi-sensor pose / structured-light pose calibration    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Ceres solver   </td><td class="markdownTableBodyCenter">1.14.0   </td><td class="markdownTableBodyCenter">Binocular    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Python   </td><td class="markdownTableBodyCenter">2.7   </td><td class="markdownTableBodyCenter">ToF    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Matplotlib   </td><td class="markdownTableBodyCenter">&ndash;   </td><td class="markdownTableBodyCenter">ToF   </td></tr>
</table>
<ol type="1">
<li>Install the dependency libraries. <div class="fragment"><div class="line">build $ sudo ./host_tool_install.sh</div>
</div><!-- fragment --></li>
<li>The calibration is based on the OpenCV 3.2.0 version. Ensure that the correct version for OpenCV is installed on the host Ubuntu building machine. Use the following reference to install the OpenCV package. First, download the opencv3.2.0.tar.gz source code package from the website: <a href="https://opencv.org/opencv-3-2.html">https://opencv.org/opencv-3-2.html</a>. <div class="fragment"><div class="line">build $ tar -xzvf opencv-3.2.0.tar.gz</div>
<div class="line">build $ cd opencv-3.2.0/</div>
<div class="line">build $ sudo mkdir -p build</div>
<div class="line">build $ cd build/</div>
<div class="line">build $ cmake ../</div>
<div class="line">build $ sudo sudo make</div>
<div class="line">build $ sudo make install</div>
</div><!-- fragment --></li>
<li>Users should also install the apriltag library to use the circle target, and the version should be apriltag-2018-11-29. Save the library in the path multi_sensor_calib/host_calib_tool/third_party . Compress it and run, as follows: <div class="fragment"><div class="line">build $ sudo make all</div>
<div class="line">build $ sudo make install</div>
</div><!-- fragment --></li>
<li>If users want to perform binocular calibration, Ceres Solver is required for installation. Ceres Solver is used for optimization; download it from <a href="https://github.com/ceres-solver/ceres-solver">https://github.com/ceres-solver/ceres-solver</a>. Ambarella uses version 1.14.0. Some dependencies can be refered to host_tool_install.sh. Compress it and run: <div class="fragment"><div class="line">build $ sudo cmake ../ceres-solver-1.14.0</div>
<div class="line">build $ sudo make</div>
<div class="line">build $ sudo make install</div>
</div><!-- fragment --></li>
<li>If users want to perform time of flight (ToF) calibration, users must install the library: <div class="fragment"><div class="line">build $ sudo pip install matplotlib</div>
</div><!-- fragment --></li>
</ol>
<h3><a class="anchor" id="sensor_calib_prepare_board"></a>
2.1.2 Board Calibration Tool</h3>
<p >Libsensor_calib.so is the tool, which supports the following features: : <br  />
</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_stitch">6. Multi-sensor Stitching Pose Calibration</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_thermal_rgb">7. Thermal-RGB Fusion FoV-Alignment Calibration</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_mono_rgb">8. Mono-RGB Fusion FoV-Alignment Calibration</a></li>
</ul>
<p >The calibration tool should be configured in menuconfig. Follow the instructions as shown below </p><dl class="section user"><dt>For CV2x SDK 3.0 Amba build:</dt><dd><div class="fragment"><div class="line">Configure libsensor_calib.so.</div>
<div class="line">build # make menuconfig</div>
<div class="line">[*] Ambarella Prebuild  ---&gt;</div>
<div class="line">    [*] Configure Ambarella sensor calibration library</div>
<div class="line"> </div>
<div class="line">Configure test_stitch and libstitch.so.</div>
<div class="line">build # make menuconfig</div>
<div class="line">[*] Ambarella Prebuild  ---&gt;</div>
<div class="line">    [*] Configure Ambarella stitch library</div>
<div class="line"> </div>
<div class="line">Configure test_sensor_calib and libmsc_ini.so.</div>
<div class="line">build # make menuconfig</div>
<div class="line">[*]  Ambarella Package Configuration  ---&gt;</div>
<div class="line">     -*-   Build Ambarella sensor calibration ini parser library</div>
<div class="line"> </div>
<div class="line">Users must specify the maximum <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a01b4671c6b7cc8f831c951c000a37735">number</a> accordingly.</div>
<div class="line">build # make menuconfig</div>
<div class="line">    drv_modules  ---&gt;</div>
<div class="line">         <span class="keyword">private</span>  ---&gt;</div>
<div class="line">          -*- ambvideo-header (drv_modules/<span class="keyword">private</span>/video/dsp_v6)  ---&gt;</div>
<div class="line">              (4)   Max VIN Channel Number</div>
<div class="ttc" id="acJSON_8h_html_a01b4671c6b7cc8f831c951c000a37735"><div class="ttname"><a href="../../../library/d1/d82/cJSON_8h.html#a01b4671c6b7cc8f831c951c000a37735">number</a></div><div class="ttdeci">const char *const const double number</div></div>
<div class="ttc" id="avin__init_8c_html_adf7dff2c57c0da9a4a2b70e3e815be31"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a></div><div class="ttdeci">int channel</div></div>
</div><!-- fragment --></dd></dl>
<dl class="section user"><dt>For Cooper Amba build:</dt><dd><div class="fragment"><div class="line">Configure test_sensor_calib and libsensor_calib.so</div>
<div class="line">build # make menuconfig</div>
<div class="line">    prebuild ---&gt;</div>
<div class="line">      library ---&gt;</div>
<div class="line">        [*] prebuild-sensorcalib (prebuild/library/multi_sensor_calib/dsp_v5)</div>
<div class="line">        [*] sensorcalib-test (prebuild/library/multi_sensor_calib/dsp_v5)</div>
<div class="line"> </div>
<div class="line">Configure test_stitch and libstitch.so</div>
<div class="line">build # make menuconfig</div>
<div class="line">    prebuild ---&gt;</div>
<div class="line">      library ---&gt;</div>
<div class="line">        [*] prebuild-stitch (prebuild/library/stitch_algo/dsp_v5)</div>
<div class="line">        [*] stitch-test (prebuild/library/stitch_algo/dsp_v5)</div>
<div class="line"> </div>
<div class="line">Configure libmsc_ini.so</div>
<div class="line">build # make menuconfig</div>
<div class="line">    <span class="keyword">package </span>---&gt;</div>
<div class="line">      [*] libmsc (packages/sensor_calib_ini_parser/armv8-a)</div>
<div class="line"> </div>
<div class="line">Users must specify the maximum channel number accordingly.</div>
<div class="line">build # make menuconfig</div>
<div class="line">    drv_modules ---&gt;</div>
<div class="line">      private ---&gt;</div>
<div class="line">        -*- ambavideo-header (drv_modules/private/video/dsp_v5) ---&gt;</div>
<div class="line">          (4) Max VIN Channel Number</div>
</div><!-- fragment --></dd></dl>
<p>The board calibration tool is in the path <br  />
 ambarella/prebuild/ambarella/library/multi_sensor_calib/lib/armv8-a/ <br  />
 The source code of application "test_sensor_calib" is in the path <br  />
 ambarella/unit_test/private/package_test/arch_v5/test_sensor_calib.cpp <br  />
</p>
<h3><a class="anchor" id="sensor_calib_prepare_pat"></a>
2.1.3 Pattern Preparing Work</h3>
<p >Users require different patterns for different calibrations. <br  />
 Some descriptions of the key points detection method of the calibration are as follows <br  />
 </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Calibration Type   </th><th class="markdownTableHeadCenter">Tool (Pattern)    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Lens   </td><td class="markdownTableBodyCenter">Circle board / chessboard    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">ToF   </td><td class="markdownTableBodyCenter">Laser board / chessboard    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">RGBD   </td><td class="markdownTableBodyCenter">chessboard    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Stitch pose   </td><td class="markdownTableBodyCenter">Circle board / chessboard    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Thermal-RGB   </td><td class="markdownTableBodyCenter">Choose the points manually    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">Mono-RGB   </td><td class="markdownTableBodyCenter">Akaze algorithm to detect the keypoints automatically    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">Structured-light   </td><td class="markdownTableBodyCenter">Circle board   </td></tr>
</table>
<div class="image">
<img src="../../circle_pattern.jpg" alt=""/>
<div class="caption">
Figure 2-1. Circle Pattern.</div></div>
 <div class="image">
<img src="../../chess_pattern.jpg" alt=""/>
<div class="caption">
Figure 2-2. Chess Pattern.</div></div>
<p> In order to maintain accuracy, Ambarella recommends following the rules below. <br  />
</p><ul>
<li>Paste the pattern flat on the board <br  />
</li>
<li>Use sufficient amounts of light <br  />
</li>
</ul>
<p >The circle pattern image shows each calibration board contains four April tags and many circles. <br  />
 <b>Key notes for the circle board:</b></p><ul>
<li>The diameter of each circle in the picture is between 15 and 20 pixels (20 is ideal, 10-20 is also sufficient). A larger size can cause loss in accuracy.</li>
<li>Ambarella recommends using at least one April tag in each image.</li>
<li>When the pattern board is sufficiently rigid and flat, users should use a ruler to measure the horizontal length (width) between the horizontal triangle strip-line symbols and <br  />
 the vertical length (height) between the vertical triangle strip-line symbols. <br  />
 Based on this data, users can obtain an average distance between the adjacent circles for the horizontal and vertical directions in order to increase accuracy. The example below is in meters. <br  />
 Horizontal spacing = width / 46 <br  />
 Vertical spacing = height / 32 <br  />
 <b>Lens calibration:</b> Fill the spacing command information "-tag_info_list" for the application "lens_calib.exe" in run_xx_circle_xx.bat. <br  />
 <b>Pose calibration:</b> Fill the spacing command information "-tag_info" for the application "test_sensor_calib.exe" in sensor_calib_ini_pose_calibration_save_target_xx.ini or command line directly. <br  />
 <hr  />
</li>
</ul>
<h1><a class="anchor" id="guide_sensor_calib_lens"></a>
3. Lens Calibration</h1>
<p >This chapter describes the following concepts:</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_principle">3.1 Lens Calibration Principle</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_tool">3.2 Lens Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_flow">3.3 Lens Calibration Flow</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_result">3.4 Lens Calibration Result</a></li>
</ul>
<h2><a class="anchor" id="lens_calib_principle"></a>
3.1 Lens Calibration Principle</h2>
<p >Users should perform lens calibration to remove distortions because there are radial and tangential distortions for each lens. </p><div class="image">
<img src="../../distortion.jpg" alt=""/>
<div class="caption">
Figure 3-1. Distortion for Lens.</div></div>
<p> The image above shows that the table will be twisted because of lens distortion. This chapter provides information on how to perform lens calibration.</p>
<h2><a class="anchor" id="lens_calib_tool"></a>
3.2 Lens Calibration Tool</h2>
<p >Ambarella supports performing lens calibration on both the PC Linux side and on the Windows side. Users can obtain lens calibration applications for the Windows side in the path below:. <br  />
 Environment: Win10, x64 Tool: cv2x_cv5x_lens_calibration_tool_for_windows_vx.x.x_x.tar.bz2</p>
<h2><a class="anchor" id="lens_calib_flow"></a>
3.3 Lens Calibration Flow</h2>
<p ><b>Multi-channel stitching lens calibration strategy:</b> Ambarella recommends performing full calibration for the specific lens (with <b>60+</b> images) and <br  />
 perform fast calibration for the other channel (as in case 7 mentioned above, the results of full calibration are used as initial parameters to estimate other lenses).</p>
<div class="image">
<img src="../../lens_calib.jpg" alt=""/>
<div class="caption">
Figure 3-2. Calibration for Pinhole Lens.</div></div>
<p> <b>1) Capture image sets</b><br  />
 The image above shows some pattern's positions when users perform the calibration. Ambarella suggests using the Zhang Zhengyou calibration method for pinhole and fisheye lens. It is recommended to use omnidirectional calibration method when the FoV is greater than 180 degrees. The calibration process requires users to capture more than <b> 60 </b> pictures as shown in the image. <br  />
 Key points for lens calibration:</p><ul>
<li>The diameter of each circle in the picture is between 15 and 20 pixels (20 is ideal, 10-20 is also sufficient). A larger diameter will cause loss in accuracy.</li>
<li>Ambarella recommends using at least one April tag for each image.</li>
<li>Cover images in different parts of the FoV.</li>
<li>If users must quickly perform calibration, Ambarella recommends covering many targets in the image.</li>
<li>The tool supports both chessboard and circle patterns to perform calibration.</li>
<li>Ambarella recommends capturing images at three different distances, such as 1.5 / 2 / 2.5 meters.</li>
<li>Move the board in different angles (pitch / roll / yaw); however, the angles should not be too large. Refer to the image above.</li>
<li>The tool supports performing lens calibration with multiple patterns in one image.</li>
</ul>
<p >For CV2x, the user should copy get_frame.sh and calib_3x_chan.lua/calib_4x_chan.lua to the "/root" directory of the board. <br  />
 For CV5x, the user should copy yuv_capture.sh and cv5x_4vin_capture_yuv.lua to the "/root" directory of the board. <br  />
 yuv_capture.sh is used to capture YUV data for each channel. <br  />
 The scripts creates in ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/script/stitch/cvxx/capture. <br  />
 CV2x: <br  />
 </p><div class="fragment"><div class="line">board # cd /root</div>
<div class="line">board # init.sh --na &amp;&amp; modprobe imx335_mipi vinc_id=0xf1320 slave=1 (the user should modify the command accordingly)</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board # test_encode -i 0 --enc-mode 0 --debug-stitched 1 --vsync-detect-disable 0 --resource-cfg calib_4x_chan.lua --raw-capture 1</div>
<div class="line">board # test_encode -A -h 1920x1080 -b 0 --rotate 1 -e -B -h 1920x1080 -b 1 --rotate 1 -e -C -h 1920x1080 -b 2 --rotate 1 -e -D -h 1920x1080 -b 3 --rotate 1 -e (the user should modify the command accordingly)</div>
<div class="line">board # ./get_frame.sh 3 0 15</div>
<div class="line">The first option <span class="stringliteral">&quot;3&quot;</span> is the <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a01b4671c6b7cc8f831c951c000a37735">number</a> of channels.</div>
<div class="line">The second option: 0: capture YUV and JPEG</div>
<div class="line">                   1: capture JPEG (Suggested, should enter the encoding state first)</div>
<div class="line">                   2: capture YUV</div>
<div class="line">The third option <span class="stringliteral">&quot;3&quot;</span> is the <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a01b4671c6b7cc8f831c951c000a37735">number</a> of JPEG / YUV data to be captured.</div>
</div><!-- fragment --><p >CV5x: <br  />
 </p><div class="fragment"><div class="line">board # cd /root</div>
<div class="line">board # modprobe ambrg</div>
<div class="line">board # modprobe max9296 <span class="keywordtype">id</span>=0x0303 vinc_id=0xb8</div>
<div class="line">board # modprobe os08a10_mipi_brg fsync=1</div>
<div class="line">board # test_aaa_service -a&amp;</div>
<div class="line">board # test_encode --resource-cfg cv5x_4vin_capture_yuv.lua --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-capture 1</div>
<div class="line">board # ./yuv_capture.sh 0 0 30</div>
<div class="line">The first option <span class="stringliteral">&quot;0&quot;</span> is the <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a01b4671c6b7cc8f831c951c000a37735">number</a> of channels.</div>
<div class="line">The second option <span class="stringliteral">&quot;0&quot;</span> is the start <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a750b5d744c39a06bfb13e6eb010e35d0">index</a>.</div>
<div class="line">The third option <span class="stringliteral">&quot;30&quot;</span> is the end endex.</div>
<div class="ttc" id="acJSON_8h_html_a750b5d744c39a06bfb13e6eb010e35d0"><div class="ttname"><a href="../../../library/d1/d82/cJSON_8h.html#a750b5d744c39a06bfb13e6eb010e35d0">index</a></div><div class="ttdeci">int index</div></div>
<div class="ttc" id="acJSON_8h_html_a788db922597cf2fb6389e278f822e59f"><div class="ttname"><a href="../../../library/d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a></div><div class="ttdeci">const char *const const char *const raw</div></div>
</div><!-- fragment --><p >This script will create sub-folders under the "/tmp" folder with the name "calib_data". After the picture capture process is complete, copy the calib_data folders to the building machine in the "host_calib_tool/" folder. Commands are as follows:</p>
<p ><b>2) Perform the full lens calibration at the PC Windows side</b> <br  />
 Some descriptions of the parameters can be found in ".bat". </p><table class="markdownTable">
<tr class="markdownTableHead">
<th class="markdownTableHeadCenter">Options   </th><th class="markdownTableHeadCenter">Tool (Pattern)    </th></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">opt   </td><td class="markdownTableBodyCenter">Specify the focal length of the lens (mm x 10)    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">cel_size   </td><td class="markdownTableBodyCenter">Specify the cell size of the sensor    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">debug   </td><td class="markdownTableBodyCenter">Bit 0: show outlier information. Bit 1: show undistorted image. Bit 2: show tag information. Bit 3: show grid image. Bit 4:: show circle / object information.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">chess_w / chess_h   </td><td class="markdownTableBodyCenter">Specify the chessboard width / height    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">start / end   </td><td class="markdownTableBodyCenter">Specify the start / end index for lens calibration    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">pic_format   </td><td class="markdownTableBodyCenter">Specify the pictures format    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">input_folder   </td><td class="markdownTableBodyCenter">Specify the folder of the "jpeg / png" format images    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">tag_info_list   </td><td class="markdownTableBodyCenter">Set the April tag information    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">dst   </td><td class="markdownTableBodyCenter">Set the maximum distance in circle detection    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">yuv_w / yuv_h   </td><td class="markdownTableBodyCenter">Set the YUV width / height    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">read_calib   </td><td class="markdownTableBodyCenter">Specify performance of fast lens calibration    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">fix_distort   </td><td class="markdownTableBodyCenter">Specify use of full lens calibration's distortion parameters    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">expand_fov   </td><td class="markdownTableBodyCenter">0: normal intrinsic parameters, 1: horizontal optimization parameters, 2: vertical optimization parameters, 3: horizontal optimization.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">k1 / k2 / k3 / k4 / k5 / k6 / k7   </td><td class="markdownTableBodyCenter">Set the distortion parameter "k" to 0. Ambarella suggests setting k4 / k5 / k6 when the lens is a low-distortion pinhole lens    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">save_undistort_map   </td><td class="markdownTableBodyCenter">Specify saving the undistorted x/y map.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">slope_ratio   </td><td class="markdownTableBodyCenter">Set the maximum slope difference with the basis when removing the wrong connection    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">start_ratio   </td><td class="markdownTableBodyCenter">Set the vector maximum ratio when detecting the origin.    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">line_ratio   </td><td class="markdownTableBodyCenter">Set the threshold of removing the wrong connection in the incline direction    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">min_area   </td><td class="markdownTableBodyCenter">Set the threshold for detecting small radius circle on the calibration pattern    </td></tr>
<tr class="markdownTableRowEven">
<td class="markdownTableBodyCenter">lens_mode   </td><td class="markdownTableBodyCenter">Set the lens calibration mode. 0: fisheye KB mode, 1: fisheye MEI mode, 2: fisheye OCAM mode, 3: PINHOLE    </td></tr>
<tr class="markdownTableRowOdd">
<td class="markdownTableBodyCenter">map_align   </td><td class="markdownTableBodyCenter">Specify the alignment for the undistorted x/y map to be saved   </td></tr>
</table>
<div class="fragment"><div class="line">host (Windows) $ Decompress cv2x_cv5x_lens_calibration_tool_for_windows_vx.x.x_x.tar.bz2</div>
<div class="line">Case 1: <span class="keywordflow">do</span> full lens calibration <span class="keywordflow">for</span> lens 1 with chessboard pattern in YUV or JPG <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>.</div>
<div class="line">host (Windows) $ run_calib_chess_jpg.bat (Suggested)</div>
<div class="line">host (Windows) $ run_calib_chess_yuv.bat</div>
<div class="line">Case 2: <span class="keywordflow">do</span> full lens calibration <span class="keywordflow">for</span> lens 1 with circle pattern in YUV <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>.</div>
<div class="line">host (Windows) $ run_calib_circle_yuv.bat</div>
<div class="line">Case 3: <span class="keywordflow">do</span> full lens calibration <span class="keywordflow">for</span> lens 1 with multiple circle patterns in JPEG <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>.</div>
<div class="line">host (Windows) $ run_calib_mutli_board.bat</div>
<div class="line">It is suggested to set expand_fov as 1 <span class="keywordflow">for</span> horizontal stitching, and expand_fov as 2 <span class="keywordflow">for</span> vertical stitching when</div>
<div class="line">option <span class="stringliteral">&quot;debug&quot;</span> is set to show undistort images.</div>
<div class="line">Case 4: <span class="keywordflow">do</span> full lens calibration <span class="keywordflow">for</span> fisheye lens in JPEG <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a>.</div>
<div class="line">host (Windows) $ run_calib_chess_jpg_fisheye.bat</div>
<div class="ttc" id="acJSON_8h_html_adb411a44855a4c49231d72a0fc9a3b3b"><div class="ttname"><a href="../../../library/d1/d82/cJSON_8h.html#adb411a44855a4c49231d72a0fc9a3b3b">format</a></div><div class="ttdeci">char const int const cJSON_bool format</div></div>
</div><!-- fragment --><p> The intrinsic parameters for specified lens will be stored in the relative path lens_calib1/out/front_end/intrinsic_0</p>
<p ><b>3) Perform the fast lens calibration at the PC Windows side (using a four-channel stitching as an example)</b> <br  />
 Fast calibration uses the full calibration's intrinsic as initial parameters to estimate the other lens. The tool supports performing fast calibration with only a few images (3 - 4). Ambarella recommends placing the calibration board in the left / middle / right of the image. <br  />
</p>
<div class="image">
<img src="../../multi_board.jpg" alt=""/>
<div class="caption">
Figure 3-3. Fast Calibration with Multiple Calibration Boards.</div></div>
<p> The tool supports performing fast calibration with many patterns in one image. <br  />
</p><ul>
<li>Use different April tag IDs for each calibration board. <br  />
</li>
<li>Keep the boards in different angles (pitch / yaw / roll). The angles should not be too large; refer to the image above. <br  />
</li>
</ul>
<div class="fragment"><div class="line">host (Windows) $ Decompress cv2x_cv5x_lens_calibration_tool_for_windows_vx.x.x_x.tar.bz2</div>
<div class="line">Case 1: <span class="keywordflow">do</span> fast lens calibration <span class="keywordflow">for</span> lens 1 with 3 images (single calibration board).</div>
<div class="line">host (Windows) $ Copy <span class="stringliteral">&quot;calib_example\circle\lens1\out\front_end&quot;</span> to <span class="stringliteral">&quot;calib_example\circle\lensx\out\front_end&quot;</span>.(lensx: <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> = 0, 1, 2, 3)</div>
<div class="line">host (Windows) $ cd <span class="stringliteral">&quot;calib_example\circle\lensx\out\front_end&quot;</span> (lensx: <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> = 0, 1, 2, 3)</div>
<div class="line">host (Windows) $ Create folder <span class="stringliteral">&quot;initial&quot;</span></div>
<div class="line">host (Windows) $ Copy <span class="stringliteral">&quot;intrinsic_0&quot;</span> generated in the stage of full lens calibration to the folder <span class="stringliteral">&quot;initial&quot;</span>.</div>
<div class="line">host (Windows) $ Edit <span class="stringliteral">&quot;run_fast_calib_circle_yuv.bat&quot;</span> and modify -folder=<span class="stringliteral">&quot;../calib_example/circle/lens1&quot;</span> to -folder=<span class="stringliteral">&quot;../calib_example/circle/lensx&quot;</span>. (lensx: <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> = 0, 1, 2, 3)</div>
<div class="line">host (Windows) $ Edit <span class="stringliteral">&quot;run_fast_calib_circle_yuv.bat&quot;</span> and modify -yuv_name=<span class="stringliteral">&quot;1_canvas1_wxh_NV12&quot;</span> to -yuv_name=<span class="stringliteral">&quot;x_canvasx_wxh_NV12&quot;</span>. (canvasx: <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> = 0, 1, 2, 3)</div>
<div class="line">host (Windows) $ Double click <span class="stringliteral">&quot;\script\run_fast_calib_circle_yuv.bat&quot;</span></div>
<div class="line">host (Windows) $ Rename <span class="stringliteral">&quot;calib_example\circle\lensx\out\front_end\intrinsic_0&quot;</span> as <span class="stringliteral">&quot;intrinsic_x&quot;</span>. (lensx: <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> = 0, 1, 2, 3), (intrinsic_x: <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> = 0, 1, 2, 3)</div>
<div class="line">Case 2: <span class="keywordflow">do</span> fast lens calibration <span class="keywordflow">for</span> lens with 1 image only.  (four calibration boards included).</div>
<div class="line">host (Windows) $ Double click <span class="stringliteral">&quot;\script\run_fast_calib_circle_multi_board_yuv.bat&quot;</span></div>
<div class="ttc" id="agroup__IAV_html_gaf80df1bdae91e5f76236e6ed1110825d"><div class="ttname"><a href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a></div><div class="ttdeci">u32 x</div></div>
</div><!-- fragment --><p >Note that if users want to apply lens calibration parameters after fast calibration, they must generate pose calibration parameters again for all channels based on new lens calibration parameters. Then, place all channels' results to the "front_end" folder. Copy the "front_end" folder to the board, and apply the parameters then: </p><div class="fragment"><div class="line">It is assumed that the parameters will be applied on channels 0, 1, 2, and 3.</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 4 -f ./</div>
<div class="line">board # test_stitch --mode 2 -f . --no-overlap --fuse-<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> 0xf (no overlap part)</div>
<div class="line">board # test_stitch --mode 2 -f . (overlap)</div>
</div><!-- fragment --><h2><a class="anchor" id="lens_calib_result"></a>
3.4 Lens Calibration Result</h2>
<div class="image">
<img src="../../before_after_ldc.jpg" alt=""/>
<div class="caption">
Figure 3-4. Before and After Lens Distortion Calibration.</div></div>
<p> The image shows the contrast result after applying the calibration intrinsic and distortion paramters. <br  />
 The curved line becomes a straight line.</p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_tof"></a>
4. ToF Calibration</h1>
<p >This chapter describes the following conceptions:</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#tof_principle">4.1 ToF Calibration Principle</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#tof_tool">4.2 ToF Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#tof_flow">4.3 ToF Calibration Flow</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#tof_result">4.4 ToF Calibration Result</a></li>
</ul>
<h2><a class="anchor" id="tof_principle"></a>
4.1 ToF Calibration Principle</h2>
<p >Users should perform the calibration as shown in the steps below: <br  />
 <b>1) Lens calibration</b> <br  />
 This calibration is used to remove the lens' distortion; each pixel will be converted into the ideal coordinate in the pin-hole model. <br  />
 Refer to <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">2. Lens Calibration</a> for more details of removing the distortion. <br  />
 <b>2) Temperature calibration</b> <br  />
 There is a phase drift introduced by the temperature. It is a linear drift in distance. Temperature calibration is used to remove such problem by doing curve-fitting. <br  />
 <b>3) Global calibration</b> <br  />
 There is a global offset between the measured distance and the real distance. <br  />
 Users just need the chessboard or some other calibration targets to do extrinsic calibration and get ground truth distance. <br  />
 <b>4) Wiggling calibration</b> <br  />
 The phase delay can not be calculated correctly because the modulation wave shape is not as perfect as the sinusoidal shape. <br  />
 The imperfect phase will introduce the wiggling errors for different distances. Wiggling calibration is used to remove such problem. <br  />
</p>
<h2><a class="anchor" id="tof_tool"></a>
4.2 ToF Calibration Tool</h2>
<p >Path: ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/bin/x86_64 <br  />
 Path: ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/script/tof <br  />
 Tool: create_xml / lens_cali / tof_cali / do_temp_calib.py <br  />
</p>
<h2><a class="anchor" id="tof_flow"></a>
4.3 ToF Calibration Flow</h2>
<p >It is assumed that the lens calibration has been completed perfectly before this stage; the section introduces the flow of ToF calibration.</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calibtof_temp_calib">4.3.1 Temperature Calibration</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calibtof_global_calib">4.3.2 Global Calibration</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calibtof_wiggle_calib">4.3.3 Wiggling Calibration</a></li>
</ul>
<h3><a class="anchor" id="sensor_calibtof_temp_calib"></a>
4.3.1 Temperature Calibration</h3>
<p >Temperature calibration performs curve-fitting to find good coefficients used in compensation. <br  />
 It is assumed that the calibration data has been stored in accuracy.csv. <br  />
 Modify x = range(37, 48) in do_temp_calib.py for the specific temperature range from the accuracy.csv file. The users can also ignore the bad statics by setting the range. </p><div class="fragment"><div class="line">host # python3 do_temp_calib.py</div>
</div><!-- fragment --> <div class="image">
<img src="../../temp_offset.jpg" alt=""/>
<div class="caption">
Figure 4-1. Temperature Calibration Fitting.</div></div>
<p> The first temperature value 37 of x = range(37, 48) is used as the base, and the image shows the fitting result by using the mean distance difference of the base. <br  />
 The tool reports the result: <br  />
 temp_mean0_base: 37 <br  />
 temp_mean0_distance: 0.12938596591621487 <br  />
 line_slopy: 0.00034453650504337203 <br  />
 base: -0.012889773367656475 <br  />
 "temp_mean0_base" is the temperature compensation base of the calibration. <br  />
 "line_slopy" and "base" are the curve-fitting coefficients used for compensation. <br  />
 Fill the parameters "line_slopy" and "base" to amba_itof_decoder or amba_itof_dec_for_calib stage in the .lc file to perform the temperature compensation. <br  />
</p>
<h3><a class="anchor" id="sensor_calibtof_global_calib"></a>
4.3.2 Global Calibration</h3>
<p >There is a global offset between the measured distance and the real distance. <br  />
 <b>1) For the short range (0 - 1.5 meters)</b> <br  />
 Ambarella suggests using a chessboard or some other calibration tools to perform extrinsic calibration and get ground truth distance. Users should perform lens calibration first, then fill with intrinsic and distortion parameters to the commands below. The tools are in the path ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool. Users can perform the calibration and choose one value as the global offset value from the report. There are some scripts (run_xxx_xxxMHZ.sh) in the folder "script/tof" for reference; the user can run it by changing some parameters. <br  />
 Some descriptions of the options in the script: <br  />
 "bw" chessboard center numbers in the horizontal direction <br  />
 "bh" chessboard center numbers in the vertical direction <br  />
 "board-square" the side length of a square (unit is meter) <br  />
 "m" ToF frequency in Hz "global-offset" global-offset value, should be 0 for the global calibration. <br  />
 The command in the script is as shown below: There are many reference calibration command scripts in the path multi_sensor_calib/host_calib_tool/script/tof. <br  />
</p>
<div class="fragment"><div class="line">host # ../../bin/x86_64/tof_cali --mode 2 --show-fit --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#ad43c3812e6d13e0518d9f8b8f463ffcf">count</a> 50 -f ../../calib_data/wiggle_20m/ --fx 380.7416486811555</div>
<div class="line">--fy 380.7416486811555 --cx 321.0045588907875 --cy 243.8313078372227 --k1 -0.1839007852803311 --k2 0.3616930968794873</div>
<div class="line">--p1 0.0002937727395641034 --p2 0.0007998748191078006 --k3 -0.2225507425779707 --show-chess --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a750b5d744c39a06bfb13e6eb010e35d0">index</a> 1 --board-start 51</div>
<div class="line">--board-end 70 --bw 7 --bh 4 --board-square 0.1933 --control-cnt 20 --use-csv --use-white -m 120000000</div>
<div class="ttc" id="acJSON_8h_html_ad43c3812e6d13e0518d9f8b8f463ffcf"><div class="ttname"><a href="../../../library/d1/d82/cJSON_8h.html#ad43c3812e6d13e0518d9f8b8f463ffcf">count</a></div><div class="ttdeci">int count</div></div>
</div><!-- fragment --><p >The tool supports choosing points manually when the image quality is not well detected. The selection interface appears when the automatic points fail to extract. </p><div class="image">
<img src="../../manual.jpg" alt=""/>
<div class="caption">
Figure 4-2. Find Points.</div></div>
<p> The image shows how to choose the chessboard cross center manually; follow the straight line's direction.</p>
<p ><b>2) For the long range (greater than 1.5 meters)</b> <br  />
 Because it is difficult to find too-large calibration parameters, Ambarella recommends that users use a laser to perform the calibration.</p>
<div class="fragment"><div class="line">host # ../../bin/x86_64/tof_cali --mode 3 --show-fit --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#ad43c3812e6d13e0518d9f8b8f463ffcf">count</a> 50 -f ../../calib_data/tof/</div>
<div class="line">--control-cnt 5 -m 120000000 --global 0.48</div>
</div><!-- fragment --><div class="image">
<img src="../../global_offset.jpg" alt=""/>
<div class="caption">
Figure 4-3. Global Offset.</div></div>
<p> The image shows how to choose the global offset manually. Choose one value from the fitting image, such as (phase 0.2, offset -0.55), where -0.55 is the global compensation value. Option "global_offset" in the compensation stage of lc file should be filled with 0.55.</p>
<h3><a class="anchor" id="sensor_calibtof_wiggle_calib"></a>
4.3.3 Wiggling Calibration</h3>
<p >Modulation wave shape is not as perfect as the sinusoidal shape, so the phase delay will not be calculated correctly, and the imperfect phase will introduce the wiggling errors for different distances. It will bring wiggling errors. Taking multiple images can bring more points and improve the accuracy of fitting results. Capture data in small steps from the start to the end position so that it can cover full 360 degree in phase, then perform the wiggling calibration with PC tools with lens calibration results. Enter the folder "script/tof", fill with the global offset value as shown in the command below, and run the command again. </p><div class="fragment"><div class="line">host # ../../bin/x86_64/tof_cali --mode 2 --show-fit --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#ad43c3812e6d13e0518d9f8b8f463ffcf">count</a> 50 -f ../../calib_data/wiggle_20m/ --fx 380.7416486811555</div>
<div class="line">--fy 380.7416486811555 --cx 321.0045588907875 --cy 243.8313078372227 --k1 -0.1839007852803311 --k2 0.3616930968794873</div>
<div class="line">--p1 0.0002937727395641034 --p2 0.0007998748191078006 --k3 -0.2225507425779707 --show-chess --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a750b5d744c39a06bfb13e6eb010e35d0">index</a> 1 --board-start 51</div>
<div class="line">--board-end 70 --bw 7 --bh 4 --board-square 0.1933 --control-cnt 20 --use-csv --use-white -m 120000000 --global -0.311332</div>
</div><!-- fragment --><p> The tool will report the following: start base 0.000000, end base 1.008698, end off 0.996727 number 64, step base 0.01601108. <br  />
 Option "fit_num" in the compensation stage of lc file should be filled with 64.</p>
<div class="image">
<img src="../../wiggle_offset.jpg" alt=""/>
<div class="caption">
Figure 4-4. Wiggling Offset.</div></div>
<p> After the calibration, the data will vibrate around y = 0 axis, and a lookup table (LUT) for specific distance spacing to express distance compensation for different positions will be created. After ToF calibration, calibration data can be used for the ToF process on the chip.</p>
<h2><a class="anchor" id="tof_result"></a>
4.4 ToF Calibration Result</h2>
<p >The calibration result is listed in the above section.</p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_tof_rgbd"></a>
5. RGBD Registration Calibration</h1>
<p >This chapter describes the following conceptions:</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#rgbd_principle">5.1 RGBD Registration Calibration Principle</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#rgbd_tool">5.2 RGBD Registration Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#rgbd_flow">5.3 RGBD Registration Flow</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#rgbd_result">5.4 RGBD Registration Result</a></li>
</ul>
<h2><a class="anchor" id="rgbd_principle"></a>
5.1 RGBD Registration Calibration Principle</h2>
<p >Depth-sensing cameras have made it possible to use 3D point clouds in many fields of reasearch and industry. <br  />
 The 2D RGB cameras are used by many algorithms to perform detection and classification. <br  />
 The proposed solution provides a mechanism to calibrate RGB and depth <br  />
 cameras's intrinsic /extrinsic paramters and create an aligned matrix. <br  />
 With applying the aligned matrix, the dpeth image could be converted to the RGB's view in real time.</p>
<h2><a class="anchor" id="rgbd_tool"></a>
5.2 RGBD Registration Calibration Tool</h2>
<p >Path ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/bin/x86_64 <br  />
 Tool binocular_cali</p>
<h2><a class="anchor" id="rgbd_flow"></a>
5.3 RGBD Registration Flow</h2>
<div class="image">
<img src="../../rgbd_calib.jpg" alt=""/>
<div class="caption">
Figure 5-1. RGBD Calibration Image.</div></div>
<p> The image shows the calibration RGB and ToF amplitude images. <br  />
 The flow of calibration is performed in the steps below: <br  />
 1) Use the Amage tool to read configurations and adjust 3A for amplitude image. <br  />
 2) Capture the RGB / ToF (amplitude) calibration dataset. <br  />
 Key points for RGBD calibration <br  />
 The calibration process requires users to capture more than <b> 60 </b> pictures as shown in the image. <br  />
 Keep images covered different parts of FoV. <br  />
 Ambarella recommends using a chessboard to perform calibration. <br  />
 Ambarella recommends capturing images at three different distances, <br  />
 such as 1.5 / 1.8 / 2 meters (capture many images at a fixed distance (1.5 meters) and capture three images at a far distance (1.8 / 2 meters)). <br  />
 Keep the board in different angles (pitch / yaw / roll). <br  />
 Ensure that the chessboard is complete in the two channels' images. <br  />
 3) Perform the RGBD registration calibration. <br  />
 Calibration algorithm is performed as described below: <br  />
 1) Perform lens calibration for each lens <br  />
 The intrinsic / distortion parameters "intrinsic_x.bin" will be stored in the debug/front_end folder. <br  />
 2) Perform binocular calibration to get the alignment matrix between RGB and ToF sensors. <br  />
 Lens calibration results will be used as the initial values for binocular calibration; they could be fixed via the "--fix-distort" option. <br  />
 The alignment matrix parameters "align_mat.bin" will be stored in the debug/front_end folder. <br  />
</p>
<div class="fragment"><div class="line">host # ../../bin/x86_64/binocular_cali -i 0 --<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#ga85db88ffee2944ecd35c616393976289">width</a> 640 --<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gadd40f8a56ae8cc650f92a3aa4d2bac99">height</a> 480</div>
<div class="line">-i 1 --<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#ga85db88ffee2944ecd35c616393976289">width</a> 1920 --<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gadd40f8a56ae8cc650f92a3aa4d2bac99">height</a> 1080  --pattern-mode 0 --chess-sqs 0.03</div>
<div class="line">-d 5 --fix-distort --get-align --chess-w 11 --chess-h 8 -s 0 -n 52</div>
<div class="line">--l-file l_640x480_nv12_0000000000.yuv_canvas0_640x480_NV12.yuv</div>
<div class="line">--r-file l_1920x1080_nv12_0000000000.yuv_canvas2_1920x1080_NV12.yuv</div>
<div class="ttc" id="agroup__IAV_html_ga85db88ffee2944ecd35c616393976289"><div class="ttname"><a href="../../../driver/df/dc0/group__IAV.html#ga85db88ffee2944ecd35c616393976289">width</a></div><div class="ttdeci">u32 width</div></div>
<div class="ttc" id="agroup__IAV_html_gadd40f8a56ae8cc650f92a3aa4d2bac99"><div class="ttname"><a href="../../../driver/df/dc0/group__IAV.html#gadd40f8a56ae8cc650f92a3aa4d2bac99">height</a></div><div class="ttdeci">u32 height</div></div>
</div><!-- fragment --><p> Options descriptions <br  />
</p><ul>
<li>"--fix-distort" is used to fix the distortion parameters from the lens calibration stage in binocular calibration. <br  />
</li>
<li>"--get-align" is used to calculate the alignment matrix parameters. <br  />
</li>
<li>"-d" is used to set numbers of distortion paramters. <br  />
</li>
<li>"chess-w" is used to set the width of the chessboard. <br  />
</li>
<li>"chess-h" is used to set the height of the chessboard. <br  />
</li>
</ul>
<h2><a class="anchor" id="rgbd_result"></a>
5.4 RGBD Registration Result</h2>
<div class="image">
<img src="../../rgbd_registration.jpg" alt=""/>
<div class="caption">
Figure 5-2. RGBD Registration.</div></div>
<p> As shown in the image, the depth image is aligned to the RGB sensor and pasted on the RGB's view with overlay.</p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_stitch"></a>
6. Multi-sensor Stitching Pose Calibration</h1>
<p >This chapter describes the following concepts, using a four-channel stitching case as an example.</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_principle">6.1 Multi-sensor Stitching Pose Calibration Principle</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_tool">6.2 Multi-sensor Stitching Pose Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_flow">6.3 Stitching Pose Calibration Flow</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#stitching_cmd_list">6.4 Multi-Channel Stitching Example</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#stitching_pose_result">6.4.1 Four-channel Stitching Example</a></li>
</ul>
<h2><a class="anchor" id="stitching_pose_principle"></a>
6.1 Multi-sensor Stitching Pose Calibration Principle</h2>
<p >Homograpy matrix is used to express the transformation between two image planes. <br  />
 The calibration is used to get the homograpy matrix and project each channel to the middle image channel. <br  />
 It is assumed that users did lens calibration before this calibration stage. <br  />
 After the pose calibration, users can get the message of configuration (offset / width / height) for each channel. <br  />
</p>
<h2><a class="anchor" id="stitching_pose_tool"></a>
6.2 Multi-sensor Stitching Pose Calibration Tool</h2>
<p >For pose calibration, Ambarella supports performing pose calibration both on PC Windows side and board side. Users can get pose calibration application for Windows side in the path below. <br  />
 Environment: Win10, x64 Tool: cv2x_cv5x_pose_calibration_tool_for_windows_vx.x.x_x.tar.bz2</p>
<p >Board side path ambarella/prebuild/ambarella/library/multi_sensor_calib/lib/armv8-a <br  />
 Tool libsensor_calib.so <br  />
 Application <br  />
 ambarella/packages/sensor_calib_ini_parser/arch_v5/unit_test/test_sensor_calib.c <br  />
</p>
<h2><a class="anchor" id="stitching_pose_flow"></a>
6.3 Stitching Pose Calibration Flow</h2>
<p ><b>1) Capture image sets</b> </p><div class="image">
<img src="../../pose_calib_layout.jpg" alt=""/>
<div class="caption">
Figure 6-1. Camera Set and Calibration Board Layout.</div></div>
<p> The figure above shows the relative position of camera set and calibration board when users perform the pose calibration. <br  />
 Key points of capturing image sets for pose calibration are listed below:<br  />
 1: Fix three calibration boards distance (from the middle line of each group of two adjacent lens) to the same 1.5 meters. <br  />
 2: Make sure each calibration board can be perpendicular to the middle line as far as possible. <br  />
 3: Totally capture four images (the schematics images are shown below) for four lenses respectively. <br  />
 4: As figures <b>"Camera Set and Calibration Board Layout"</b> and <b>"Four-lens Schematic Images"</b> shown, the overlapping part view of two adjacent channels' must have circles of the calibration board. </p><div class="image">
<img src="../../pose_calib_schematic_image.jpg" alt=""/>
<div class="caption">
Figure 6-2. Four-lens Schematic Images.</div></div>
<p ><b>2) Perform the pose calibration</b> <br  />
 As users refer to <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_flow">3.3 Lens Calibration Flow</a> to get "intrinsic_x"(x = 0, 1, 2, 3) in the stage of lens calibration. Users can do pose calibration with the process below both at PC Windows side and board edge side. Users can perform pose calibration with the process below both at PC Windows side and board edge side. Compared with performing pose calibration at the board-edge side, performing pose calibration on the PC Windows-side is faster and more convenient. However, users may be required to change the specific distance dynamically. For such a situation, it is preferred to select board-edge side pose calibration. Here, Ambarella lists the commands at both the Windows side and the board-edge side. Users can choose either to perform pose calibration.</p>
<p ><b>PC Windows side:</b> </p><div class="fragment"><div class="line">host (Windows) $ copy <span class="stringliteral">&quot;intrinsic_x&quot;</span> generated in the stage of <span class="stringliteral">&quot;lens calibration&quot;</span> to the path <span class="stringliteral">&quot;front_end/&quot;</span> directly. (intrinsic_x: <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> = 0, 1, 2, 3)</div>
<div class="line">host (Windows) $ test_sensor_calib --msc-ini-file ..\config\sensor_calib_ini_pose_calibration_save_target_4x_ver.ini (or simply <span class="keywordtype">double</span> click <span class="stringliteral">&quot;save_target_info_4x_ver.bat&quot;</span>)</div>
<div class="line">host (Windows) $ Edit <span class="stringliteral">&quot;sensor_calib_ini_pose_calibration_distance_4x_ver.ini&quot;</span> and modify <span class="stringliteral">&quot;sensor_distance=x&quot;</span> accordingly. (<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> means the distance user specified, unit is meter.)</div>
<div class="line">host (Windows) $ test_sensor_calib --msc-ini-file ..\config\sensor_calib_ini_pose_calibration_distance_4x_ver.ini (or simply <span class="keywordtype">double</span> click <span class="stringliteral">&quot;specify_distance_4x_ver.bat&quot;</span>)</div>
<div class="line">host (Windows) $ There will be <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> configurations in the command window shown in the figure below.</div>
<div class="line">Users can then configure the <span class="stringliteral">&quot;cvx_quad_chan_xm_stitch_xM_linear.lua&quot;</span> file accordingly; the simplified reference lua configurations is shown below.</div>
<div class="line">vsrc_0 = {</div>
<div class="line">      ..............</div>
<div class="line">      mode = <span class="stringliteral">&quot;2592x1944&quot;</span>,</div>
<div class="line">      ..............</div>
<div class="line">}</div>
<div class="line">vsrc_1 = {</div>
<div class="line">      ..............</div>
<div class="line">      mode = <span class="stringliteral">&quot;2592x1944&quot;</span>,</div>
<div class="line">      ..............</div>
<div class="line">}</div>
<div class="line">vsrc_2 = {</div>
<div class="line">      ..............</div>
<div class="line">      mode = <span class="stringliteral">&quot;2592x1944&quot;</span>,</div>
<div class="line">      ..............</div>
<div class="line">}</div>
<div class="line">vsrc_3 = {</div>
<div class="line">      ..............</div>
<div class="line">      mode = <span class="stringliteral">&quot;2592x1944&quot;</span>,</div>
<div class="line">      ..............</div>
<div class="line">}</div>
<div class="line">chan_0 = {</div>
<div class="line">      ..............</div>
<div class="line">   -- ================ src buf cfg  ================</div>
<div class="line">      <a class="code hl_functionRef" target="_blank" href="../../../video/db/d1a/test__vout__cfg_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a> = {</div>
<div class="line">          max_output = {2592, 0},  -- output <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#ga85db88ffee2944ecd35c616393976289">width</a></div>
<div class="line">          input = {0, 0, 2592, 1944},  -- full VIN</div>
<div class="line">          output = {0, 0, 1984, 1696},</div>
<div class="line">      },</div>
<div class="line">      ..............</div>
<div class="line">}</div>
<div class="line">chan_1 = {</div>
<div class="line">      ..............</div>
<div class="line">   -- ================ src buf cfg  ================</div>
<div class="line">      <a class="code hl_functionRef" target="_blank" href="../../../video/db/d1a/test__vout__cfg_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a> = {</div>
<div class="line">          max_output = {2592, 0},  -- output <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#ga85db88ffee2944ecd35c616393976289">width</a></div>
<div class="line">          input = {0, 0, 2592, 1944},  -- full VIN</div>
<div class="line">          output = {0, 1536, 1984, 1696},</div>
<div class="line">      },</div>
<div class="line">      ..............</div>
<div class="line">}</div>
<div class="line">chan_2 = {</div>
<div class="line">      ..............</div>
<div class="line">   -- ================ src buf cfg  ================</div>
<div class="line">      <a class="code hl_functionRef" target="_blank" href="../../../video/db/d1a/test__vout__cfg_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a> = {</div>
<div class="line">          max_output = {2592, 0},  -- output <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#ga85db88ffee2944ecd35c616393976289">width</a></div>
<div class="line">          input = {0, 0, 2592, 1944},  -- full VIN</div>
<div class="line">          output = {0, 2944, 1984, 1696},</div>
<div class="line">      },</div>
<div class="line">      ..............</div>
<div class="line">}</div>
<div class="line">chan_3 = {</div>
<div class="line">      ..............</div>
<div class="line">      ..............</div>
<div class="line">   -- ================ src buf cfg  ================</div>
<div class="line">      <a class="code hl_functionRef" target="_blank" href="../../../video/db/d1a/test__vout__cfg_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a> = {</div>
<div class="line">          max_output = {2592, 0},  -- output <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#ga85db88ffee2944ecd35c616393976289">width</a></div>
<div class="line">          input = {0, 0, 2592, 1944},  -- full VIN</div>
<div class="line">          output = {0, 4480, 1984, 1472},</div>
<div class="line">      },</div>
<div class="line">      ..............</div>
<div class="line">}</div>
<div class="line">stream_0 = {</div>
<div class="line">    ..............</div>
<div class="line">    <span class="keywordtype">id</span> = 0,</div>
<div class="line">    max_size = {5952, 1984},</div>
<div class="line">    ..............</div>
<div class="line">}</div>
<div class="line">_resource_config_ = {</div>
<div class="line">      channels = {</div>
<div class="line">        chan_0,</div>
<div class="line">        chan_1,</div>
<div class="line">        chan_2,</div>
<div class="line">        chan_3,</div>
<div class="line">      },</div>
<div class="line">      canvas = {</div>
<div class="line">        {</div>
<div class="line">            type = <span class="stringliteral">&quot;encode&quot;</span>,</div>
<div class="line">            size = {1984, 5952},</div>
<div class="line">            <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> = {<span class="stringliteral">&quot;chan_0.main&quot;</span>,<span class="stringliteral">&quot;chan_1.main&quot;</span>,<span class="stringliteral">&quot;chan_2.main&quot;</span>,<span class="stringliteral">&quot;chan_3.main&quot;</span>,},</div>
<div class="line">        },</div>
<div class="line">      },</div>
<div class="line">      streams = {</div>
<div class="line">        stream_0,</div>
<div class="line">      },</div>
<div class="line">}</div>
<div class="line"><span class="keywordflow">return</span> _resource_config_</div>
<div class="ttc" id="acJSON_8h_html_aff2566f4c366b48d73479bef43ee4d2e"><div class="ttname"><a href="../../../library/d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a></div><div class="ttdeci">char * buffer</div></div>
<div class="ttc" id="atest__vout__cfg_8c_html_a3c04138a5bfe5d72780bb7e82a18e627"><div class="ttname"><a href="../../../video/db/d1a/test__vout__cfg_8c.html#a3c04138a5bfe5d72780bb7e82a18e627">main</a></div><div class="ttdeci">int main(int argc, char **argv)</div></div>
<div class="ttc" id="avin__init_8c_html_a07a87b2e6ed927503e2f95f119c9fc23"><div class="ttname"><a href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a></div><div class="ttdeci">int source</div></div>
</div><!-- fragment --> <div class="image">
<img src="../../source_buffer_configurations.jpg" alt=""/>
<div class="caption">
Figure 6-3. Source Buffer Configurations.</div></div>
<p ><b>The board edge side (The method for configuring the source buffer is the same as that for PC Windows side):</b> </p><div class="fragment"><div class="line">Board # copy <span class="stringliteral">&quot;intrinsic_x&quot;</span> generated in the stage of <span class="stringliteral">&quot;lens calibration&quot;</span> to the path <span class="stringliteral">&quot;front_end/&quot;</span> directly. (intrinsic_x: <a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> = 0, 1, 2, 3)</div>
<div class="line">Board # test_sensor_calib --msc-ini-file ../config/sensor_calib_ini_pose_calibration_save_target_4x_ver.ini</div>
<div class="line">Board # Edit <span class="stringliteral">&quot;sensor_calib_ini_pose_calibration_distance_4x_ver.ini&quot;</span> and modify <span class="stringliteral">&quot;sensor_distance=x&quot;</span> accordingly. (<a class="code hl_variableRef" target="_blank" href="../../../driver/df/dc0/group__IAV.html#gaf80df1bdae91e5f76236e6ed1110825d">x</a> means the distance user specified, unit is meter.)</div>
<div class="line">Board # test_sensor_calib --msc-ini-file ../config/sensor_calib_ini_pose_calibration_distance_4x_ver.ini</div>
<div class="line">Board # There will be <a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#a07a87b2e6ed927503e2f95f119c9fc23">source</a> <a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#aff2566f4c366b48d73479bef43ee4d2e">buffer</a> configurations showed in the command window, and then users can config <span class="stringliteral">&quot;cvx_quad_chan_xm_stitch_xM_linear.lua&quot;</span> file accordingly.</div>
</div><!-- fragment --><h2><a class="anchor" id="stitching_cmd_list"></a>
6.4 Multi-Channel Stitching Example</h2>
<h3><a class="anchor" id="stitching_pose_result"></a>
6.4.1 Four-channel Stitching Example</h3>
<p >The commands below demonstrate how to set up a four-channel stitching case. CV2x: <br  />
 </p><div class="fragment"><div class="line">host (Windows) $ copy folder <span class="stringliteral">&quot;back_end/&quot;</span> and <span class="stringliteral">&quot;cvx_quad_chan_xm_stitch_xM_linear.lua&quot;</span> file generated in the stage of @ref stitching_pose_flow to the path <span class="stringliteral">&quot;/root&quot;</span> of board.</div>
<div class="line">Board # init.sh --na &amp;&amp; modprobe imx335_mipi vinc_id=0xf1320 slave=1</div>
<div class="line">Board # test_aaa_service -a&amp;</div>
<div class="line">Board # test_encode -i 0 --enc-mode 0 --debug-stitched 1 --vsync-detect-disable 0 --resource-cfg cvx_quad_chan_xm_stitch_xM_linear.lua --<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a788db922597cf2fb6389e278f822e59f">raw</a>-capture 1</div>
<div class="line">Board # test_encode -A -H 1984x5952 -<a class="code hl_variableRef" target="_blank" href="../../../library/d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a> 1 --rotate 1 -e</div>
<div class="line">Board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 4 -f ./</div>
<div class="line">Board # test_stitch --mode 2 -f . --no-overlap --fuse-<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a> 15 --vertical (no overlap part)</div>
<div class="line">Board # test_stitch --mode 2 -f . --vertical (overlap)</div>
<div class="ttc" id="acJSON_8h_html_a1a175e87536301df98c805ac0636ad7c"><div class="ttname"><a href="../../../library/d1/d82/cJSON_8h.html#a1a175e87536301df98c805ac0636ad7c">b</a></div><div class="ttdeci">const cJSON *const b</div></div>
</div><!-- fragment --><p >The image below shows the contrast result for 4 channels stitching case after applying the pose calibration paramters. <br  />
 </p><div class="image">
<img src="../../before_after_stitching.jpg" alt=""/>
<div class="caption">
Figure 6-4. Before vs After Pose Calibration.</div></div>
<p> For more principles of stitching sensor calibration and stitching LDC alignment, please refer to links below. <a class="elRef" target="_blank" href="../../../library/d1/d1e/page_lib_sensor_calib_doc.html">Sensor Calibration Library API</a> <a class="elRef" target="_blank" href="../../../library/dd/da8/page_lib_stitch_doc.html">Stitch Library API</a></p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_thermal_rgb"></a>
7. Thermal-RGB Fusion FoV-Alignment Calibration</h1>
<p >This chapter describes the following conceptions:</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#thermal_rgb_principle">7.1 Thermal-RGB Fusion FoV-Alignment Calibration Principle</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#thermal_rgb_tool">7.2 Thermal-RGB Fusion FoV-Alignment Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#thermal_rgb_flow">7.3 Thermal-RGB Fusion FoV-Alignment Calibration Flow</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#thermal_rgb_result">7.4 Thermal-RGB Fusion FoV-Alignment Calibration Result</a></li>
</ul>
<h2><a class="anchor" id="thermal_rgb_principle"></a>
7.1 Thermal-RGB Fusion FoV-Alignment Calibration Principle</h2>
<div class="image">
<img src="../../thermal_rgb_fov_align_calib.jpg" alt=""/>
<div class="caption">
Figure 7-1. Thermal RGB Align Calibration.</div></div>
<p> For the majority of use cases, users will have to align the FoV of the thermal image with the RGB image before combining them. <br  />
 For example, suppose the thermal sensor resolution is 256x192, and the RGB sensor resolution is 2336x1752. <br  />
 To align the FoVs between thermal and RGB, users will need to get the coordinates of several specified <br  />
 key points for the same target in both sensor's FoVs. <br  />
</p>
<h2><a class="anchor" id="thermal_rgb_tool"></a>
7.2 Thermal-RGB Fusion FoV-Alignment Calibration Tool</h2>
<p >Path: ambarella/prebuild/ambarella/library/multi_sensor_calib/lib/armv8-a <br  />
 Tool: libsensor_calib.so <br  />
 Application: <br  />
 ambarella/packages/sensor_calib_ini_parser/arch_v5/unit_test/test_sensor_calib.c</p>
<h2><a class="anchor" id="thermal_rgb_flow"></a>
7.3 Thermal-RGB Fusion FoV-Alignment Calibration Flow</h2>
<p >Refer to <a class="elRef" target="_blank" href="../../../library/d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_thermal_rgb">Thermal and RGB Sensors Calibration</a> for more details.</p>
<h2><a class="anchor" id="thermal_rgb_result"></a>
7.4 Thermal-RGB Fusion FoV-Alignment Calibration Result</h2>
<div class="image">
<img src="../../thermal_rgb_result.jpg" alt=""/>
<div class="caption">
Figure 7-2. Thermal and RGB Alignment.</div></div>
<p> The image shows the result between before and after applying the thermal and RGB calibration paramters. <br  />
</p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_mono_rgb"></a>
8. Mono-RGB Fusion FoV-Alignment Calibration</h1>
<p >This chapter describes the following conceptions:</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#mono_rgb_principle">8.1 Mono-RGB Fusion FoV-Alignment Calibration Principle</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#mono_rgb_tool">8.2 Mono-RGB Fusion FoV-Alignment Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#mono_rgb_flow">8.3 Mono-RGB Fusion FoV-Alignment Calibration Flow</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#mono_rgb_result">8.4 Mono-RGB Fusion FoV-Alignment Calibration Result</a></li>
</ul>
<h2><a class="anchor" id="mono_rgb_principle"></a>
8.1 Mono-RGB Fusion FoV-Alignment Calibration Principle</h2>
<div class="image">
<img src="../../mono_rgb_cali.jpg" alt=""/>
<div class="caption">
Figure 8-1. Mono RGB Alignment Calibration.</div></div>
<p> For the mono and RGB sensors fusion application, users will have to align the FoV of the mono image with the FoV of the RGB image before combining them. <br  />
 The proposed solution provides a mechanism for thermal and RGB images alignment automated and much more efficient. <br  />
 With the advances in technology, mono and RGB alignment can be built to leverage automatic extraction method to reach subpixel pixel level alignment effect. <br  />
</p>
<h2><a class="anchor" id="mono_rgb_tool"></a>
8.2 Mono-RGB Fusion FoV-Alignment Calibration Tool</h2>
<p >Path: ambarella/prebuild/ambarella/library/multi_sensor_calib/lib/armv8-a <br  />
 Tool: libsensor_calib.so <br  />
 Application: <br  />
 ambarella/unit_test/private/package_test/arch_v5/test_sensor_calib.cpp <br  />
</p>
<h2><a class="anchor" id="mono_rgb_flow"></a>
8.3 Mono-RGB Fusion FoV-Alignment Calibration Flow</h2>
<p >1) If the user wants to use keypoints automatic detection algorithm to do calibration, Just do mono and RGB sensors calibration with following commands. </p><div class="fragment"><div class="line">Set no_dist_flag=0 <span class="keywordflow">if</span> the distortion has been calibrated.</div>
<div class="line">board # test_sensor_calib --msc-ini-file sensor_calib_ini_rgb_mono.ini</div>
<div class="line">If <span class="stringliteral">&quot;no_dist_flag=1&quot;</span> is used :</div>
<div class="line">board # test_stitch --mode 2 -f . --no-overlap --fuse 1</div>
<div class="line">If <span class="stringliteral">&quot;no_dist_flag=0&quot;</span> is used :</div>
<div class="line">board # test_sensor_calib --mode 2 --<a class="code hl_variableRef" target="_blank" href="../../../video/d4/daa/vin__init_8c.html#adf7dff2c57c0da9a4a2b70e3e815be31">channel</a>-num 2 -f ./</div>
<div class="line">board # test_stitch --mode 2 -f . --no-overlap --fuse 3</div>
</div><!-- fragment --><p >2) If the users have done the calibration by themselves, and want to apply homography matrix to the specific channel. </p><div class="fragment"><div class="line">board # test_sensor_calib --mode 1 -i 0 --no-distort --H_matrix 0.9977401365552157,-0.000099578</div>
<div class="line">23263696219,2.775830523841213,-0.0001202783377077572,0.9971905736384313,1.376427136930342,-</div>
<div class="line">0.0000001840078883173892,-0.000000157500677787866,1 --cali-type 0 -w 2688 -h 1520 -f .</div>
<div class="line">Configure the lua as the tool reports, and run :</div>
<div class="line">board # test_stitch --mode 2 -f . --no-overlap --fuse 1</div>
</div><!-- fragment --><p >Refer to <a class="elRef" target="_blank" href="../../../library/d1/d1e/page_lib_sensor_calib_doc.html#sensor_calib_mono_rgb"><ol type="1">
<li>Mono and RGB Sensor Calibration</li>
</ol>
</a> for more details.</p>
<h2><a class="anchor" id="mono_rgb_result"></a>
8.4 Mono-RGB Fusion FoV-Alignment Calibration Result</h2>
<div class="image">
<img src="../../mono_rgb_match.jpg" alt=""/>
<div class="caption">
Figure 8-2. Mono and RGB Alignment Matching.</div></div>
<p> The image shows the keypoints matching the result with mono and RGB sensors calibration. <br  />
</p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_structure_light"></a>
9. Structured-light Parameters Pose Calibration</h1>
<p >This chapter describes the following conceptions:</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sl_pose_principle">9.1 Structured-light Pose Parameters Calibration Principle</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sl_pose_tool">9.2 Structured-light Pose Parameters Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sl_pose_flow">9.3 Structured-light Pose Parameters Calibration Flow</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sl_pose_result">9.4 Structured-light Pose Parameters Calibration Result</a></li>
</ul>
<h2><a class="anchor" id="sl_pose_principle"></a>
9.1 Structured-light Pose Parameters Calibration Principle</h2>
<p >It is easy to cause an accuracy loss if users use the ruler to measure the baseline between the projector and the RGB sensor. <br  />
 The proposed solution provides a mechanism to calculate the structured light's pose parameters with high accuracy. With the advances in technology, the pose calibration parameters accuracy can reach 0.01 mm. </p><div class="image">
<img src="../../sl_formula.jpg" alt=""/>
<div class="caption">
Figure 9-1. Structured-light Pose Calibration.</div></div>
<p> With the proposed solution, the formula to calculate the depth can be expressed as shown in the image above. <br  />
 "e" is the disparity <br  />
 "d0" is the depth to the specific pattern. <br  />
 "fx" is the focal length from lens calibration. <br  />
 "Tx", "Ty" and "Tz" are the 3D coordinates based on the camera optical center. <br  />
 "u2" is the x coordinate in 2D image. <br  />
</p>
<h2><a class="anchor" id="sl_pose_tool"></a>
9.2 Structured-light Pose Parameters Calibration Tool</h2>
<p >Path: ambarella/prebuild/ambarella/library/multi_sensor_calib/host_calib_tool/bin/x86_64 <br  />
 Tool: sl_cali <br  />
</p>
<h2><a class="anchor" id="sl_pose_flow"></a>
9.3 Structured-light Pose Parameters Calibration Flow</h2>
<p >It is assumed that the lens calibration has been done perfectly before this stage, and the images are captured without distortion. Users can refer to <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#guide_sensor_calib_lens">Lens Calibration</a> for more details of lens calibration. </p><div class="image">
<img src="../../sl_base.jpg" alt=""/>
<div class="caption">
Figure 9-2. Structured Light in the First Position.</div></div>
<p> Put the structured-light camera in the first position with a certain distance (like 45 cm) to the pattern, <br  />
 and capture two YUVs as shown in the image. One image has no speckle, and the other one has. <br  />
 Convert them to the format of BMP. The name of one image is base_img.bmp, and name of the other image is random_img.bmp. <br  />
</p>
<div class="image">
<img src="../../sl_location.jpg" alt=""/>
<div class="caption">
Figure 9-3. Structured Light in the Second Position.</div></div>
<p> Put the structured-light camera in the second position with a certain distance (like 55 cm) to the pattern, <br  />
 and capture two YUVs as shown in the image. One image has no speckle, and the other one has. <br  />
 Convert them to the format of BMP. The name of one image is base_img1.bmp, and name of the other image is random_img1.bmp. <br  />
</p>
<p >Run the command as shown below: <br  />
 Tag-info is used to specify the pattern information, refer to <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sensor_calib_prepare_pat">2.1.3 Pattern Preparing Work</a> for more details. <br  />
 Share-id is used to specify the common April tag corner ID (there are four April tags in one image, and each tag has its own ID). <br  />
 Ensure that at lease one same April tag is visible in the four images. <br  />
 </p><div class="fragment"><div class="line">bin/x86_64/sl_cali -f calib_data/rgbir/50 --pattern 1 --tag-info 14,0.024,0.024 --share-<span class="keywordtype">id</span> 2 -r</div>
</div><!-- fragment --><h2><a class="anchor" id="sl_pose_result"></a>
9.4 Structured-light Pose Parameters Calibration Result</h2>
<p >The result is shown below : </p><div class="fragment"><div class="line">fitting plan file calib_data/rgbir/50/base_img.bmp</div>
<div class="line">fitting plan file calib_data/rgbir/50/random_img.bmp</div>
<div class="line">random points file calib_data/rgbir/50/base_img1.bmp</div>
<div class="line">random points file calib_data/rgbir/50/random_img1.bmp</div>
<div class="line">cnt 71, avg epilines error 0.131668</div>
<div class="line">cnt 65, avg epilines error 0.101085</div>
<div class="line">Final inlier 46</div>
<div class="line">T [0.040939398;</div>
<div class="line"> 0.00016056612]</div>
</div><!-- fragment --><p >"T" is the pose calibration result, it contains Tx and Tz. Users can apply it to the formula expressed in <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#sl_pose_principle">9.1 Structured-light Pose Parameters Calibration Principle</a>.</p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_dual_fish"></a>
10. Dual-fisheye back to back Pose Calibration</h1>
<p >This chapter describes the following conceptions:</p><ul>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#ds_pose_principle">10.1 Dual-fisheye Pose Calibration Principle</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#ds_pose_tool">10.2 Dual-fisheye Pose Calibration Tool</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#ds_pose_flow">10.3 Dual-fisheye Pose Calibration Flow</a></li>
<li><a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#ds_pose_result">10.4 Dual-fisheye Pose Calibration Result</a></li>
</ul>
<h2><a class="anchor" id="ds_pose_principle"></a>
10.1 Dual-fisheye Pose Calibration Principle</h2>
<p >Homograpy matrix is used to express the transformation between two image planes. <br  />
 The calibration is used to get the homograpy matrix and project each channel to the first image channel. <br  />
 After the pose calibration, users could get the message of configuration (offset / width / height) for each channel. <br  />
 </p><div class="image">
<img src="../../dual_fisheye_panorama.jpg" alt=""/>
<div class="caption">
Figure 10-1. Dual-fisheye Pose Calibration.</div></div>
<p> The ouput is a 360 x 180 degree panorama stitched view.</p>
<h2><a class="anchor" id="ds_pose_tool"></a>
10.2 Dual-fisheye Pose Calibration Tool</h2>
<p >For pose calibration, Ambarella supports to do pose calibration both on PC Windows side and board side. <br  />
 Users can get pose calibration application for Windows side from the below path. <br  />
 Environment: Win10, x64 Tool: cv2x_cv5x_pose_calibration_tool_for_windows_vx.x.x_x.tar.bz2 <br  />
 Board side path: ambarella/prebuild/ambarella/library/multi_sensor_calib/lib/armv8-a <br  />
 Tool: libsensor_calib.so <br  />
 Application: <br  />
 ambarella/packages/sensor_calib_ini_parser/arch_v5/unit_test/test_sensor_calib.c <br  />
</p>
<h2><a class="anchor" id="ds_pose_flow"></a>
10.3 Dual-fisheye Pose Calibration Flow</h2>
<p >1) If the users want to do the pose calibration with chessboard calibration board: <br  />
 The command to run the lens calibration is shown below: <br  />
 </p><div class="fragment"><div class="line">host $ save_target_info_2x_dual_fisheye_1920_1920_auto_chessboard_mei.bat</div>
</div><!-- fragment --><p >2) If the users want to to do the pose calibration without doing lens calibration : <br  />
 The users need to find the fisheye circle radius and image center manually. <br  />
 </p><div class="image">
<img src="../../fishe_radius_center.jpg" alt=""/>
<div class="caption">
Figure 10-2. Fisheye Radius and Center.</div></div>
<p> 1&gt; Find the circle center and radius like the picture show. <br  />
 Left point coordinate : (380, 528) <br  />
 Right point coordinate : (1489, 528) <br  />
 Radius = (1489 - 380) / 2 = 554 <br  />
 Center = (380 + (1489 - 380) / 2, 528) = (934, 528) <br  />
</p>
<p >2&gt; Run below command to create the undistorted images. <br  />
 </p><div class="fragment"><div class="line">host $ save_target_info_2x_dual_fisheye_1600_1296_manully_no_lens_calibration.bat &lt;br&gt;</div>
</div><!-- fragment --><p> The undistorted images will be stored in the same folder of the bat files, named "un_image_x.png". <br  />
</p>
<div class="image">
<img src="../../fisheye_undistorted_segment.jpg" alt=""/>
<div class="caption">
Figure 10-3. Fisheye Stitching Offset and Corresponding Points.</div></div>
<p> 3&gt; Choose the x coordinate offset_0 / offset_1 from the image "un_image_0.png". <br  />
 4&gt; Choose more than 4 pairs of corresponding points from the two undistorted images. <br  />
 5&gt; Fill them into the ini file as shown below. <br  />
 </p><div class="fragment"><div class="line">[Chan_x]</div>
<div class="line">   top_left_point=570,539:579,776</div>
<div class="line">   bot_right_point=1778,439:1830,815</div>
<div class="line">   focal=1080</div>
<div class="line">   cx=826</div>
<div class="line">   cy=624</div>
<div class="line">   no_dist_flag=1</div>
<div class="line"> </div>
<div class="line">[Calib]</div>
<div class="line">   fisheye_radius=602</div>
<div class="line">   fisheye_stitch_start=652</div>
<div class="line">   fisheye_stitch_end=1891</div>
</div><!-- fragment --><p >6&gt; Run below command to get the canvas configuration information. <br  />
 </p><div class="fragment"><div class="line">host $ save_target_info_2x_dual_fisheye_1600_1296_manully_no_lens_calibration.bat</div>
</div><!-- fragment --><p >3) If users want to to do the pose calibration with choosing the points manually: <br  />
 1&gt; Run below command to create the undistorted images. <br  />
 </p><div class="fragment"><div class="line">host $ save_target_info_2x_dual_fisheye_1920_1080_manully_mei.bat</div>
</div><!-- fragment --><p> The undistorted images will be stored in the same folder of the bat files, named "un_image_x.png" <br  />
 2&gt; Choose more than 4 pairs of corresponding points in the two undistorted images like above image shown. <br  />
 3&gt; Run below command to create the calibration information. <br  />
 </p><div class="fragment"><div class="line">host $ save_target_info_2x_dual_fisheye_1920_1080_manully_mei.bat</div>
</div><!-- fragment --><h2><a class="anchor" id="ds_pose_result"></a>
10.4 Dual-fisheye Pose Calibration Result</h2>
<p >The result is shown below: </p><div class="fragment"><div class="line">Channel [0] Configuration :</div>
<div class="line">Buffer : output size [2400x1296], zoom [1.000000, 1.000000]</div>
<div class="line">Canvas : Input : offset [0x0], size [0x0], Output : offset [0x0], size [704x1200]</div>
<div class="line">Canvas : Input : offset [0x0], size [0x0], Output : offset [1792x0], size [512x1200]</div>
<div class="line">Channel [1] Configuration :</div>
<div class="line">Buffer : output size [2752x1304], zoom [1.000000, 1.000000]</div>
<div class="line">Canvas : Input : offset [0x0], size [0x0], Output : offset [640x0], size [1216x1200]</div>
<div class="line">Canvas : Input : offset [0x0], size [0x0], Output : offset [0x0], size [0x0]</div>
</div><!-- fragment --><p> Users need to configure the lua script according to the report.</p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_faq"></a>
11. Sensor Calibration FAQ</h1>
<h2><a class="anchor" id="guide_sensor_calib_faq_q1"></a>
Question 1 How to ensure the lens calibration quality?</h2>
<p ><b>Answer:</b> To assure the lens calibration works well. Users need to ensure the following : <br  />
 1) Tool supports circle and chessboard patterns. It is more accurate to use circle pattern, keep each circle's diameter about 20 pixels. <br  />
 2) At least one Apriltag in the image. <br  />
 3) It is better to take snapshots in different distances from close to far, with different angles (pitch / yaw / roll, cover full FoV). <br  />
 4) Choose the rigid and flat board as a calibration board, and make sure RMS is less than 0.4. It is hard to achieve 0.4, if the calibration target's quality is not good enough. <br  />
 5) Measure average distance between two circle centers (measuring distance between two tags in the horizontal and vertical direction, divided by circle numbers, then getting an average value) and fill in run_cali.sh. <br  />
 6) Set <b> "debug" </b> option as <a class="el" href="../../d9/d68/page_sensor_calib_user_guide_doc.html#lens_calib_flow">3.3 Lens Calibration Flow</a> to check the lens calibration quality.</p>
<h2><a class="anchor" id="guide_sensor_calib_faq_q2"></a>
Question 2 What is the minimum number of images required for the fast lens calibration?</h2>
<p ><b>Answer:</b> Users need to capture at least 3 images to perform the fast lens calibration. It is suggested <br  />
 to put the pattern in left, middle, right part of the image, refer to the dataset in the cv2x_cv5x_lens_calibration_tool_for_windows_vx.x.x_x.tar.bz2.</p>
<h2><a class="anchor" id="guide_sensor_calib_faq_q3"></a>
Question 3 Can Lens calibration work well with multiple patterns in one image?</h2>
<p ><b>Answer:</b> Yes. The lens calibration supports multiple circle patterns in one image. <br  />
 Users can set <b> "debug" </b> option's bit 2 as 1 to check the tag information.</p>
<h2><a class="anchor" id="guide_sensor_calib_faq_q4"></a>
Question 4 How to ensure the stitching pose calibration quality?</h2>
<p ><b>Answer:</b> To make sure stitch pose calibration works well. Users need to ensure the following : <br  />
 1) At least one pair of common April tag in the images. <br  />
 2) The lens calibration result is good.</p>
<h2><a class="anchor" id="guide_sensor_calib_faq_q5"></a>
Question 5 What's the mass production strategy for multi-VIN stitching?</h2>
<p ><b>Answer:</b> <br  />
 1) If the customer wants to do the pose calibration with a fixed pattern (without specifying specific distance). <br  />
 It is better to do lens calibration once, as distortion parameters are similar for the same type lens. <br  />
 Pose calibration must be done for every equipment, using the calibration tool on board is faster. <br  />
 2) If the customer wants to do the pose calibration with a fixed pattern (specifying certain distance). <br  />
 As the image center is different for each channel, it is recommended to use more than <b> 60 </b> images to do the full lens calibration once to get initial parameters. Additionally, the lens calibration for each lens with two or three images is performed to estimate the image center.</p>
<h2><a class="anchor" id="guide_sensor_calib_faq_q6"></a>
Question 6 How to ensure the thermal-RGB fusion FoV-alignment calibration quality?</h2>
<p ><b>Answer:</b> <br  />
 If the user is not satisfied with the alignment quality of choosing 4 pairs of key points manually, the tools support more pairs of <br  />
 key points to do calibration, the more the better. It is suggested to choose the points that are uniform and do not cluster together to improve the accuracy.</p>
<h2><a class="anchor" id="guide_sensor_calib_faq_q7"></a>
Question 7 How to avoid image size mismatching between different channels for multi-VIN stitching?</h2>
<p ><b>Answer:</b> <br  />
 </p><div class="image">
<img src="../../different_stitching_size.jpg" alt=""/>
<div class="caption">
Figure 11-1. Image Size Mismatching between Different Channel.</div></div>
<p> The image shows the pattern size is mismatching between two channels, the root cause is that the calibration intrinsic data's focal length <br  />
 is not similar (lens calibration is not performed well). For example, if one channel's focal lenght is 1750, <br  />
 and the other channel's focal length is 1810, the difference will be (1800 - 1750) / 1750 = 0.03. <br  />
 So it is necessary to keep the output of the lens calibration's intrinsic parameters are similar when doing the lens calibration.</p>
<hr  />
<h1><a class="anchor" id="guide_sensor_calib_lic"></a>
12. License</h1>
<p >Copyright (c) 2024 Ambarella International LP.</p>
<p >This file and its contents ( "Software" ) are protected by intellectual property rights including, without limitation, U.S. and/or foreign copyrights. This Software is also the confidential and proprietary information of Ambarella International LP and its licensors. You may not use, reproduce, disclose, distribute, modify, or otherwise prepare derivative works of this Software or any portion thereof except pursuant to a signed license agreement or nondisclosure agreement with Ambarella International LP or its authorized affiliates. In the absence of such an agreement, you agree to promptly notify and return this Software to Ambarella International LP</p>
<p >THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF NON-INFRINGEMENT, MERCHANTABILITY, AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL AMBARELLA INTERNATIONAL LP OR ITS AFFILIATES BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; COMPUTER FAILURE OR MALFUNCTION; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3 </li>
  </ul>
</div>
</body>
</html>
