<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.3"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Video: OTHER - FAQ</title>
<link href="../../tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../jquery.js"></script>
<script type="text/javascript" src="../../dynsections.js"></script>
<link href="../../navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../resize.js"></script>
<script type="text/javascript" src="../../navtreedata.js"></script>
<script type="text/javascript" src="../../navtree.js"></script>
<link href="../../search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="../../search/search.js"></script>
<link rel="search" href="../../search_opensearch.php?v=opensearch.xml" type="application/opensearchdescription+xml" title="Video"/>
<link href="../../doxygen.css" rel="stylesheet" type="text/css" />
<link href="../../doxygen-awesome.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-awesome-sidebar-only.css" rel="stylesheet" type="text/css"/>
<link href="../../doxygen-ambarella.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectlogo"><img alt="Logo" src="../../Ambarella.png"/></td>
  <td id="projectalign">
   <div id="projectname">Video<span id="projectnumber">&#160;Cooper_1.6.0 (CV72 &amp; CV3) @ 2024.07.10 14:12:44</span>
   </div>
   <div id="projectbrief">placeholder</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.3 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "../../search",'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="../../menudata.js"></script>
<script type="text/javascript" src="../../menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('../../',true,true,'search.html','Search');
  $(document).ready(function() {
    if ($('.searchresults').length > 0) { searchBox.DOMSearchField().focus(); }
  });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(document).ready(function(){initNavTree('d5/d6e/fs_others_faq.html','../../'); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<div><div class="header">
  <div class="headertitle"><div class="title">OTHER - FAQ </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h1><a class="anchor" id="faq_block_diagram_of_the_chip"></a>
1. Block Diagram of the Chip (Single VIN)</h1>
<p >The following figure shows the data flow of the chip (single VIN). </p><div class="image">
<img src="../../data_flow_of_chip_v6.png" alt=""/>
<div class="caption">
Data Flow of Chip</div></div>
<p> Before proceeding, read the following to better understand the system.</p><ul>
<li>The main buffer is generated from sensor with Digital Pan/Tilt/Zoom (DPTZ) type I, and other five sub-buffers are generated from the main buffer with the DPTZ type II. As a result, updating the main buffer affects all five sub-buffers.</li>
<li>VIN size &gt;= main buffer size &gt;= sub-buffer size.</li>
<li>For information on the limitation of each buffer, please refer to <a class="el" href="../../d0/ded/fs_basic_source_buffer.html">BASIC - Source Buffer</a>.</li>
<li>Stream is different from buffer. There are 6 buffers and 20 streams for CV5x / CV7x, and streams can use the same buffer as the video source or use different buffers for the video source. As a result, the ratio between buffers and streams is unequal.</li>
<li>DPTZ is not used from the source buffer to the encoder; however, crop can be used for encoding from different areas in the same buffer.</li>
<li>The overlay / blur is inserted between the buffer and encoder, so if all the streams come from the same buffer, they will share the same overlay / blur. Therefore, to obtain different overlay / blur, set streams to encode from different buffers.</li>
<li>Because privacy mask (PM) is inserted in the main buffer, all streams will include PM.</li>
</ul>
<h1><a class="anchor" id="faq_max_encode_performance"></a>
2. Max Encode Performance</h1>
<p >Each Cooper platform has several part numbers with a different maximum encode performance. For details, refer to the Ambarella Cooper Linux SDK Release Notes document.</p>
<h1><a class="anchor" id="faq_obtain_video_data_efficiently"></a>
3. Obtain Video Data Efficiently</h1>
<p >Because the DSP provides H.264 / H.265 RAW data, the core task is to efficiently fetch bitstream and avoid data copy while connecting the user's app / middleware and the Ambarella SDK.<br  />
 The data is stored in the bitstream buffer (BSB) regardless of the amount of streams used. The buffer is located at a physical continual address which is mapped to the user space in Linux. As a result, the buffer uses different addresses in different processes, which is convenient for data point delivery between various processes with no copy.<br  />
 To efficiently obtain video data, perform the following steps:<br  />
 To obtain the stream, refer to the test samples <code>(test_stream/test_bsreader)</code> in the SDK. The following command uses the '"test_stream.c"' as an example.<br  />
 </p><div class="fragment"><div class="line">query_mem.mid = <a class="code hl_variableRef" href="../../../library/de/d89/iav__ioctl_8h.html#aa4ef4a9add627e30f58595a1e8a78225ad6cd45b3e12fec076b535370ba973524">IAV_MEM_PARTITION</a>;</div>
<div class="line">part_info = &amp;query_mem.arg.partition;</div>
<div class="line">part_info-&gt;pid = <a class="code hl_variableRef" href="../../../library/de/d89/iav__ioctl_8h.html#a6e160acba2472e919b41321d8fbe72faa09de9a53727022c18429db179a1d1ead">IAV_PART_BSB</a>;</div>
<div class="line">ioctl(<a class="code hl_variable" href="../../d4/daa/vin__init_8c.html#a5294002f7dca0cd9bcc0009a27895ef7">fd_iav</a>, IAV_IOC_QUERY_MEMBLOCK, &amp;query_mem);</div>
<div class="line">bsb_size = part_info-&gt;mem.length;</div>
<div class="line">bsb_mem = mmap(NULL, bsb_size * 2, PROT_READ, MAP_SHARED, <a class="code hl_variable" href="../../d4/daa/vin__init_8c.html#a5294002f7dca0cd9bcc0009a27895ef7">fd_iav</a>, part_info-&gt;mem.addr);</div>
<div class="ttc" id="aiav__ioctl_8h_html_a6e160acba2472e919b41321d8fbe72faa09de9a53727022c18429db179a1d1ead"><div class="ttname"><a href="../../../library/de/d89/iav__ioctl_8h.html#a6e160acba2472e919b41321d8fbe72faa09de9a53727022c18429db179a1d1ead">IAV_PART_BSB</a></div><div class="ttdeci">IAV_PART_BSB</div></div>
<div class="ttc" id="aiav__ioctl_8h_html_aa4ef4a9add627e30f58595a1e8a78225ad6cd45b3e12fec076b535370ba973524"><div class="ttname"><a href="../../../library/de/d89/iav__ioctl_8h.html#aa4ef4a9add627e30f58595a1e8a78225ad6cd45b3e12fec076b535370ba973524">IAV_MEM_PARTITION</a></div><div class="ttdeci">IAV_MEM_PARTITION</div></div>
<div class="ttc" id="avin__init_8c_html_a5294002f7dca0cd9bcc0009a27895ef7"><div class="ttname"><a href="../../d4/daa/vin__init_8c.html#a5294002f7dca0cd9bcc0009a27895ef7">fd_iav</a></div><div class="ttdeci">int fd_iav</div></div>
</div><!-- fragment --><p> The code above shows how to obtain the base virtual address of BSB in the current process. This base address will be different for various processes. </p><div class="fragment"><div class="line">query_desc.qid = <a class="code hl_variableRef" href="../../../driver/d3/de3/group__iav-ioctl-general-helper.html#gga3606b35b652dca594dc455dfb0b9f172a05a4e65f2c13698887b00b1c3ecc78f9">IAV_DESC_FRAME</a>;</div>
<div class="line">ioctl(<a class="code hl_variable" href="../../d4/daa/vin__init_8c.html#a5294002f7dca0cd9bcc0009a27895ef7">fd_iav</a>, IAV_IOC_QUERY_DESC, &amp;query_desc);</div>
<div class="ttc" id="agroup__iav-ioctl-general-helper_html_gga3606b35b652dca594dc455dfb0b9f172a05a4e65f2c13698887b00b1c3ecc78f9"><div class="ttname"><a href="../../../driver/d3/de3/group__iav-ioctl-general-helper.html#gga3606b35b652dca594dc455dfb0b9f172a05a4e65f2c13698887b00b1c3ecc78f9">IAV_DESC_FRAME</a></div><div class="ttdeci">IAV_DESC_FRAME</div></div>
</div><!-- fragment --><p> Additionally, the code above can obtain the address offset between each frame; this value can be transferred between different processes. However, users should not call <b>IAV_IOC_QUERY_DESC</b> simultaneously during different processes because the same frame cannot be repeatedly fetched.<br  />
 Moreover, users should not create processes to call <b>IAV_IOC_QUERY_DESC</b> for every stream, as this is used to obtain the frames together and distribute them out to every stream.<br  />
 BSB is a ring buffer; the time for data overflow is determined by the BSB size and the frame rate for each stream. However, under normal circumstances, users can obtain the data for the file store or net transfer directly without loosing data. As a result, it is not necessary to create a new pool buffer for the data cycle save, as it will not be efficient for dynamic random-access memory (DRAM) bandwidth nor the CPU.<br  />
 Use make menuconfig to change the size of the bitstream buffer. For details, refer to the Doxygen CMA Driver document.</p>
<h1><a class="anchor" id="faq_synchronization_between_3a_and_encode"></a>
4. Synchronization between 3A and Encode</h1>
<p >This section describes the work flow of synchronization between encode and the image applications.<br  />
 The following illustrates the work flow. </p><div class="image">
<img src="../../illustration_of_synchronization_flow.png" alt=""/>
<div class="caption">
Illustration of Synchronization Flow</div></div>
<p> The image process includes multiple threads: one is a Netlink thread; all others are 3A threads. Netlink synchronization occurs only between the Netlink thread in the image process and the IAV driver.<br  />
 The encode process does not directly join this. The figure above describes two flows of synchronization between the images and the encode applications.</p><ol type="1">
<li>Sequence of "enter preview state":<ul>
<li>(<code>test_aaa_service</code>) Establish Netlink connection with the IAV driver from the user space.</li>
<li>(<code>test_aaa_service</code>) Wait for "prepare_3a" message from the kernel space.</li>
<li>(<code>test_encode</code>) Call IOCTL to issue the encode commands to enter into the preview state and wait for the IOCTL calls to be complete.</li>
<li>(<code>IAV driver</code>) Check the parameters from "test_encode", and then send "prepare_3a" message to the image application, and wait for the acknowledgment (ACK) from the user space.</li>
<li>(<code>test_aaa_service</code>) Receive the "prepare_3a" message and prepare the IDSP bin for 3A configuration.</li>
<li>(<code>test_aaa_service</code>) Send "prepare_3a" ACK to the kernel and wait for the "start_3a" message from the kernel.</li>
<li>(<code>IAV driver</code>) Receive the "prepare_3a" ACK from the user space, then issue commands to the DSP and enter the preview state.</li>
<li>(<code>IAV driver</code>) Send "start_3a" message to the image application and wait for the ACK from the user space.</li>
<li>(<code>test_aaa_service</code>) Receive the "start_3a" message, create, and start 3A working threads.</li>
<li>(<code>test_aaa_service</code>) Send "start_3a" ACK to kernel, and wait for "stop_3a" message from the kernel space. Until then, all 3A threads are kept running to receive the 3A API as usual.</li>
<li>(<code>IAV driver</code>) Receive the "start_3a" ACK from the user space and return the IOCTL callings to "test_encode".</li>
<li>(<code>test_encode</code>) Exit from IOCTL callings.</li>
<li>The system now enters the preview state and the image quality is correct.</li>
<li>In the preview state, all 3A threads are run to receive the image API as usual. All image API callings go directly to 3A threads, but not to the Netlink thread.</li>
</ul>
</li>
<li>Sequence of "enter idle state":<ul>
<li>(<code>test_aaa_service</code>) Wait for the "stop_3a" message from the kernel space.</li>
<li>(<code>test_encode</code>) Call IOCTL to issue the encode command to enter the IDLE state, and wait for the IOCTL callings to be complete.</li>
<li>(<code>IAV_driver</code>) Check the parameters from "test_encode", then send a "stop_3a" message to the image application, and wait for the ACK from the user space.</li>
<li>(<code>test_aaa_service</code>) Receive the "stop_3a" message and stop the 3A working threads.</li>
<li>(<code>test_aaa_service</code>) Send "stop_3a" ACK to kernel and wait for the "prepare_3a" message from the kernel.</li>
<li>(<code>IAV driver</code>) Receive the "stop_3a" ACK from the user space, and then issue commands to DSP, and enter the idle state.</li>
<li>(<code>IAV driver</code>) Return from IOCTL callings to "test_encode".</li>
<li>(<code>test_encode</code>) Exit from IOCTL callings.</li>
<li>Now, the system enters the idle state and the image process waits for the "prepare_3a" message in the next round.</li>
</ul>
</li>
</ol>
<h1><a class="anchor" id="faq_magic_zoom"></a>
5. Magic Zoom</h1>
<p >Magic Zoom is a key component in Ambarella resolution. Without interpolation amplification, Magic Zoom achieves the same effect with optical zoom; the AMBA DSP connects to a large resolution sensor, which is larger than the encoding specifications (see the following figure). </p><div class="image">
<img src="../../magic_zoom_with_dptz_1.png" alt=""/>
<div class="caption">
Magic Zoom with DPTZ I</div></div>
<p> Example:<br  />
 In OS05A10 (5M), the main buffer is 720p. 4M data converts to 720 through oversampling-&gt;stitching-&gt;downscaling. The field of views (FoVs) of all pictures are complete, and the screen resolution is better than from the 720p sensor.<br  />
 Next, add zoom in, and perform downscaling (2X) after the sensor is used to crop in original video or directly send the original video to the main buffer for encoding. Because there is no interpolation amplification, good video quality is guaranteed.<br  />
 Although this feature uses DPTZ I to perform Magic Zoom, users can save a high resolution stream in local by using DTPZ II (see the following figure). Users can crop 720p downscaling or 480p downscaling for encoding in the main buffer. </p><div class="image">
<img src="../../magic_zoom_with_dptz_2.png" alt=""/>
<div class="caption">
Magic Zoom with DPTZ II</div></div>
<h1><a class="anchor" id="faq_data_dump"></a>
6. Data Dump</h1>
<p >When the DSP enters the preview or encode state, users can dump RAW / YUV420 / YUV422 / ME0 / ME1 data for different uses:</p><ul>
<li>Because RAW data comes from the sensor, the dumped RAW data can be used to check if the sensor is functioning correctly.</li>
<li>YUV420 / YUV422 / ME1 / ME0 are used for motion detection. There is only one Y (Luma) component in the ME1/ME0 data. The ME0 data size is 1/8 the width and height of the source buffer. Additionally the ME1 data size is 1/4 the width and height of the source buffer, so the total size is 1/16 of the source buffer. Therefore, ME0 is the best data for motion detection for cases with a small DRAM bandwidth.</li>
</ul>
<h1><a class="anchor" id="faq_two_types_of_pts"></a>
7. Two Types of PTS</h1>
<p >Users can obtain two different types of presentation time stamps (PTS): arm_pts and dsp_pts (code in <code>test_stream.c</code>). arm_pts is used for audio and video synchronization. dsp_pts is used for internal reference only, to calculate each frame interval.<br  />
 Therefore, if the file <code>\proc\ambarella\ambarella_hwtimer</code> exists (indicating a hardware timer is included), arm_pts will be generated by the hardware; or alternatively, it will be generated by the software, as function <b>get_monotonic_pts</b> calls <b>do_gettimeofday</b> to obtain system time.</p>
<h1><a class="anchor" id="faq_vbr_and_cbr"></a>
8. Variable Bit Rate (VBR) and Constant Bit Rate (CBR)</h1>
<p >The following include descriptions for the different types of constant bit rate and variable bit rate modes.</p><ul>
<li>IAV_CBR (CBR): One of the Smart CBR modes, where bitrate is set by "--bitrate". QP minimal value is 1 and the maximal value is 51, and frame drop is not allowed. Change QP to ensure a stable bitrate.</li>
<li>IAV_CBR_QUALITY_KEEPING (CBR-quality): One of the Smart CBR modes, where bit rate is set by "--bitrate". QP minimal value is 1, and maximal is decided by the bit rate and resolution. Change QP value and drop frame to ensure a stable bit rate, and try to keep the video quality stable.</li>
<li>IAV_VBR (VBR): One of the Smart CBR modes, where bit rate is set by "--vbr-bitrate". QP maximal value is 51, and the minimal is decided by "--vbr-bitrate" and resolution, and the frame drop is not allowed. Changing QP to make the bit rate stay in range is set by "--vbr-bitrate".</li>
<li>IAV_VBR_QUALITY_KEEPING (VBR-quality): One of the Smart CBR modes, where bit rate is set by "--vbr-bitrate". QP maximal value is the same as the minimal value, all decided by the maximal value of "--vbr-bitrate" and resolution; it also allows the frame drop. Change the QP value and drop frame to ensure a stable bit rate, and try to keep the video quality stable. Typically, the smart CBR is used for CBR | VBR | CBR-quality | VBR-quality. Users can set the QP value, decide to set the frame drop or not, and set the rate range and other values to achieve the balance between the image and bit rate when the bit rate is relatively stable.</li>
</ul>
<h1><a class="anchor" id="faq_dump_yuv_with_without_osd"></a>
9. Dump YUV with / without overlay</h1>
<p >As the final stage of YUV, overlay is inserted before the encoder. The captured YUV data can be stamped with or without the overlay.<br  />
 The following illustrates the flow of video data. </p><div class="image">
<img src="../../video_data_flow.png" alt=""/>
<div class="caption">
Video Data Flow</div></div>
<p> To ensure that the overlay is inserted on the YUV frame, perform the following:</p><ul>
<li>Set "extra_dram_buf = 3" in a lua script's canvas configuration to make a YUV image be stored in the memory cached for more than 3 frames’ time before overlay insertion; <div class="fragment"><div class="line">canvas = {</div>
<div class="line">    ...</div>
<div class="line">    {</div>
<div class="line">        type = <span class="stringliteral">&quot;encode&quot;</span>,</div>
<div class="line">        ...</div>
<div class="line">        extra_dram_buf = 3,</div>
<div class="line">    },</div>
<div class="line">        ...</div>
<div class="line">}</div>
</div><!-- fragment --></li>
<li>Query the address of YUV frame and the corresponding YUV PTS, and then save the two variables.</li>
<li>Compare H.264 PTS with YUV PTS which is saved in Step 2. If the values are equal, it means the frame has been encoded with overlay. Then, read out the YUV data from the address of YUV frame corresponding to this YUV PTS. At this time, user application can ensure that the frame read out is a complete frame with overlay.</li>
<li>If the CPU is used to read out the YUV data (like to call <b>memcpy()</b> function), the speed can be slow as it is affected by the CPU loading introduced by other user applications. If the YUV data cannot be read out within extra_dram_buf frames’ time, it will be overwritten by the DSP. Therefore, it is strongly recommended to use GDMA copy to speed up the YUV data copying. GDMA copy is not affected by the CPU loading since it is operated by GDMA hardware. For the usage above, refer to the codes:<br  />
 <code>unit_test\private\iav_test\dsp_v6\test_stream.c</code><br  />
 <code>unit_test\private\iav_test\dsp_v6\test_yuvcap.c</code><br  />
 <code>unit_test\private\iav_test\dsp_v6\test_memcpy.c</code><br  />
 Note the following when determining a method for not inserting overlay on the YUV frame:</li>
<li>Because the Arm® is not given the exact time when the overlay content will be applied on the source buffer, it cannot guarantee YUV without overlay.</li>
<li>The option, "--encode-dummy-latency" can be used to cache frames between the image digital signal processing (IDSP) and the video digital signal processing (VDSP). (overlay is added in the VDSP side.) When the cache frames option is enabled, the application can obtain the YUV data without overlay. This option increases the DSP DRAM size by "YUV frame size * dummy_latency_frames".<br  />
 For example, if "test_encode --encode-dummy-latency 1", the user has one frame time (33ms) to read out the YUV data before overlay applied, but DSP DRAM size also increases one frame size for all source buffers, from main to the 5th buffer. </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="../../doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.3 </li>
  </ul>
</div>
</body>
</html>
